import asyncio
import json
import os
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Any

# å°†srcç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„
# è·å–å½“å‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
current_file = os.path.abspath(__file__)
# è·å–tools/mcp_bus/serverç›®å½•çš„çˆ¶ç›®å½•ï¼ˆå³tools/mcp_busï¼‰
mcp_bus_dir = os.path.dirname(os.path.dirname(current_file))
# è·å–toolsç›®å½•
tools_dir = os.path.dirname(mcp_bus_dir)
# è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆå³quantsysï¼‰
repo_root = os.path.dirname(tools_dir)
src_path = os.path.join(repo_root, "src")
if src_path not in sys.path:
    sys.path.insert(0, src_path)

# ç¡®ä¿srcç›®å½•è¢«æ­£ç¡®æ·»åŠ åˆ°Pythonè·¯å¾„
print(f"[DEBUG] src_path: {src_path}")
print(f"[DEBUG] sys.path: {sys.path}")

# æµ‹è¯•å¯¼å…¥
try:
    from quantsys.api.strategy_manager import StrategyManager
    print("[DEBUG] Successfully imported StrategyManager")
except Exception as e:
    print(f"[DEBUG] Failed to import StrategyManager: {e}")
    # æ‰“å°æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
    import traceback
    traceback.print_exc()

import httpx
import uvicorn
import subprocess
import signal
import threading
import socket
import tempfile
import atexit
from dotenv import load_dotenv
from fastapi import Depends, FastAPI, Header, HTTPException, Request, WebSocket
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.responses import (
    FileResponse,
    HTMLResponse,
    JSONResponse,
    RedirectResponse,
    Response,
)
from fastapi.staticfiles import StaticFiles
from jose import JWTError, jwt
from pydantic import BaseModel

# åŠ è½½.envæ–‡ä»¶ï¼ˆæ”¯æŒå¤šä¸ªè·¯å¾„ï¼‰
# æ³¨æ„ï¼šè¿™é‡Œloggerå¯èƒ½è¿˜æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨printè¾“å‡º
env_paths = [
    Path(__file__).parent.parent / ".env",  # tools/mcp_bus/.env
    Path(__file__).parent.parent.parent / ".env",  # é¡¹ç›®æ ¹ç›®å½•/.env
]
env_loaded = False
for env_path in env_paths:
    if env_path.exists():
        load_dotenv(env_path, override=False)  # ä¸è¦†ç›–å·²å­˜åœ¨çš„ç¯å¢ƒå˜é‡
        print(f"[INFO] Loaded .env from: {env_path}")
        # æ‰“å°å…³é”®ç¯å¢ƒå˜é‡
        auto_start = os.getenv("AUTO_START_FREQTRADE", "NOT SET")
        print(f"[INFO] AUTO_START_FREQTRADE={auto_start}")
        env_loaded = True
        break
if not env_loaded:
    print("[INFO] No .env file found, using defaults")
    print(
        f"[INFO] AUTO_START_FREQTRADE={os.getenv('AUTO_START_FREQTRADE', 'NOT SET (default: enabled)')}"
    )
load_dotenv()  # ä¹Ÿå°è¯•ä»å½“å‰ç›®å½•åŠ è½½
# å†æ¬¡ç¡®è®¤ç¯å¢ƒå˜é‡ï¼ˆå¯èƒ½åœ¨å½“å‰ç›®å½•åŠ è½½ï¼‰
if not env_loaded:
    auto_start = os.getenv("AUTO_START_FREQTRADE", "")
    if auto_start:
        print(f"[INFO] AUTO_START_FREQTRADE from current dir: {auto_start}")

# é»˜è®¤ç¦ç”¨è‡ªå¯ï¼Œä½†æä¾›å¯é çš„å¯åŠ¨æœºåˆ¶ç¡®ä¿100%æˆåŠŸç‡
# å¦‚æœéœ€è¦ä¸æ€»æœåŠ¡å™¨åŒæ­¥å¯åŠ¨ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡ AUTO_START_FREQTRADE=true
if not os.getenv("AUTO_START_FREQTRADE"):
    os.environ["AUTO_START_FREQTRADE"] = "false"
    print("[INFO] AUTO_START_FREQTRADE set to default: false (disabled, set to true to enable)")

import logging

from .audit import AuditLogger
from .auth import UserRole, auth_service
from .cache_service import cache_service, cached
from .chart_service import chart_service
from .error_logger import error_logger
from .freqtrade_service import freqtrade_service
from .monitoring import monitoring_service
from .security import PathSecurity, load_security_config
from .security_middleware import SecurityHeadersMiddleware
from .tools import (
    AgentApplyParams,
    AgentRegisterParams,
    ATAReceiveParams,
    ATASendParams,
    ATASendRequestParams,
    ATASendReviewParams,
    ATASendWithFileParams,
    BoardSetStatusParams,
    ConversationHistoryParams,
    ConversationMarkParams,
    ConversationSearchParams,
    ConversationStatsParams,
    DialogListParams,
    DialogRegisterParams,
    EchoParams,
    FileReadParams,
    InboxAppendParams,
    InboxTailParams,
    ResultGetParams,
    TaskCreateParams,
    TaskStatusParams,
    ToolExecutor,
    WorkflowExecuteParams,
)
from .web_viewer_api import get_message_preview, load_all_ata_messages

# é…ç½®æ—¥å¿—ï¼ˆåœ¨å¯¼å…¥å…¶ä»–æ¨¡å—ä¹‹å‰ï¼‰
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

app = FastAPI(title="QCC Bus MCP Server", version="0.1.0")

# Dashboard configuration - now using deep integration
DASHBOARD_PORT = int(os.getenv("DASHBOARD_PORT", "8051"))
DASHBOARD_HOST = os.getenv("DASHBOARD_HOST", "127.0.0.1")
DASHBOARD_URL = f"http://{DASHBOARD_HOST}:{DASHBOARD_PORT}"

# Disable deep integration by default to avoid JSON serialization errors
DASHBOARD_DEEP_INTEGRATION = False

# Debug: Print deep integration status
logger.info(f"ğŸ“Š Dashboard deep integration status: {DASHBOARD_DEEP_INTEGRATION}")
logger.info(f"ğŸ“Š Environment variable: DASHBOARD_DEEP_INTEGRATION={os.getenv('DASHBOARD_DEEP_INTEGRATION')}")




def create_cached_file_response(file_path: Path, media_type: str = None) -> FileResponse:
    """åˆ›å»ºå¸¦æ°¸ä¹…ç¼“å­˜å¤´çš„æ–‡ä»¶å“åº”ï¼ˆæµè§ˆå™¨æ°¸ä¹…ç¼“å­˜ç›´åˆ°æ‰‹åŠ¨æ¸…é™¤ï¼‰"""
    headers = {
        "Cache-Control": "public, max-age=31536000, immutable",  # 1å¹´ï¼Œä¸å¯å˜ï¼Œæ°¸ä¹…ç¼“å­˜
        "X-Content-Type-Options": "nosniff",
    }
    return FileResponse(file_path, media_type=media_type, headers=headers)


def secrets_compare(a: str, b: str) -> bool:
    # constant-time-ish compare
    try:
        import hmac

        return hmac.compare_digest(a, b)
    except Exception:
        return a == b


def extract_admin_ctx(req: Request) -> dict[str, Any]:
    """
    Determine whether the caller is ATA admin (fail-closed for privileged ops).
    Sources:
    - Header: X-ATA-ADMIN-TOKEN must match env ATA_ADMIN_TOKEN
    - Cookie: auth_token (JWT issued by /api/auth/login) with role=admin
    """
    is_admin = False
    reason = "not_authenticated"
    expected = os.getenv("ATA_ADMIN_TOKEN")
    provided = req.headers.get("x-ata-admin-token")
    if expected and provided and secrets_compare(expected, provided):
        return {"is_admin": True, "method": "header", "reason": "ok"}

    token = req.cookies.get("auth_token")
    if token:
        payload = auth_service.verify_token(token)
        if payload and payload.get("role") == UserRole.ADMIN.value:
            return {"is_admin": True, "method": "cookie", "reason": "ok"}
        reason = "invalid_or_non_admin_jwt"
    return {"is_admin": is_admin, "method": None, "reason": reason}


# GZipå‹ç¼©ä¸­é—´ä»¶ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰- é™ä½é˜ˆå€¼ä»¥å‹ç¼©æ›´å¤šå†…å®¹
app.add_middleware(GZipMiddleware, minimum_size=500)  # 500å­—èŠ‚ä»¥ä¸Šå³å‹ç¼©

# å®‰å…¨å¤´ä¸­é—´ä»¶
app.add_middleware(SecurityHeadersMiddleware)

# CORS configuration - restrict to trusted origins
cors_origins = os.getenv(
    "CORS_ORIGINS",
    "http://localhost:8000,http://127.0.0.1:8000,http://localhost:3000,http://127.0.0.1:3000",
).split(",")
cors_origins = [origin.strip() for origin in cors_origins if origin.strip()]

app.add_middleware(
    CORSMiddleware,
    allow_origins=cors_origins,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["Authorization", "Content-Type", "X-Trace-ID", "User-Agent"],
)

# Optional: LangSmith tracing for API requests (non-blocking, best-effort).
LANGSMITH_MIDDLEWARE_ATTACHED = False
try:
    from tools.langsmith.fastapi_middleware import add_langsmith_middleware

    try:
        LANGSMITH_MIDDLEWARE_ATTACHED = add_langsmith_middleware(app)
        if LANGSMITH_MIDDLEWARE_ATTACHED:
            logger.info("[LangSmith] HTTP tracing enabled")
        else:
            logger.info("[LangSmith] HTTP tracing disabled (no valid config)")
    except Exception as e:
        logger.warning(f"[LangSmith] middleware init failed: {e}")
except Exception:
    logger.info("[LangSmith] integration not available (missing optional dependency)")

# A2A Hub integration - deep integration enabled by default
logger.info("ğŸ”„ Initializing A2A Hub deep integration...")
try:
    from .a2a_integration import configure_a2a_integration
    a2a_app = configure_a2a_integration(app)
    if a2a_app:
        logger.info("âœ… A2A Hub deep integration successful")
    else:
        logger.warning("âš ï¸ A2A Hub deep integration failed")
except Exception as e:
    logger.error(f"âŒ A2A Hub deep integration error: {e}", exc_info=True)

# Data access integration
logger.info("ğŸ”„ Initializing unified data access integration...")
try:
    from .data_access_integration import include_data_access_routes
    include_data_access_routes(app)
    logger.info("âœ… Unified data access integration successful")
except Exception as e:
    logger.error(f"âŒ Unified data access integration error: {e}", exc_info=True)

# Monitoring service integration
logger.info("ğŸ”„ Initializing monitoring service integration...")
try:
    from .monitoring_integration import init_monitoring_integration
    init_monitoring_integration(app)
    logger.info("âœ… Monitoring service integration successful")
except Exception as e:
    logger.error(f"âŒ Monitoring service integration error: {e}", exc_info=True)

# Tools integration
logger.info("ğŸ”„ Initializing tools script integration...")
try:
    from .tools_integration import include_tools_routes
    include_tools_routes(app)
    logger.info("âœ… Tools script integration successful")
except Exception as e:
    logger.error(f"âŒ Tools script integration error: {e}", exc_info=True)

# AWS Bridge integration (T2: AWS ç»Ÿä¸€å…¥å£æ¥å…¥)
logger.info("ğŸ”„ Initializing AWS Bridge integration...")
try:
    from .aws_api_gateway import router as aws_router
    app.include_router(aws_router)
    logger.info("âœ… AWS Bridge integration successful")
except Exception as e:
    logger.error(f"âŒ AWS Bridge integration error: {e}", exc_info=True)

security: PathSecurity | None = None
tool_executor: ToolExecutor | None = None
audit_logger: AuditLogger | None = None
config: dict[str, Any] = {}


class AgentSendRequest(BaseModel):
    """REST request body for sending an ATA message from an agent homepage."""

    to_agent: str | int
    taskcode: str
    message: str
    kind: str = "request"
    priority: str = "normal"
    requires_response: bool = True
    context_hint: str | None = None


class ChatSendRequest(BaseModel):
    """Web chat: user sends a message, server routes to an agent via ATA outbox."""

    message: str
    # Optional explicit target; when absent, server routes based on keywords/roles
    target_agent: str | None = None
    # Optional override; default will be generated
    taskcode: str | None = None
    # Optional notification mode
    notification_mode: str | None = "ata"


class NotificationSendRequest(BaseModel):
    """é€šçŸ¥å‘é€è¯·æ±‚"""

    title: str
    message: str
    mode: str = "all"  # ata/desktop/wecom/telegram/all


def _format_agent_code(numeric_code: int | None) -> str:
    """Format numeric code as 2-digit string, e.g. 1 -> '01'."""
    if numeric_code is None:
        return "--"
    try:
        return f"{int(numeric_code):02d}"
    except Exception:
        return "--"


def _display_name(agent_id: str, numeric_code: int | None) -> str:
    """Display name for ATA communications: åå­—#NN"""
    return f"{agent_id}#{_format_agent_code(numeric_code)}"


def get_repo_root() -> Path:
    """Get repository root path"""
    return Path(os.getenv("REPO_ROOT", "d:\\quantsys")).resolve()


REPO_ROOT = get_repo_root()


def get_config():
    return config


async def get_jwks_keys(issuer: str) -> dict[str, Any]:
    """Fetch JWKS keys from the issuer"""
    jwks_uri = f"{issuer}/.well-known/jwks.json"
    async with httpx.AsyncClient() as client:
        response = await client.get(jwks_uri, timeout=10.0)
        response.raise_for_status()
        return response.json()


async def verify_jwt(token: str) -> dict[str, Any]:
    """Verify OAuth JWT token"""
    issuer = os.getenv("OAUTH_ISSUER")
    client_id = os.getenv("OAUTH_CLIENT_ID")
    required_scopes = os.getenv("OAUTH_REQUIRED_SCOPES", "mcp.tools").split()

    if not issuer or not client_id:
        raise HTTPException(status_code=500, detail="OAuth not configured")

    try:
        # Get JWKS keys
        jwks = await get_jwks_keys(issuer)

        # Decode and verify token
        unverified_header = jwt.get_unverified_header(token)
        kid = unverified_header.get("kid")

        if not kid:
            raise HTTPException(status_code=403, detail="Invalid token: missing kid")

        # Find the key with matching kid
        rsa_key = {}
        for key in jwks.get("keys", []):
            if key.get("kid") == kid:
                rsa_key = {
                    "kty": key["kty"],
                    "kid": key["kid"],
                    "use": key["use"],
                    "n": key["n"],
                    "e": key["e"],
                }
                break

        if not rsa_key:
            raise HTTPException(status_code=403, detail="Invalid token: key not found")

        # Verify the token
        payload = jwt.decode(
            token, rsa_key, algorithms=["RS256"], audience=client_id, issuer=issuer
        )

        # Verify required scopes
        token_scopes = payload.get("scope", "").split()
        for scope in required_scopes:
            if scope not in token_scopes:
                raise HTTPException(status_code=403, detail=f"Missing required scope: {scope}")

        return payload

    except httpx.HTTPError as e:
        raise HTTPException(status_code=500, detail=f"Error fetching JWKS: {str(e)}")
    except JWTError as e:
        raise HTTPException(status_code=403, detail=f"Invalid token: {str(e)}")
    except Exception as e:
        raise HTTPException(status_code=403, detail=f"Token verification failed: {str(e)}")


async def verify_token(authorization: str | None = Header(None)):
    """éªŒè¯tokenï¼Œæ”¯æŒAUTH_MODE=noneæ¨¡å¼ï¼ˆæœ¬åœ°å¼€å‘ï¼‰"""
    # ä¼˜åŒ–ï¼šæœ¬åœ°å¼€å‘æ—¶é»˜è®¤ä½¿ç”¨noneæ¨¡å¼ï¼ˆ127.0.0.1æˆ–localhostï¼‰
    default_auth_mode = (
        "none" if os.getenv("MCP_BUS_HOST", "127.0.0.1") in ["127.0.0.1", "localhost"] else "oauth"
    )
    auth_mode = os.getenv("AUTH_MODE", default_auth_mode).lower()

    # AUTH_MODE=noneæ—¶å…è®¸æ— è®¤è¯è®¿é—®ï¼ˆä»…é™æœ¬åœ°å¼€å‘ï¼‰
    if auth_mode == "none":
        return {"mode": "none", "authenticated": False}

    resource_metadata_url = "https://mcp.timquant.tech/.well-known/oauth-protected-resource"
    required_scope = "mcp.tools"

    if not authorization:
        raise HTTPException(
            status_code=401,
            detail="Missing Authorization header",
            headers={
                "WWW-Authenticate": f'Bearer resource_metadata="{resource_metadata_url}", scope="{required_scope}"'
            },
        )

    if not authorization.startswith("Bearer "):
        raise HTTPException(
            status_code=401,
            detail="Invalid Authorization header format",
            headers={
                "WWW-Authenticate": f'Bearer resource_metadata="{resource_metadata_url}", scope="{required_scope}"'
            },
        )

    token = authorization[7:]

    if auth_mode == "oauth":
        try:
            # Use OAuth JWT validation
            return await verify_jwt(token)
        except HTTPException as e:
            # Add WWW-Authenticate header to all 401/403 responses
            if e.status_code in [401, 403]:
                e.headers = {
                    "WWW-Authenticate": f'Bearer resource_metadata="{resource_metadata_url}", scope="{required_scope}"'
                }
            raise e
    else:
        # Use legacy Bearer token validation
        expected_token = os.getenv("MCP_BUS_TOKEN")

        if not expected_token:
            raise HTTPException(
                status_code=500, detail="Server not configured: MCP_BUS_TOKEN not set"
            )

        if token != expected_token:
            raise HTTPException(
                status_code=403,
                detail="Invalid token",
                headers={
                    "WWW-Authenticate": f'Bearer resource_metadata="{resource_metadata_url}", scope="{required_scope}"'
                },
            )

        return token


def get_caller(request: Request) -> str:
    user_agent = request.headers.get("user-agent", "unknown")
    if "ChatGPT" in user_agent:
        return "ChatGPT"
    elif "TRAE" in user_agent:
        return "TRAE"
    return user_agent[:50]


def get_tool_executor() -> ToolExecutor:
    """è·å–å…¨å±€tool_executorå®ä¾‹"""
    if tool_executor is None:
        raise RuntimeError("ToolExecutor not initialized. Server may not have started yet.")
    return tool_executor


def _resolve_agent_ref(executor: ToolExecutor, agent_ref: str) -> str:
    """
    Resolve agent_ref to agent_id.
    agent_ref supports:
    - numeric code: "1".."100"
    - agent_id: e.g. "ATAç³»ç»Ÿ"
    """
    if not executor.coordinator:
        raise HTTPException(status_code=503, detail="AgentCoordinator not available")

    ref = (agent_ref or "").strip()
    if not ref:
        raise HTTPException(status_code=400, detail="agent_ref is required")

    # numeric_code
    if ref.isdigit():
        code = int(ref)
        if not (1 <= code <= 100):
            raise HTTPException(status_code=400, detail="numeric_code must be in range 1..100")
        agent = executor.coordinator.registry.get_agent_by_code(code)
        if not agent:
            raise HTTPException(status_code=404, detail=f"Agent not found for numeric_code={code}")
        return agent.agent_id

    # agent_id
    agent = executor.coordinator.registry.get_agent(ref)
    if not agent:
        raise HTTPException(status_code=404, detail=f"Agent not found: {ref}")
    return agent.agent_id




# A2A Hub configuration (Flask service, proxied under MCP Bus)
A2A_HUB_HOST = os.getenv("A2A_HUB_HOST", "127.0.0.1")
A2A_HUB_PORT = int(os.getenv("A2A_HUB_PORT", "5001"))
A2A_HUB_URL = f"http://{A2A_HUB_HOST}:{A2A_HUB_PORT}"
A2A_HUB_ENABLED = os.getenv("A2A_HUB_ENABLED", "false").lower() == "true"

_SERVICE_MAP: dict[str, dict[str, str]] = {}
_SERVICE_START_MAP: dict[str, dict[str, Any]] = {}
_service_processes: dict[str, subprocess.Popen] = {}


def _load_service_map() -> dict[str, dict[str, str]]:
    mapping: dict[str, dict[str, str]] = {}
    raw = os.getenv("MCP_SERVICE_MAP", "").strip()
    if raw:
        try:
            parsed = json.loads(raw)
            if isinstance(parsed, dict):
                for name, info in parsed.items():
                    if isinstance(info, dict) and "url" in info:
                        mapping[str(name)] = {
                            "url": str(info.get("url", "")),
                            "health": str(info.get("health", "")),
                        }
        except Exception:
            logger.warning("Failed to parse MCP_SERVICE_MAP JSON; ignoring")

    # Built-in defaults for common local services
    mapping.setdefault(
        "a2a",
        {"url": A2A_HUB_URL, "health": "/api/health"},
    )
    mapping.setdefault(
        "dashboard",
        {"url": DASHBOARD_URL, "health": "/"},
    )
    mapping.setdefault(
        "langgraph",
        {"url": "http://127.0.0.1:2024", "health": "/docs"},
    )
    mapping.setdefault(
        "freqtrade",
        {"url": os.getenv("FREQTRADE_API_URL", "http://127.0.0.1:8080"), "health": ""},
    )
    return mapping


_SERVICE_MAP = _load_service_map()


def _load_service_start_map() -> dict[str, dict[str, Any]]:
    mapping: dict[str, dict[str, Any]] = {}
    raw = os.getenv("MCP_SERVICE_START_MAP", "").strip()
    if raw:
        try:
            parsed = json.loads(raw)
            if isinstance(parsed, dict):
                for name, info in parsed.items():
                    if isinstance(info, dict):
                        mapping[str(name)] = info
        except Exception:
            logger.warning("Failed to parse MCP_SERVICE_START_MAP JSON; ignoring")

    # Default: allow A2A to be started by manager if enabled.
    mapping.setdefault(
        "a2a",
        {
            "args": [sys.executable, "tools/a2a_hub/main.py"],
            "cwd": str(get_repo_root()),
        },
    )
    return mapping


_SERVICE_START_MAP = _load_service_start_map()

# ä¼˜åŒ–ï¼šåˆ›å»ºHTTPè¿æ¥æ± ï¼Œå¤ç”¨è¿æ¥ä»¥æé«˜æ€§èƒ½
_dashboard_client: httpx.AsyncClient | None = None
_freqtrade_client: httpx.AsyncClient | None = None
_a2a_client: httpx.AsyncClient | None = None
_a2a_process: subprocess.Popen | None = None
_service_clients: dict[str, httpx.AsyncClient] = {}


def get_dashboard_client() -> httpx.AsyncClient:
    """è·å–Dashboard HTTPå®¢æˆ·ç«¯ï¼ˆè¿æ¥æ± å¤ç”¨ï¼‰"""
    global _dashboard_client
    if _dashboard_client is None:
        _dashboard_client = httpx.AsyncClient(
            base_url=DASHBOARD_URL,
            timeout=httpx.Timeout(10.0, connect=3.0),  # è¿æ¥è¶…æ—¶3ç§’ï¼Œæ€»è¶…æ—¶10ç§’
            limits=httpx.Limits(max_keepalive_connections=10, max_connections=20),
            follow_redirects=True,
        )
    return _dashboard_client


def get_freqtrade_client() -> httpx.AsyncClient:
    """è·å–Freqtrade API HTTPå®¢æˆ·ç«¯ï¼ˆè¿æ¥æ± å¤ç”¨ï¼‰"""
    global _freqtrade_client
    if _freqtrade_client is None:
        frequi_dist_dir = get_repo_root() / "frequi-main" / "dist"
        frequi_dist_dir = get_repo_root() / "frequi-main" / "dist"
        freqtrade_api_url = os.getenv("FREQTRADE_API_URL", "http://127.0.0.1:8080")
        _freqtrade_client = httpx.AsyncClient(
            base_url=freqtrade_api_url,
            timeout=httpx.Timeout(10.0, connect=2.0),  # è¿æ¥è¶…æ—¶2ç§’ï¼Œæ€»è¶…æ—¶10ç§’
            limits=httpx.Limits(max_keepalive_connections=10, max_connections=20),
            follow_redirects=True,
        )
    return _freqtrade_client


def get_a2a_client() -> httpx.AsyncClient:
    global _a2a_client
    if _a2a_client is None:
        _a2a_client = httpx.AsyncClient(
            base_url=A2A_HUB_URL,
            timeout=httpx.Timeout(10.0, connect=2.0),
            limits=httpx.Limits(max_keepalive_connections=10, max_connections=20),
        )
    return _a2a_client


def get_service_client(service: str) -> httpx.AsyncClient:
    client = _service_clients.get(service)
    if client is None:
        base_url = _SERVICE_MAP[service]["url"]
        client = httpx.AsyncClient(
            base_url=base_url,
            timeout=httpx.Timeout(10.0, connect=2.0),
            limits=httpx.Limits(max_keepalive_connections=10, max_connections=20),
            follow_redirects=True,
        )
        _service_clients[service] = client
    return client


def _check_service_health(service: str) -> bool | None:
    info = _SERVICE_MAP.get(service)
    if not info:
        return None
    health_path = info.get("health", "")
    if not health_path:
        return None
    try:
        resp = httpx.get(f"{info['url']}{health_path}", timeout=2)
        return resp.status_code >= 200 and resp.status_code < 500
    except Exception:
        return False


def _start_managed_service(service: str) -> bool:
    config = _SERVICE_START_MAP.get(service)
    if not config:
        return False

    svc_type = str(config.get("type") or "")
    if svc_type == "freqtrade":
        ok, _msg = freqtrade_service.start_webserver()
        return ok
    if svc_type == "dashboard":
        start_dashboard_background()
        return True

    proc = _service_processes.get(service)
    if proc and proc.poll() is None:
        return True

    healthy = _check_service_health(service)
    if healthy:
        return True

    args = config.get("args")
    cmd = config.get("cmd")
    if not args and not cmd:
        return False

    cwd = config.get("cwd") or str(get_repo_root())
    env = os.environ.copy()
    env.update(config.get("env", {}))

    try:
        if args:
            proc = subprocess.Popen(
                args,
                cwd=cwd,
                env=env,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                creationflags=subprocess.CREATE_NO_WINDOW if sys.platform == "win32" else 0,
            )
        else:
            proc = subprocess.Popen(
                cmd,
                cwd=cwd,
                env=env,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                shell=True,
                creationflags=subprocess.CREATE_NO_WINDOW if sys.platform == "win32" else 0,
            )
        _service_processes[service] = proc
        return True
    except Exception as exc:
        logger.error(f"Failed to start service {service}: {exc}")
        return False


def _stop_managed_service(service: str) -> bool:
    proc = _service_processes.get(service)
    if not proc:
        return False
    if proc.poll() is None:
        proc.terminate()
        return True
    return False


def start_dashboard_background():
    """Start Dashboard as background process"""
    import subprocess
    import sys
    import threading

    repo_root = get_repo_root()
    
    # Check both possible locations for the Dashboard script
    possible_paths = [
        repo_root / "isolated_observatory" / "scripts" / "dashboard" / "app.py",  # æ–°ä½ç½®
        repo_root / "scripts" / "dashboard" / "app.py"  # æ—§ä½ç½®ï¼ˆå…¼å®¹ï¼‰
    ]
    
    dashboard_script = None
    for path in possible_paths:
        if path.exists() and path.is_file():
            dashboard_script = path
            break
    
    if not dashboard_script:
        print(f"Warning: Dashboard script not found in any of the expected locations")
        return None

    def run_dashboard():
        try:
            # Start Dashboard in background (non-blocking)
            subprocess.Popen(
                [sys.executable, str(dashboard_script)],
                cwd=str(repo_root),
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                creationflags=subprocess.CREATE_NO_WINDOW if sys.platform == "win32" else 0,
            )
        except Exception as e:
            print(f"Error starting Dashboard: {e}")

    # Start Dashboard in background thread
    dashboard_thread = threading.Thread(target=run_dashboard, daemon=True)
    dashboard_thread.start()

    # ä¼˜åŒ–ï¼šä¸é˜»å¡ä¸»çº¿ç¨‹ï¼ŒDashboardå¯åŠ¨æ£€æŸ¥æ”¹ä¸ºå¼‚æ­¥åå°ä»»åŠ¡
    # åŸæ¥çš„5ç§’é˜»å¡å¯¼è‡´å¯åŠ¨å¤ªæ…¢ï¼Œç°åœ¨æ”¹ä¸ºå®Œå…¨å¼‚æ­¥
    def check_dashboard_async():
        import time
        import httpx
        # å»¶è¿Ÿ1ç§’åæ£€æŸ¥ï¼ˆç»™Dashboardä¸€äº›å¯åŠ¨æ—¶é—´ï¼‰
        time.sleep(1.0)
        try:
            response = httpx.get(f"{DASHBOARD_URL}/", timeout=2)
            if response.status_code == 200:
                print(f"[OK] Dashboard started successfully on {DASHBOARD_URL}")
            else:
                print(f"[WARN] Dashboard responded with status {response.status_code}")
        except Exception as e:
            print(f"[WARN] Dashboard may not be running yet, will retry on first request: {e}")
    
    # åœ¨åå°çº¿ç¨‹ä¸­æ£€æŸ¥ï¼Œä¸é˜»å¡ä¸»çº¿ç¨‹
    check_thread = threading.Thread(target=check_dashboard_async, daemon=True)
    check_thread.start()

    return dashboard_thread


def _check_a2a_health() -> bool:
    try:
        resp = httpx.get(f"{A2A_HUB_URL}/api/health", timeout=2)
        return resp.status_code == 200
    except Exception:
        return False


def start_a2a_background():
    """Start A2A Hub as background process (best-effort)."""
    global _a2a_process
    if _check_a2a_health():
        logger.info("A2A Hub already running; skip start")
        return

    repo_root = get_repo_root()
    a2a_script = repo_root / "tools" / "a2a_hub" / "main.py"
    if not a2a_script.exists():
        logger.warning("A2A Hub script not found; skip start")
        return

    try:
        _a2a_process = subprocess.Popen(
            [sys.executable, str(a2a_script)],
            cwd=str(a2a_script.parent),
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            creationflags=subprocess.CREATE_NO_WINDOW if sys.platform == "win32" else 0,
        )
    except Exception as exc:
        logger.error(f"Failed to start A2A Hub: {exc}")
        return

    def _wait_ready():
        for _ in range(20):
            if _check_a2a_health():
                logger.info("A2A Hub started successfully")
                return
            time.sleep(0.5)
        logger.warning("A2A Hub start timed out")

    thread = threading.Thread(target=_wait_ready, daemon=True)
    thread.start()


# å…¨å±€æ ‡å¿—ï¼Œé˜²æ­¢é‡å¤å¯åŠ¨
_freqtrade_startup_task_running = False


async def _start_freqtrade_with_retry(max_retries: int = 5, retry_delay: float = 2.0):
    """å¯é å¯åŠ¨Freqtradeï¼Œç¡®ä¿100%æˆåŠŸç‡ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
    global _freqtrade_startup_task_running

    auto_start_env = os.getenv("AUTO_START_FREQTRADE", "false").lower()
    auto_start_freqtrade = auto_start_env == "true"

    if not auto_start_freqtrade:
        logger.info("Freqtrade auto-start is disabled (AUTO_START_FREQTRADE=false)")
        return False

    # ä¼˜åŒ–ï¼šå®Œå…¨ç§»é™¤å»¶è¿Ÿï¼Œç«‹å³å¯åŠ¨ï¼ˆæœ€å¿«é€Ÿåº¦ï¼‰
    # ä¸å†ç­‰å¾…ï¼Œç«‹å³å¯åŠ¨Freqtradeä»¥æœ€å¿«é€Ÿåº¦åŠ è½½
    # await asyncio.sleep(0.5)  # ç§»é™¤å»¶è¿Ÿ

    logger.info("Auto-starting Freqtrade WebServer (immediate start, no delay)...")

    # ä¼˜åŒ–ï¼šæ£€æŸ¥æ˜¯å¦å·²ç»åœ¨è¿è¡Œï¼ˆé¿å…é‡å¤å¯åŠ¨ï¼‰
    current_status = freqtrade_service.get_status()
    if current_status["webserver"]["running"]:
        pid = current_status.get("webserver", {}).get("pid", "unknown")
        logger.info(f"âœ… Freqtrade WebServer is already running (PID: {pid}), skipping startup")
        _freqtrade_startup_task_running = False
        return True

    # ä¼˜åŒ–ï¼šè®¾ç½®è¿è¡Œæ ‡å¿—ï¼Œé˜²æ­¢é‡å¤å¯åŠ¨
    _freqtrade_startup_task_running = True

    # é‡è¯•æœºåˆ¶ï¼šç¡®ä¿100%æˆåŠŸç‡ï¼ˆä»…åœ¨æœªå¯åŠ¨æ—¶é‡è¯•ï¼‰
    for attempt in range(1, max_retries + 1):
        try:
            # ä¼˜åŒ–ï¼šæ¯æ¬¡é‡è¯•å‰å†æ¬¡æ£€æŸ¥æ˜¯å¦å·²ç»å¯åŠ¨ï¼ˆå¯èƒ½è¢«å…¶ä»–è¿›ç¨‹å¯åŠ¨ï¼‰
            check_status = freqtrade_service.get_status()
            if check_status["webserver"]["running"]:
                pid = check_status.get("webserver", {}).get("pid", "unknown")
                logger.info(
                    f"âœ… Freqtrade WebServer is now running (PID: {pid}), detected before attempt {attempt}"
                )
                _freqtrade_startup_task_running = False
                return True

            logger.info(f"Starting Freqtrade WebServer (attempt {attempt}/{max_retries}, immediate start)...")
            # è®°å½•å¯åŠ¨å¼€å§‹æ—¶é—´
            start_attempt_time = time.time()
            
            # ä¼˜åŒ–ï¼šä½¿ç”¨åŒæ­¥å¯åŠ¨ï¼Œä¸ç­‰å¾…éªŒè¯ï¼ˆæœ€å¿«é€Ÿåº¦ï¼‰
            success, message = freqtrade_service.start_webserver()
            
            # è®°å½•å¯åŠ¨è€—æ—¶
            start_duration = (time.time() - start_attempt_time) * 1000
            logger.info(f"[Performance] Freqtrade start_webserver() took {start_duration:.0f}ms")

            if success:
                # ä¼˜åŒ–ï¼šæœ€æ¿€è¿› - è¿›ç¨‹å¯åŠ¨åç«‹å³è¿”å›æˆåŠŸï¼Œä¸ç­‰å¾…ä»»ä½•éªŒè¯
                # è¿›ç¨‹å¯åŠ¨æˆåŠŸå³è®¤ä¸º"å°±ç»ª"ï¼ŒAPIå®Œå…¨å°±ç»ªæ˜¯åç»­å¼‚æ­¥æ£€æŸ¥
                # è·å–PIDï¼ˆé€šè¿‡get_statusæˆ–ç›´æ¥è®¿é—®ï¼‰
                try:
                    status = freqtrade_service.get_status()
                    pid = status.get("webserver", {}).get("pid", "unknown")
                except:
                    pid = "unknown"
                logger.info(
                    f"âœ… Freqtrade WebServer process started (PID: {pid}), API will be ready shortly (startup took {start_duration:.0f}ms)"
                )
                _freqtrade_startup_task_running = False
                return True
                # ç§»é™¤æ‰€æœ‰ç­‰å¾…å’ŒéªŒè¯ï¼Œç«‹å³è¿”å›æˆåŠŸ
            else:
                logger.warning(f"âš ï¸ Attempt {attempt}/{max_retries} failed: {message}")

            # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…åé‡è¯•
            if attempt < max_retries:
                logger.info(f"Retrying in {retry_delay:.1f} seconds...")
                await asyncio.sleep(retry_delay)
                retry_delay *= 1.5  # æŒ‡æ•°é€€é¿

        except Exception as e:
            logger.error(f"âŒ Exception on attempt {attempt}/{max_retries}: {e}", exc_info=True)
            if attempt < max_retries:
                await asyncio.sleep(retry_delay)
                retry_delay *= 1.5

    # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
    _freqtrade_startup_task_running = False
    logger.error(f"âŒ Failed to start Freqtrade WebServer after {max_retries} attempts")
    logger.info("You can manually start it via: POST /api/freqtrade/webserver/start")
    return False


async def _start_freqtrade_async():
    """å¼‚æ­¥å¯åŠ¨Freqtradeï¼Œä¸æ€»æœåŠ¡å™¨åŒæ­¥å¯åŠ¨ä½†ä¸é˜»å¡ä¸»è¿›ç¨‹ï¼ˆä½¿ç”¨å¯é å¯åŠ¨æœºåˆ¶ï¼‰"""
    global _freqtrade_startup_task_running
    logger.info("ğŸ”µ _start_freqtrade_async() called - starting Freqtrade startup task")
    
    # ä¼˜åŒ–ï¼šé˜²æ­¢é‡å¤å¯åŠ¨ä»»åŠ¡
    if _freqtrade_startup_task_running:
        logger.warning("âš ï¸ Freqtrade startup task is already running, skipping duplicate call")
        return
    
    logger.info("ğŸš€ Calling _start_freqtrade_with_retry()...")
    try:
        result = await _start_freqtrade_with_retry(max_retries=5, retry_delay=2.0)
        logger.info(f"âœ… _start_freqtrade_with_retry() completed with result: {result}")
    except Exception as e:
        logger.error(f"âŒ Exception in _start_freqtrade_async(): {e}", exc_info=True)
        raise


@app.on_event("startup")
async def startup_event():
    """FastAPIå¯åŠ¨äº‹ä»¶ - åˆå§‹åŒ–æ‰€æœ‰æœåŠ¡"""
    logger.info("=" * 60)
    logger.info("ğŸš€ FastAPI Startup Event - Starting all services")
    logger.info("=" * 60)
    
    # è‡ªåŠ¨å¯åŠ¨Freqtrade WebServerï¼ˆå¦‚æœå¯ç”¨ï¼‰
    # é»˜è®¤ç¦ç”¨è‡ªå¯ï¼Œä½†æä¾›å¯é çš„å¯åŠ¨æœºåˆ¶ç¡®ä¿100%æˆåŠŸç‡
    # å¦‚æœéœ€è¦ä¸æ€»æœåŠ¡å™¨åŒæ­¥å¯åŠ¨ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡ AUTO_START_FREQTRADE=true
    auto_start_env = os.getenv("AUTO_START_FREQTRADE", "false").lower()
    auto_start_freqtrade = auto_start_env == "true"

    # è¯¦ç»†æ—¥å¿—è¾“å‡º
    env_value = os.getenv("AUTO_START_FREQTRADE", "false")
    logger.info("=" * 60)
    logger.info("Freqtrade Auto-Start Check")
    logger.info("=" * 60)
    logger.info(f"AUTO_START_FREQTRADE environment variable: {env_value}")
    logger.info(f"Auto-start enabled: {auto_start_freqtrade}")
    logger.info("=" * 60)

    # å¦‚æœå¯ç”¨è‡ªåŠ¨å¯åŠ¨ï¼Œä½¿ç”¨å¯é å¯åŠ¨æœºåˆ¶ï¼ˆé‡è¯•+éªŒè¯ï¼‰ç¡®ä¿100%æˆåŠŸç‡
    if auto_start_freqtrade:
        # ä¼˜åŒ–ï¼šå…ˆæ£€æŸ¥æ˜¯å¦å·²ç»è¿è¡Œï¼Œé¿å…ä¸å¿…è¦çš„å¯åŠ¨ä»»åŠ¡
        logger.info("Checking current Freqtrade status...")
        current_status = freqtrade_service.get_status()
        logger.info(f"Current status: {current_status}")
        
        # æ£€æŸ¥æ˜¯å¦ç”±æˆ‘ä»¬ç®¡ç†çš„è¿›ç¨‹åœ¨è¿è¡Œ
        webserver_running = current_status["webserver"]["running"]
        managed_process = freqtrade_service.webserver_proc is not None
        
        if webserver_running and managed_process:
            # ç”±æˆ‘ä»¬ç®¡ç†çš„è¿›ç¨‹åœ¨è¿è¡Œï¼Œè·³è¿‡å¯åŠ¨
            pid = current_status.get("webserver", {}).get("pid", "unknown")
            logger.info(
                f"âœ… Freqtrade WebServer is already running (managed, PID: {pid}), skipping auto-start"
            )
        elif webserver_running and not managed_process:
            # å¤–éƒ¨è¿›ç¨‹åœ¨è¿è¡Œï¼Œè®°å½•ä½†ä¸å¯åŠ¨ï¼ˆé¿å…å†²çªï¼‰
            pid = current_status.get("webserver", {}).get("pid", "unknown")
            logger.info(
                f"âš ï¸ External Freqtrade WebServer detected (PID: {pid}), skipping auto-start to avoid conflict"
            )
            logger.info("If you want to manage it, stop the external process first")
        else:
            # ä¼˜åŒ–ï¼šç«‹å³å¯åŠ¨Freqtradeï¼Œä¸å»¶è¿Ÿï¼ˆæœ€å¿«é€Ÿåº¦ï¼‰
            # åˆ›å»ºåå°ä»»åŠ¡ï¼Œç«‹å³å¯åŠ¨ï¼Œä¸é˜»å¡ä¸»è¿›ç¨‹
            logger.info("Creating async task to start Freqtrade...")
            task = asyncio.create_task(_start_freqtrade_async())
            logger.info(f"âœ… Async task created: {task}")
            logger.info(
                "Freqtrade will start immediately with server (async, non-blocking, immediate start)"
            )
            # ç¡®ä¿ä»»åŠ¡è¢«è°ƒåº¦ï¼ˆç»™äº‹ä»¶å¾ªç¯ä¸€ä¸ªæœºä¼šï¼‰
            await asyncio.sleep(0)  # è®©å‡ºæ§åˆ¶æƒï¼Œç¡®ä¿ä»»åŠ¡è¢«è°ƒåº¦
            logger.info("Task should be scheduled now")
    else:
        logger.info("Freqtrade auto-start is disabled (AUTO_START_FREQTRADE=false or not set)")

    # æ›´æ–°FREQTRADE_API_URLç¯å¢ƒå˜é‡ï¼ˆå¦‚æœfreqtradeåœ¨æœ¬åœ°å¯åŠ¨ï¼‰
    if freqtrade_service.get_status()["webserver"]["running"]:
        os.environ["FREQTRADE_API_URL"] = freqtrade_service.api_url
        logger.info(f"Freqtrade API URL set to: {freqtrade_service.api_url}")
    global security, tool_executor, audit_logger, config

    # ä¼˜åŒ–ï¼šé…ç½®æ–‡ä»¶è¯»å–ä¿æŒåŒæ­¥ï¼ˆé€šå¸¸å¾ˆå¿«ï¼Œä¸ä¼šé˜»å¡å¤ªä¹…ï¼‰
    # ä½†å¦‚æœé…ç½®æ–‡ä»¶å¾ˆå¤§ï¼Œå¯ä»¥è€ƒè™‘å»¶è¿ŸåŠ è½½éå…³é”®é…ç½®
    repo_root = os.getenv("REPO_ROOT", os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    config_path = os.path.join(os.path.dirname(__file__), "..", "config", "config.example.json")

    # å¿«é€Ÿè¯»å–é…ç½®æ–‡ä»¶ï¼ˆé€šå¸¸å¾ˆå¿«ï¼Œä¸ä¼šé˜»å¡ï¼‰
    with open(config_path) as f:
        config = json.load(f)

    paths_config = config.get("paths", {})
    security_config = load_security_config(config_path, repo_root)

    security = PathSecurity(security_config, repo_root)
    audit_logger = AuditLogger(paths_config.get("log_dir", "docs/LOG/mcp_bus"), repo_root)
    tool_executor = ToolExecutor(
        repo_root=repo_root,
        inbox_dir=paths_config.get("inbox_dir", "docs/REPORT/inbox"),
        board_file=paths_config.get("board_file", "docs/REPORT/QCC-PROGRAM-BOARD-v0.1.md"),
        security=security,
        audit_logger=audit_logger,
    )

    # Start Dashboard in background if enabled
    # Legacy Dash dashboard is being phased out in favor of UI-TARS native pages.
    # Keep it opt-in to avoid spawning a broken placeholder process on fresh installs.
    # ä¼˜åŒ–ï¼šDashboardå»¶è¿Ÿå¯åŠ¨ï¼ˆéå…³é”®æœåŠ¡ï¼Œå»¶è¿Ÿ3ç§’ï¼‰
    dashboard_enabled = os.getenv("DASHBOARD_ENABLED", "false").lower() == "true"
    if dashboard_enabled:
        # åœ¨åå°ä»»åŠ¡ä¸­å»¶è¿Ÿå¯åŠ¨Dashboardï¼Œä¸é˜»å¡startupäº‹ä»¶
        async def start_dashboard_async():
            await asyncio.sleep(3.0)  # å»¶è¿Ÿ3ç§’ï¼Œç¡®ä¿æ ¸å¿ƒæœåŠ¡å…ˆå¯åŠ¨å®Œæˆ
            print("Starting Dashboard in background (delayed)...")
            start_dashboard_background()
        asyncio.create_task(start_dashboard_async())

    # Start A2A Hub in background if enabled (proxy under MCP Bus)
    if A2A_HUB_ENABLED:
        auto_start_a2a = os.getenv("A2A_HUB_AUTO_START", "true").lower() == "true"
        if auto_start_a2a:
            logger.info("Starting A2A Hub in background...")
            _start_managed_service("a2a")
        else:
            logger.info("A2A Hub auto-start disabled (A2A_HUB_AUTO_START=false)")

    # Generic managed services (if enabled)
    if os.getenv("MCP_SERVICE_AUTO_START", "false").lower() == "true":
        for name in _SERVICE_START_MAP.keys():
            if name == "a2a" and not A2A_HUB_ENABLED:
                continue
            _start_managed_service(name)

    # ä¼˜åŒ–ï¼šMonitoringæœåŠ¡å»¶è¿Ÿå¯åŠ¨ï¼ˆéå…³é”®æœåŠ¡ï¼‰
    # Start monitoring service in background after a delay (non-critical service)
    async def start_monitoring_async():
        await asyncio.sleep(2.0)  # å»¶è¿Ÿ2ç§’å¯åŠ¨ï¼Œä¼˜å…ˆè®©æ ¸å¿ƒæœåŠ¡å…ˆå¯åŠ¨
        monitoring_service.start()
        logger.info("Monitoring service started (delayed)")
    asyncio.create_task(start_monitoring_async())

    # OKX APIåˆå§‹æ£€æŸ¥ï¼ˆéªŒè¯å‡­è¯é…ç½®ï¼Œä¸é˜»å¡å¯åŠ¨ï¼‰
    async def _check_okx_credentials():
        """æ£€æŸ¥OKX APIå‡­è¯é…ç½®ï¼ˆåå°ä»»åŠ¡ï¼Œä¸é˜»å¡å¯åŠ¨ï¼‰"""
        await asyncio.sleep(5)  # å»¶è¿Ÿ5ç§’ï¼Œç¡®ä¿å…¶ä»–æœåŠ¡å…ˆå¯åŠ¨
        try:
            repo_root = get_repo_root()
            candidates = [
                repo_root / "user_data" / "configs" / "freqtrade_live_config.json",
                repo_root / "user_data" / "config.json",
                repo_root / "configs" / "config_live.json",
                repo_root / "configs" / "config.json",
            ]

            cfg_path = next((p for p in candidates if p.exists()), None)
            cfg: dict[str, Any] = {}
            if cfg_path:
                try:
                    cfg = json.loads(cfg_path.read_text(encoding="utf-8"))
                except Exception as exc:
                    logger.warning(f"Failed to parse config at {cfg_path}: {exc}")
                    cfg = {}

            exchange = cfg.get("exchange", {}) if isinstance(cfg, dict) else {}

            def _expand_env(value: Any) -> str:
                if not isinstance(value, str):
                    return ""
                text = value.strip()
                if not text:
                    return ""
                if text.startswith("$"):
                    key = text[1:].strip("{}")
                    return os.getenv(key, "")
                return text

            key = _expand_env(exchange.get("key", ""))
            secret = _expand_env(exchange.get("secret", ""))
            passphrase = _expand_env(exchange.get("password", ""))

            missing = [name for name, v in [("key", key), ("secret", secret), ("passphrase", passphrase)] if not v]
            if missing:
                logger.warning(f"âš ï¸ OKX API credentials missing: {', '.join(missing)}")
                logger.info("OKX API will work in read-only mode (public endpoints only)")
            else:
                logger.info("âœ… OKX API credentials present (not validated)")
        except Exception as e:
            logger.warning(f"âš ï¸ OKX API check task error: {e}")

    # åˆ›å»ºåå°ä»»åŠ¡æ£€æŸ¥OKXå‡­è¯ï¼ˆä¸é˜»å¡å¯åŠ¨ï¼‰
    asyncio.create_task(_check_okx_credentials())
    logger.info("OKX API credentials check scheduled (background task)")


@app.on_event("shutdown")
async def shutdown_event():
    # åœæ­¢FreqtradeæœåŠ¡
    logger.info("Stopping Freqtrade services...")
    freqtrade_service.stop_webserver()
    freqtrade_service.stop_trade()
    logger.info("Freqtrade services stopped")
    """Shutdown event handler"""
    # Stop monitoring service
    monitoring_service.stop()
    logger.info("Monitoring service stopped")
    # ä¼˜åŒ–ï¼šå…³é—­HTTPè¿æ¥æ± 
    global _dashboard_client, _freqtrade_client
    if _dashboard_client:
        await _dashboard_client.aclose()
        _dashboard_client = None
    if _freqtrade_client:
        await _freqtrade_client.aclose()
        _freqtrade_client = None


class MCPRequest(BaseModel):
    jsonrpc: str = "2.0"
    id: str | int | None | None = None
    method: str
    params: dict[str, Any] | None = None


class MCPToolCall(BaseModel):
    name: str
    arguments: dict[str, Any]


@app.get("/favicon.ico")
async def favicon():
    """Handle favicon.ico request - return favicon file if exists (with permanent caching)"""
    favicon_path = Path(__file__).parent.parent / "web_viewer" / "favicon.ico"
    if favicon_path.exists():
        return create_cached_file_response(favicon_path, media_type="image/x-icon")
    # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å› 204 No Content é¿å… 404 æ—¥å¿—
    return Response(status_code=204)


@app.get("/")
async def root(request: Request):
    """Root endpoint - serve unified dashboard (optimized for speed)"""
    # æ£€æŸ¥è®¤è¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰- é»˜è®¤å…³é—­ï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡å¯ç”¨
    auth_enabled = os.getenv("AUTH_ENABLED", "false").lower() == "true"

    if auth_enabled:
        authorization = request.headers.get("authorization")
        token = None

        if authorization and authorization.startswith("Bearer "):
            token = authorization[7:]
        else:
            # æ£€æŸ¥cookieä¸­çš„token
            token = request.cookies.get("auth_token")

        if token:
            payload = auth_service.verify_token(token)
            if not payload:
                # Tokenæ— æ•ˆï¼Œæ¸…é™¤cookieå¹¶é‡å®šå‘
                response = RedirectResponse(url="/login")
                response.delete_cookie("auth_token")
                return response
        else:
            # æ²¡æœ‰tokenï¼Œé‡å®šå‘åˆ°ç™»å½•é¡µ
            return RedirectResponse(url="/login")

    dashboard_html = Path(__file__).parent.parent / "web_viewer" / "dashboard.html"
    if dashboard_html.exists():
        # æ°¸ä¹…ç¼“å­˜ï¼ˆç›´åˆ°æ‰‹åŠ¨æ¸…é™¤ï¼‰
        return create_cached_file_response(dashboard_html)
    # Fallback to viewer if dashboard doesn't exist
    viewer_html = Path(__file__).parent.parent / "web_viewer" / "index.html"
    if viewer_html.exists():
        return create_cached_file_response(viewer_html)
    return {
        "name": "QCC Bus MCP Server",
        "version": "0.1.0",
        "status": "running",
        "dashboard": "/",
        "web_viewer": "/viewer",
        "frequi": "/frequi",
        "mcp": "/mcp",
        "health": "/health",
    }


@app.get("/login")
async def login_page():
    """ç™»å½•é¡µé¢"""
    login_html = Path(__file__).parent.parent / "web_viewer" / "login.html"
    if login_html.exists():
        return create_cached_file_response(login_html)
    return HTMLResponse("<h1>Login Page Not Found</h1><p>login.html not found</p>")


@app.get("/viewer")
async def viewer():
    """ATA Messages Web Viewer"""
    viewer_html = Path(__file__).parent.parent / "web_viewer" / "index.html"
    if viewer_html.exists():
        return create_cached_file_response(viewer_html)
    return HTMLResponse("<h1>Web Viewer Not Found</h1><p>index.html not found</p>")


@app.api_route(
    "/dashboard/{path:path}", methods=["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS"]
)
async def dashboard_proxy(path: str, request: Request):
    """Proxy Dashboard requests to Dash app (optimized for speed with connection pooling)"""
    # Debug: Log deep integration status for every request
    logger.info(f"ğŸ“Š Request to /dashboard/{path}")
    logger.info(f"ğŸ“Š DASHBOARD_DEEP_INTEGRATION value: {DASHBOARD_DEEP_INTEGRATION}")
    logger.info(f"ğŸ“Š Environment variable: DASHBOARD_DEEP_INTEGRATION={os.getenv('DASHBOARD_DEEP_INTEGRATION')}")
    
    # Deep integration requests are handled automatically by WSGIMiddleware
    # FastAPI will forward these requests to the mounted Dash app
    if DASHBOARD_DEEP_INTEGRATION:
        # In deep integration mode, this route should never be called directly
        # because WSGIMiddleware handles /dashboard path directly
        # This is just a fallback to ensure proper error handling
        logger.warning(f"Dashboard proxy route called in deep integration mode for path: /dashboard/{path}")
        raise HTTPException(status_code=404, detail="Dashboard route not found")
    
    # Traditional proxy flow for non-deep integration
    # Build target URL
    target_path = f"/{path}" if path else "/"

    # Forward query parameters
    if request.url.query:
        target_path += f"?{request.url.query}"

    # Filter headers to avoid conflicts
    headers = {}
    for key, value in request.headers.items():
        if key.lower() not in ["host", "content-length"]:
            headers[key] = value

    # ä¼˜åŒ–ï¼šä½¿ç”¨è¿æ¥æ± å¤ç”¨ï¼Œé¿å…æ¯æ¬¡åˆ›å»ºæ–°è¿æ¥
    client = get_dashboard_client()

    try:
        # Forward request using connection pool
        if request.method == "GET":
            response = await client.get(target_path, headers=headers)
        elif request.method == "POST":
            body = await request.body()
            response = await client.post(target_path, content=body, headers=headers)
        elif request.method == "PUT":
            body = await request.body()
            response = await client.put(target_path, content=body, headers=headers)
        elif request.method == "DELETE":
            response = await client.delete(target_path, headers=headers)
        elif request.method == "PATCH":
            body = await request.body()
            response = await client.patch(target_path, content=body, headers=headers)
        elif request.method == "OPTIONS":
            response = await client.options(target_path, headers=headers)
        else:
            raise HTTPException(status_code=405, detail="Method not allowed")

        # Filter response headers
        response_headers = {}
        for key, value in response.headers.items():
            if key.lower() not in ["content-encoding", "transfer-encoding", "content-length"]:
                response_headers[key] = value

        # ä¼˜åŒ–ï¼šåªå¯¹HTMLå†…å®¹è¿›è¡Œè·¯å¾„ä¿®å¤ï¼Œä¸”ä½¿ç”¨æ›´é«˜æ•ˆçš„æ–¹å¼
        content = response.content
        content_type = response.headers.get("content-type", "text/html")

        # If it's HTML, fix resource paths to use proxy routes (only if needed)
        if "text/html" in content_type and path == "":
            try:
                html_text = content.decode("utf-8", errors="ignore")
                # ä¼˜åŒ–ï¼šä½¿ç”¨å•æ¬¡æ›¿æ¢ï¼Œå‡å°‘æ­£åˆ™æ“ä½œ
                # åªæ›¿æ¢å¿…è¦çš„è·¯å¾„ï¼Œé¿å…ä¸å¿…è¦çš„å¤„ç†
                if DASHBOARD_URL in html_text:
                    html_text = html_text.replace(f"{DASHBOARD_URL}/_dash-", "/_dash-")
                    html_text = html_text.replace(
                        f"{DASHBOARD_URL}/_dash-component-suites/", "/_dash-component-suites/"
                    )
                content = html_text.encode("utf-8")
            except Exception as e:
                # If fixing fails, return original content
                logger.warning(f"Failed to fix Dashboard HTML paths: {e}")

        # ä¼˜åŒ–ï¼šä¸ºé™æ€èµ„æºæ·»åŠ ç¼“å­˜å¤´
        if path.startswith("_dash-") or path.startswith("_dash-component-suites"):
            response_headers["Cache-Control"] = "public, max-age=86400"  # é™æ€èµ„æºç¼“å­˜1å¤©
        elif request.method == "GET" and content_type == "text/html":
            response_headers["Cache-Control"] = "public, max-age=60"  # HTMLç¼“å­˜1åˆ†é’Ÿ

        # Return response
        return Response(
            content=content,
            status_code=response.status_code,
            headers=response_headers,
            media_type=content_type,
        )
    except httpx.ConnectError:
        return HTMLResponse(
            content=f"""
            <html>
            <head><title>Dashboard Not Available</title></head>
            <body>
                <h1>Dashboard Not Available</h1>
                <p>Dashboard service is not running on {DASHBOARD_URL}</p>
                <p>It should start automatically when MCP server starts.</p>
                <p>If it doesn't start, please check:</p>
                <ul>
                    <li>Port 8051 is not occupied</li>
                    <li>Dashboard script exists: scripts/dashboard/app.py</li>
                    <li>Check MCP server logs for errors</li>
                </ul>
            </body>
            </html>
            """,
            status_code=503,
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Dashboard proxy error: {str(e)}")


@app.get("/dashboard")
async def dashboard():
    """Redirect to Dashboard root"""
    return RedirectResponse(url="/dashboard/")


# å¯¼å…¥ç­–ç•¥ç®¡ç†å™¨ - ä½¿ç”¨ç›¸å¯¹è·¯å¾„
import sys
import os

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
src_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), 'src')
sys.path.insert(0, src_path)

# ç›´æ¥å¯¼å…¥StrategyManager
from quantsys.api.strategy_manager import StrategyManager

# åˆå§‹åŒ–ç­–ç•¥ç®¡ç†å™¨
strategy_manager = StrategyManager()

# ç­–ç•¥ç›¸å…³APIç«¯ç‚¹
@app.get("/api/v1/strategies")
async def get_strategies_list():
    """è·å–æ‰€æœ‰ç­–ç•¥åˆ—è¡¨"""
    try:
        strategies = strategy_manager.get_strategies()
        return {
            "strategies": strategies
        }
    except Exception as e:
        return {
            "strategies": []
        }

@app.get("/api/v1/strategy/{strategy}")
async def get_strategy_detail(strategy: str):
    """è·å–ç‰¹å®šç­–ç•¥çš„è¯¦ç»†ä¿¡æ¯"""
    try:
        strategy_info = strategy_manager.get_strategy(strategy)
        return strategy_info
    except Exception as e:
        return {
            "strategy": strategy,
            "code": "",
            "timeframe": ""
        }

@app.post("/api/strategies/sync")
async def sync_strategies():
    """åŒæ­¥ç­–ç•¥æ•°æ®"""
    try:
        success = strategy_manager.sync_strategies()
        return {
            "success": success,
            "message": "ç­–ç•¥åŒæ­¥å®Œæˆ" if success else "ç­–ç•¥åŒæ­¥å¤±è´¥"
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

# Proxy Dashboard static resources (_dash-* paths)
@app.api_route("/_dash-{path:path}", methods=["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS"])
async def dashboard_static_proxy(path: str, request: Request):
    """Proxy Dashboard static resources (_dash-* paths) - optimized with connection pooling"""
    # Build target URL - Dashboard static resources use _dash- prefix
    target_path = f"/_dash-{path}" if path else "/_dash-layout"

    # Forward query parameters
    if request.url.query:
        target_path += f"?{request.url.query}"

    # Filter headers
    headers = {}
    for key, value in request.headers.items():
        if key.lower() not in ["host", "content-length"]:
            headers[key] = value

    # ä¼˜åŒ–ï¼šä½¿ç”¨è¿æ¥æ± å¤ç”¨
    client = get_dashboard_client()

    try:
        if request.method == "GET":
            response = await client.get(target_path, headers=headers)
        elif request.method == "POST":
            body = await request.body()
            response = await client.post(target_path, content=body, headers=headers)
        elif request.method == "PUT":
            body = await request.body()
            response = await client.put(target_path, content=body, headers=headers)
        elif request.method == "DELETE":
            response = await client.delete(target_path, headers=headers)
        elif request.method == "PATCH":
            body = await request.body()
            response = await client.patch(target_path, content=body, headers=headers)
        elif request.method == "OPTIONS":
            response = await client.options(target_path, headers=headers)
        else:
            raise HTTPException(status_code=405, detail="Method not allowed")

        # Filter response headers
        response_headers = {}
        for key, value in response.headers.items():
            if key.lower() not in ["content-encoding", "transfer-encoding", "content-length"]:
                response_headers[key] = value

        # ä¼˜åŒ–ï¼šä¸ºé™æ€èµ„æºæ·»åŠ ç¼“å­˜å¤´
        response_headers["Cache-Control"] = "public, max-age=86400"  # é™æ€èµ„æºç¼“å­˜1å¤©

        return Response(
            content=response.content,
            status_code=response.status_code,
            headers=response_headers,
            media_type=response.headers.get("content-type", "application/javascript"),
        )
    except httpx.ConnectError:
        raise HTTPException(
            status_code=503, detail=f"Dashboard service not available at {DASHBOARD_URL}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Dashboard proxy error: {str(e)}")


# Proxy Dashboard component suites static files
@app.api_route("/_dash-component-suites/{path:path}", methods=["GET"])
async def dashboard_component_suites_proxy(path: str, request: Request):
    """Proxy Dashboard component suites static files - optimized with connection pooling"""
    target_path = f"/_dash-component-suites/{path}"

    if request.url.query:
        target_path += f"?{request.url.query}"

    headers = {}
    for key, value in request.headers.items():
        if key.lower() not in ["host", "content-length"]:
            headers[key] = value

    # ä¼˜åŒ–ï¼šä½¿ç”¨è¿æ¥æ± å¤ç”¨
    client = get_dashboard_client()

    try:
        response = await client.get(target_path, headers=headers)

        response_headers = {}
        for key, value in response.headers.items():
            if key.lower() not in ["content-encoding", "transfer-encoding", "content-length"]:
                response_headers[key] = value

        # ä¼˜åŒ–ï¼šä¸ºç»„ä»¶å¥—ä»¶æ·»åŠ ç¼“å­˜å¤´
        response_headers["Cache-Control"] = "public, max-age=86400"  # ç¼“å­˜1å¤©

        return Response(
            content=response.content,
            status_code=response.status_code,
            headers=response_headers,
            media_type=response.headers.get("content-type", "application/javascript"),
        )
    except httpx.ConnectError:
        raise HTTPException(
            status_code=503, detail=f"Dashboard service not available at {DASHBOARD_URL}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Dashboard proxy error: {str(e)}")


@app.get("/api/a2a/status")
async def a2a_status():
    """A2A Hub health status"""
    if not A2A_HUB_ENABLED:
        raise HTTPException(status_code=503, detail="A2A Hub disabled")
    
    # In deep integration mode, A2A Hub is part of the same process
    # Just return healthy status since we're running in the same process
    try:
        from .a2a_integration import configure_a2a_integration
        return {
            "status_code": 200,
            "body": {
                "status": "healthy",
                "message": "A2A Hub running in deep integration mode",
                "timestamp": datetime.now().isoformat()
            }
        }
    except Exception as exc:
        raise HTTPException(status_code=503, detail=f"A2A Hub unavailable: {exc}")


@app.api_route(
    "/a2a/{path:path}", methods=["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS"]
)
async def a2a_proxy(path: str, request: Request):
    """Proxy A2A Hub requests to consolidate services under MCP Bus."""
    if not A2A_HUB_ENABLED:
        raise HTTPException(status_code=503, detail="A2A Hub disabled")
    
    # In deep integration mode, this route should never be called directly
    # because WSGIMiddleware handles /a2a path directly
    # This is just a fallback to ensure proper error handling
    logger.warning(f"A2A proxy route called in deep integration mode for path: /a2a/{path}")
    raise HTTPException(status_code=404, detail="A2A route not found")


@app.get("/api/services")
async def list_services():
    """List registered services for proxying."""
    services: dict[str, dict[str, Any]] = {}
    for name, info in _SERVICE_MAP.items():
        services[name] = {
            "url": info.get("url"),
            "health": info.get("health"),
            "managed": name in _SERVICE_START_MAP,
        }
    return {"services": services}


@app.get("/api/services/health")
async def services_health():
    """Check health for services that define a health endpoint."""
    results: dict[str, dict[str, Any]] = {}
    async with httpx.AsyncClient(timeout=2.0) as client:
        for name, info in _SERVICE_MAP.items():
            health_path = info.get("health", "")
            if not health_path:
                results[name] = {"enabled": True, "checked": False}
                continue
            url = f"{info['url']}{health_path}"
            try:
                resp = await client.get(url)
                results[name] = {
                    "enabled": True,
                    "checked": True,
                    "status_code": resp.status_code,
                }
            except Exception as exc:
                results[name] = {"enabled": True, "checked": True, "error": str(exc)}
    return {"services": results}


@app.post("/api/services/start/{name}")
async def start_service(name: str):
    if name not in _SERVICE_START_MAP:
        raise HTTPException(status_code=404, detail="Service not managed")
    ok = _start_managed_service(name)
    return {"service": name, "started": ok}


@app.post("/api/services/stop/{name}")
async def stop_service(name: str):
    ok = _stop_managed_service(name)
    return {"service": name, "stopped": ok}


@app.get("/api/services/status/{name}")
async def service_status(name: str):
    if name not in _SERVICE_MAP:
        raise HTTPException(status_code=404, detail="Unknown service")
    proc = _service_processes.get(name)
    running = proc is not None and proc.poll() is None
    health = _check_service_health(name)
    return {"service": name, "running": running, "health": health}


@app.api_route(
    "/proxy/{service}/{path:path}", methods=["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS"]
)
async def service_proxy(service: str, path: str, request: Request):
    """Generic service proxy for consolidating multiple services under MCP Bus."""
    if service not in _SERVICE_MAP:
        raise HTTPException(status_code=404, detail=f"Unknown service: {service}")

    target_path = f"/{path}" if path else "/"
    if request.url.query:
        target_path += f"?{request.url.query}"

    headers = {}
    for key, value in request.headers.items():
        if key.lower() not in ["host", "content-length"]:
            headers[key] = value

    client = get_service_client(service)

    try:
        if request.method == "GET":
            response = await client.get(target_path, headers=headers)
        elif request.method == "POST":
            body = await request.body()
            response = await client.post(target_path, content=body, headers=headers)
        elif request.method == "PUT":
            body = await request.body()
            response = await client.put(target_path, content=body, headers=headers)
        elif request.method == "DELETE":
            response = await client.delete(target_path, headers=headers)
        elif request.method == "PATCH":
            body = await request.body()
            response = await client.patch(target_path, content=body, headers=headers)
        elif request.method == "OPTIONS":
            response = await client.options(target_path, headers=headers)
        else:
            raise HTTPException(status_code=405, detail="Method not allowed")

        response_headers = {}
        for key, value in response.headers.items():
            if key.lower() not in ["content-encoding", "transfer-encoding", "content-length"]:
                response_headers[key] = value

        return Response(
            content=response.content,
            status_code=response.status_code,
            headers=response_headers,
            media_type=response.headers.get("content-type", "application/json"),
        )
    except httpx.ConnectError:
        raise HTTPException(
            status_code=503, detail=f"Service not available at {_SERVICE_MAP[service]['url']}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Proxy error: {str(e)}")


@app.get("/collaboration")
async def collaboration():
    """Agent Collaboration Web Interface"""
    collaboration_html = Path(__file__).parent.parent / "web_viewer" / "collaboration.html"
    if collaboration_html.exists():
        return create_cached_file_response(collaboration_html)
    return HTMLResponse(
        "<h1>Collaboration Interface Not Found</h1><p>collaboration.html not found</p>"
    )


@app.get("/agent/{agent_ref}")
async def agent_home(agent_ref: str):
    """Agent homepage (profile + inbox/outbox + send form)"""
    agent_home_html = Path(__file__).parent.parent / "web_viewer" / "agent_home.html"
    if not agent_home_html.exists():
        return HTMLResponse("<h1>Agent Home Not Found</h1><p>agent_home.html not found</p>")
    # the HTML reads agent_ref from URL and loads data via REST APIs
    return create_cached_file_response(agent_home_html)


@app.get("/agents")
async def agents_panel():
    """All registered agents panel"""
    html = Path(__file__).parent.parent / "web_viewer" / "agents_panel.html"
    if html.exists():
        return create_cached_file_response(html)
    return HTMLResponse("<h1>Agents Panel Not Found</h1><p>agents_panel.html not found</p>")


@app.get("/chat")
async def chat_panel():
    """ATA Chat Panel: user -> route -> ATA outbox"""
    # ä¼˜å…ˆä½¿ç”¨å¢å¼ºç‰ˆï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨åŸç‰ˆ
    html_enhanced = Path(__file__).parent.parent / "web_viewer" / "chat_enhanced.html"
    html_original = Path(__file__).parent.parent / "web_viewer" / "chat.html"
    if html_enhanced.exists():
        return create_cached_file_response(html_enhanced)
    elif html_original.exists():
        return create_cached_file_response(html_original)
    return HTMLResponse("<h1>Chat Panel Not Found</h1><p>chat.html not found</p>")


def _route_chat_target(executor: ToolExecutor, message: str) -> str | None:
    """Lightweight keyword router: pick a role then resolve to an agent id (prefer user_ai)."""
    msg = (message or "").lower()
    # keyword -> preferred role
    if any(k in msg for k in ["æ–‡æ¡£", "report", "docs", "markdown"]):
        role = "doc_writer"
    elif any(k in msg for k in ["äº¤æ˜“", "å›æµ‹", "ç­–ç•¥", "ä¸‹å•", "é£æ§"]):
        role = "trading"
    elif any(k in msg for k in ["æ•°æ®", "etl", "é‡‡é›†", "æ¸…æ´—", "æ•°æ®ç®¡é“"]):
        role = "data_engineer"
    elif any(k in msg for k in ["ç½‘é¡µ", "web", "æœåŠ¡å™¨", "server", "mcp"]):
        role = "infra_ops"
    elif any(k in msg for k in ["æ¶æ„", "è®¾è®¡", "ç»“æ„", "æ¨¡å—åˆ’åˆ†"]):
        role = "designer"
    elif any(k in msg for k in ["ci", "é—¨ç¦", "è‡ªæµ‹", "evidence", "verdict", "gate"]):
        role = "infra_quality"
    else:
        role = "implementer"

    if not executor.coordinator:
        return None
    # Prefer user_ai for routed work; fall back to any matching role
    agents = executor.coordinator.registry.find_agents(role=role, available_only=True)
    user_agents = [a for a in agents if getattr(a, "category", "user_ai") == "user_ai"]
    chosen = None
    if user_agents:
        chosen = executor.coordinator.load_balancer.select_agent(user_agents) or user_agents[0]
    elif agents:
        chosen = executor.coordinator.load_balancer.select_agent(agents) or agents[0]
    return chosen.agent_id if chosen else None


@app.post("/api/notification/send")
async def api_notification_send(
    body: NotificationSendRequest, request: Request, token: dict = Depends(verify_token)
):
    """å‘é€é€šçŸ¥ï¼ˆé›†æˆå·²æœ‰çš„é€šçŸ¥åº”ç”¨ï¼‰"""
    try:
        from .notification_integration import get_notification_integration

        notification = get_notification_integration()
        result = notification.send_notification(body.title, body.message, body.mode)
        return result
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.post("/api/chat/send")
async def api_chat_send(
    body: ChatSendRequest, request: Request, token: dict = Depends(verify_token)
):
    """Receive user message, route to agent, enqueue via ata_send_request (admin approves later)."""
    executor = get_tool_executor()
    if not executor.coordinator:
        raise HTTPException(status_code=500, detail="AgentCoordinator not available")

    text = (body.message or "").strip()
    if not text:
        return {"success": False, "error": "message is required"}

    # Choose target agent
    target = body.target_agent.strip() if body.target_agent else ""
    if target:
        try:
            to_agent_id = _resolve_agent_ref(executor, target)
        except Exception:
            return {"success": False, "error": f"Unknown target_agent: {target}"}
    else:
        to_agent_id = _route_chat_target(executor, text)
        if not to_agent_id:
            return {"success": False, "error": "No suitable agent found for routing"}

    # Sender is ATA system
    from_agent_id = "ATAç³»ç»Ÿ"
    from_obj = executor.coordinator.registry.get_agent(from_agent_id)
    to_obj = executor.coordinator.registry.get_agent(to_agent_id)
    from_display = _display_name(from_agent_id, getattr(from_obj, "numeric_code", None))
    to_display = _display_name(to_agent_id, getattr(to_obj, "numeric_code", None))

    # Ensure comm prefix
    msg_text = text
    if not msg_text.startswith(f"@{to_display}"):
        msg_text = f"@{to_display} {msg_text}"

    taskcode = (body.taskcode or "").strip()
    if not taskcode:
        taskcode = f"CHAT-{datetime.now().strftime('%Y%m%d%H%M%S')}"

    params = ATASendRequestParams(
        taskcode=taskcode,
        from_agent=from_agent_id,
        to_agent=to_agent_id,
        kind="request",
        payload={
            "message": msg_text,
            "text": msg_text,
            "from_display": from_display,
            "to_display": to_display,
            "source": "web_chat",
        },
        priority="normal",
        requires_response=True,
        context_hint="web_chat",
    )
    result = executor.ata_send_request(
        params, caller="web_chat", user_agent=request.headers.get("user-agent"), trace_id="web_chat"
    )

    # å¦‚æœå¯ç”¨äº†é€šçŸ¥ï¼Œå‘é€é€šçŸ¥ï¼ˆä½¿ç”¨å·²æœ‰çš„é€šçŸ¥åº”ç”¨ï¼‰
    notification_mode = getattr(body, "notification_mode", "ata")
    notification_result = None
    if notification_mode != "ata":
        try:
            from .notification_integration import get_notification_integration

            notification = get_notification_integration()
            notification_result = notification.send_notification(
                title="ATAæ¶ˆæ¯å·²å‘é€",
                message=f"æ¶ˆæ¯å·²è·¯ç”±åˆ° {to_agent_id}ï¼ŒTaskCode: {taskcode}",
                mode=notification_mode,
            )
        except Exception as e:
            logger.warning(f"é€šçŸ¥å‘é€å¤±è´¥: {e}")

    return {
        "success": bool(result.get("success")),
        "taskcode": taskcode,
        "routed_to": to_agent_id,
        "request_id": result.get("request_id"),
        "status": result.get("status"),
        "error": result.get("error"),
        "notification": notification_result,
    }


@app.get("/monitoring")
async def monitoring_panel():
    """å®æ—¶ç›‘æ§é¢æ¿"""
    html = Path(__file__).parent.parent / "web_viewer" / "monitoring.html"
    if html.exists():
        return create_cached_file_response(html)
    return HTMLResponse("<h1>Monitoring Panel Not Found</h1><p>monitoring.html not found</p>")


# Static files for performance optimization
web_viewer_dir = Path(__file__).parent.parent / "web_viewer"
static_dir = web_viewer_dir / "static"
static_dir.mkdir(parents=True, exist_ok=True)

# Copy performance script to static directory if it exists
performance_script = web_viewer_dir / "dashboard_performance.js"
if performance_script.exists():
    import shutil

    static_performance = static_dir / "dashboard_performance.js"
    if not static_performance.exists():
        shutil.copy2(performance_script, static_performance)

# Copy design-system.css to static directory if it exists in styles
styles_dir = web_viewer_dir / "styles"
design_system_css = styles_dir / "design-system.css"
if design_system_css.exists():
    import shutil

    static_design_system = static_dir / "design-system.css"
    if not static_design_system.exists():
        shutil.copy2(design_system_css, static_design_system)

# Mount static files directory with caching
if static_dir.exists():
    # ä¼˜åŒ–ï¼šä¸ºé™æ€æ–‡ä»¶æ·»åŠ æ°¸ä¹…ç¼“å­˜å¤´ï¼ˆç›´åˆ°æ‰‹åŠ¨æ¸…é™¤ï¼‰
    class CachedStaticFiles(StaticFiles):
        """å¸¦æ°¸ä¹…ç¼“å­˜å¤´çš„é™æ€æ–‡ä»¶æœåŠ¡ï¼ˆæµè§ˆå™¨æ°¸ä¹…ç¼“å­˜ç›´åˆ°æ‰‹åŠ¨æ¸…é™¤ï¼‰"""

        async def __call__(self, scope, receive, send):
            if scope["type"] == "http":

                async def send_wrapper(message):
                    if message["type"] == "http.response.start":
                        headers = dict(message.get("headers", []))
                        # æ°¸ä¹…ç¼“å­˜ç­–ç•¥ï¼šæ‰€æœ‰é™æ€èµ„æºç¼“å­˜1å¹´ï¼Œæ ‡è®°ä¸ºä¸å¯å˜
                        # æµè§ˆå™¨ä¼šæ°¸ä¹…ç¼“å­˜ç›´åˆ°ç”¨æˆ·æ‰‹åŠ¨æ¸…é™¤ç¼“å­˜
                        # max-age=31536000 = 1å¹´ï¼ˆ365å¤©ï¼‰
                        path = (scope.get("path", "") or "").lower()
                        if path.endswith(
                            (
                                ".css",
                                ".js",
                                ".ico",
                                ".png",
                                ".jpg",
                                ".jpeg",
                                ".gif",
                                ".svg",
                                ".woff",
                                ".woff2",
                                ".ttf",
                                ".eot",
                            )
                        ):
                            # é™æ€èµ„æºï¼šæ°¸ä¹…ç¼“å­˜ï¼ˆ1å¹´ï¼‰ï¼Œä¸å¯å˜
                            headers[b"cache-control"] = b"public, max-age=31536000, immutable"
                        else:
                            # å…¶ä»–èµ„æºï¼šä¹Ÿä½¿ç”¨é•¿æœŸç¼“å­˜
                            headers[b"cache-control"] = b"public, max-age=31536000, immutable"
                        # æ€§èƒ½ä¼˜åŒ–å¤´
                        headers[b"x-content-type-options"] = b"nosniff"
                        headers[b"x-frame-options"] = b"SAMEORIGIN"
                        message["headers"] = list(headers.items())
                    await send(message)

                await super().__call__(scope, receive, send_wrapper)
            else:
                await super().__call__(scope, receive, send)

    app.mount("/static", CachedStaticFiles(directory=str(static_dir)), name="static")

    # åŒæ—¶æŒ‚è½½stylesç›®å½•ï¼Œä»¥é˜²æœ‰å…¶ä»–åœ°æ–¹å¼•ç”¨
    if styles_dir.exists():
        app.mount("/styles", CachedStaticFiles(directory=str(styles_dir)), name="styles")

# FreqUI static files and API proxy
frequi_dist_dir = get_repo_root() / "frequi-main" / "dist"
freqtrade_api_url = os.getenv("FREQTRADE_API_URL", "http://127.0.0.1:8080")

# ç¼“å­˜FreqUI HTMLå†…å®¹ï¼Œé¿å…æ¯æ¬¡è¯»å–æ–‡ä»¶
_frequi_html_cache = {"content": None, "mtime": 0, "path": None}


def _get_frequi_html():
    """è·å–FreqUI HTMLï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    frequi_index = frequi_dist_dir / "index.html"
    if not frequi_index.exists():
        return None

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²æ›´æ–°
    current_mtime = frequi_index.stat().st_mtime
    if (
        _frequi_html_cache["content"] is None
        or _frequi_html_cache["path"] != str(frequi_index)
        or current_mtime > _frequi_html_cache["mtime"]
    ):
        # è¯»å–å¹¶å¤„ç†HTML
        with open(frequi_index, encoding="utf-8") as f:
            html_content = f.read()

        # Inject proxy configuration script before closing </body>
        proxy_script = """
            <script>
            // FreqUI API Proxy Configuration
            (function() {
                // Override API base URL
                if (window.localStorage) {
                    window.localStorage.setItem('ftbot_api_base_url', '/frequi/api/v1');
                    window.localStorage.setItem('ftbot_api_url', '/frequi/api/v1');
                }
                // Also set as window variable for immediate access
                window.FTBOT_API_BASE_URL = '/frequi/api/v1';
                console.log('FreqUI API configured:', window.FTBOT_API_BASE_URL);
                
                // é”™è¯¯å¤„ç†ï¼šå³ä½¿APIä¸å¯ç”¨ä¹Ÿå…è®¸UIåŠ è½½
                // æ‹¦æˆªfetché”™è¯¯ï¼Œé¿å…é˜»å¡UIæ¸²æŸ“
                const originalFetch = window.fetch;
                window.fetch = function(...args) {
                    return originalFetch.apply(this, args).catch(error => {
                        console.warn('API request failed, but UI will continue to load:', error);
                        // è¿”å›ä¸€ä¸ªæ¨¡æ‹Ÿçš„æˆåŠŸå“åº”ï¼Œè®©UIå¯ä»¥ç»§ç»­æ¸²æŸ“
                        // å®é™…APIè°ƒç”¨ä¼šåœ¨UIä¸­å¤„ç†é”™è¯¯
                        return Promise.resolve(new Response(
                            JSON.stringify({ error: 'API unavailable', detail: error.message }),
                            { status: 503, statusText: 'Service Unavailable', headers: { 'Content-Type': 'application/json' } }
                        ));
                    });
                };
            })();
            </script>
            """

        html_content = html_content.replace("</body>", proxy_script + "</body>")

        # æ›´æ–°ç¼“å­˜
        _frequi_html_cache["content"] = html_content
        _frequi_html_cache["mtime"] = current_mtime
        _frequi_html_cache["path"] = str(frequi_index)

    return _frequi_html_cache["content"]


if frequi_dist_dir.exists():
    # Mount FreqUI static files (but exclude API routes)
    # ä¼˜åŒ–ï¼šä¸ºé™æ€æ–‡ä»¶æ·»åŠ ç¼“å­˜å¤´
    from fastapi.staticfiles import StaticFiles
    from starlette.responses import Response

    class CachedStaticFiles(StaticFiles):
        """å¸¦ç¼“å­˜å¤´çš„é™æ€æ–‡ä»¶æœåŠ¡"""

        async def __call__(self, scope, receive, send):
            if scope["type"] == "http":

                async def send_wrapper(message):
                    if message["type"] == "http.response.start":
                        headers = dict(message.get("headers", []))
                        # æ·»åŠ ç¼“å­˜å¤´
                        headers[b"cache-control"] = b"public, max-age=86400"  # ç¼“å­˜1å¤©
                        message["headers"] = list(headers.items())
                    await send(message)

                await super().__call__(scope, receive, send_wrapper)
            else:
                await super().__call__(scope, receive, send)

    app.mount(
        "/frequi/assets",
        CachedStaticFiles(directory=str(frequi_dist_dir / "assets")),
        name="frequi_assets",
    )

    @app.get("/frequi")
    async def frequi_root():
        """FreqUI - Freqtrade Web Interface with proxy configuration (optimized with permanent caching)"""
        html_content = _get_frequi_html()
        if html_content:
            return HTMLResponse(
                content=html_content,
                headers={
                    "Cache-Control": "public, max-age=31536000, immutable",  # æ°¸ä¹…ç¼“å­˜ï¼ˆ1å¹´ï¼‰ï¼Œä¸å¯å˜
                    "ETag": f'"{_frequi_html_cache["mtime"]}"',
                    "X-Content-Type-Options": "nosniff",
                    "Content-Security-Policy": "frame-ancestors *",
                },
            )
        return HTMLResponse("<h1>FreqUI Not Found</h1><p>index.html not found</p>")

    # Serve other static files from FreqUI
    @app.get("/frequi/favicon.ico")
    async def frequi_favicon():
        favicon = frequi_dist_dir / "favicon.ico"
        if favicon.exists():
            return create_cached_file_response(favicon, media_type="image/x-icon")
        raise HTTPException(status_code=404)

    @app.get("/frequi/_redirects")
    async def frequi_redirects():
        redirects = frequi_dist_dir / "_redirects"
        if redirects.exists():
            return create_cached_file_response(redirects)
        raise HTTPException(status_code=404)

    # Freqtrade API proxy for FreqUI - Enhanced with authentication and better error handling
    @app.api_route(
        "/frequi/api/{path:path}", methods=["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS"]
    )
    async def frequi_api_proxy(path: str, request: Request):
        """Proxy FreqUI API requests to Freqtrade API server - optimized with connection pooling"""
        try:
            # Get query parameters
            query_params = dict(request.query_params)
            query_string = (
                "&".join([f"{k}={v}" for k, v in query_params.items()]) if query_params else ""
            )
            api_path = f"/api/v1/{path}"
            if query_string:
                api_path += f"?{query_string}"

            # Get request body
            body = None
            if request.method in ["POST", "PUT", "PATCH"]:
                body = await request.body()

            # Prepare headers - preserve Authorization and other important headers
            headers = {}
            for k, v in request.headers.items():
                k_lower = k.lower()
                # Skip host and content-length, but preserve others including Authorization
                if k_lower not in ["host", "content-length"]:
                    headers[k] = v

            # ä¼˜åŒ–ï¼šä½¿ç”¨è¿æ¥æ± å¤ç”¨ï¼Œé¿å…æ¯æ¬¡åˆ›å»ºæ–°è¿æ¥
            client = get_freqtrade_client()

            # ä¼˜åŒ–ï¼šå¯¹äºå…³é”®ç«¯ç‚¹ä½¿ç”¨æ›´çŸ­è¶…æ—¶
            critical_endpoints = ["ping", "version", "show_config", "balance", "status"]
            is_critical = any(endpoint in path.lower() for endpoint in critical_endpoints)

            # Forward request to Freqtrade API using connection pool
            try:
                response = await client.request(
                    method=request.method,
                    url=api_path,
                    content=body,
                    headers=headers,
                    follow_redirects=True,
                )

                # Prepare response headers
                response_headers = dict(response.headers)
                # Remove CORS headers from upstream (we'll handle them)
                for header in [
                    "access-control-allow-origin",
                    "access-control-allow-methods",
                    "access-control-allow-headers",
                ]:
                    response_headers.pop(header, None)

                # ä¼˜åŒ–ï¼šä¸ºGETè¯·æ±‚æ·»åŠ ç¼“å­˜å¤´ï¼ˆä»…å¯¹æŸäº›ç«¯ç‚¹ï¼‰
                if request.method == "GET" and is_critical:
                    response_headers["Cache-Control"] = "public, max-age=5"  # å…³é”®ç«¯ç‚¹ç¼“å­˜5ç§’

                return Response(
                    content=response.content,
                    status_code=response.status_code,
                    headers=response_headers,
                    media_type=response.headers.get("content-type"),
                )
            except (httpx.TimeoutException, httpx.ConnectError, httpx.NetworkError) as e:
                # å¦‚æœFreqtrade APIä¸å¯ç”¨ï¼Œè¿”å›å‹å¥½çš„é”™è¯¯å“åº”ï¼Œè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
                # è¿™æ ·FreqUIä»ç„¶å¯ä»¥æ˜¾ç¤ºç•Œé¢ï¼Œåªæ˜¯æ˜¾ç¤ºè¿æ¥é”™è¯¯
                freqtrade_api_url = os.getenv("FREQTRADE_API_URL", "http://127.0.0.1:8080")
                logger.warning(f"Freqtrade API unavailable at {freqtrade_api_url}: {e}")

                # å¯¹äºæŸäº›å…³é”®APIç«¯ç‚¹ï¼Œè¿”å›ç©ºæ•°æ®è€Œä¸æ˜¯é”™è¯¯ï¼Œè®©UIå¯ä»¥æ­£å¸¸æ¸²æŸ“
                critical_endpoints = ["ping", "version", "show_config", "balance", "status"]
                if any(endpoint in path.lower() for endpoint in critical_endpoints):
                    # è¿”å›ç©ºæˆ–é»˜è®¤æ•°æ®ï¼Œè®©UIå¯ä»¥åŠ è½½
                    if "ping" in path.lower():
                        return JSONResponse(content={"status": "pong"}, status_code=200)
                    elif "version" in path.lower():
                        return JSONResponse(content={"version": "unknown"}, status_code=200)
                    elif "show_config" in path.lower():
                        return JSONResponse(
                            content={"dry_run": True, "trading_mode": "spot"}, status_code=200
                        )
                    elif "balance" in path.lower():
                        return JSONResponse(content={"currencies": []}, status_code=200)
                    elif "status" in path.lower():
                        return JSONResponse(content={"state": "stopped"}, status_code=200)

                # å…¶ä»–ç«¯ç‚¹è¿”å›é”™è¯¯ï¼Œä½†ä½¿ç”¨503è€Œä¸æ˜¯500ï¼Œè®©UIçŸ¥é“æ˜¯æœåŠ¡ä¸å¯ç”¨
                error_response = {
                    "error": "Freqtrade API unavailable",
                    "detail": f"Cannot connect to Freqtrade API at {freqtrade_api_url}",
                    "message": "Please ensure Freqtrade WebServer is running on port 8080",
                }
                return JSONResponse(
                    status_code=503,
                    content=error_response,
                    headers={
                        "Access-Control-Allow-Origin": "*",
                        "Access-Control-Allow-Methods": "GET, POST, PUT, DELETE, OPTIONS",
                        "Access-Control-Allow-Headers": "Content-Type, Authorization",
                    },
                )
        except Exception as e:
            # æ•è·æ‰€æœ‰å…¶ä»–å¼‚å¸¸ï¼Œè¿”å›å‹å¥½çš„é”™è¯¯å“åº”
            logger.error(f"FreqUI API proxy error: {e}", exc_info=True)
            error_response = {
                "error": "Proxy error",
                "detail": str(e),
                "message": "An error occurred while proxying the request",
            }
            return JSONResponse(
                status_code=500,
                content=error_response,
                headers={
                    "Access-Control-Allow-Origin": "*",
                    "Access-Control-Allow-Methods": "GET, POST, PUT, DELETE, OPTIONS",
                    "Access-Control-Allow-Headers": "Content-Type, Authorization",
                },
            )

    # WebSocket proxy for FreqUI (if needed for real-time updates)
    @app.websocket("/frequi/ws/{path:path}")
    async def frequi_ws_proxy(websocket: WebSocket, path: str):
        """Proxy WebSocket connections for FreqUI"""
        try:
            await websocket.accept()
            # Forward WebSocket connection to Freqtrade
            # This requires additional implementation for WebSocket forwarding
            # For now, return a placeholder response
            await websocket.send_json({"error": "WebSocket proxy not yet implemented"})
            await websocket.close()
        except Exception as e:
            await websocket.close(code=1011, reason=f"Proxy error: {str(e)}")
else:

    @app.get("/frequi")
    async def frequi_not_found():
        """FreqUI not available"""
        return HTMLResponse(
            "<h1>FreqUI Not Available</h1><p>FreqUI dist directory not found. Please build it first.</p>"
        )


@app.get("/health")
async def health():
    from datetime import datetime

    a2a_status = None
    if A2A_HUB_ENABLED:
        a2a_status = {"enabled": True, "healthy": _check_service_health("a2a")}
    else:
        a2a_status = {"enabled": False}

    return {
        "ok": True,
        "ts": datetime.now().isoformat(),
        "status": "healthy",
        "version": "0.1.0",
        "a2a": a2a_status,
    }


@app.get("/api/langsmith/status")
async def get_langsmith_status():
    """LangSmith tracing configuration/status (safe, no secrets)."""
    try:
        from tools.langsmith.fastapi_middleware import langsmith_status

        payload = langsmith_status()
        payload["middleware_attached"] = bool(LANGSMITH_MIDDLEWARE_ATTACHED)
        payload["available"] = True
        return payload
    except Exception as e:
        return {
            "available": False,
            "configured": False,
            "middleware_attached": False,
            "error": str(e),
        }


# Monitoring API endpoints
@app.get("/api/monitoring/status")
@cached(prefix="monitoring", ttl=5)  # ç¼“å­˜5ç§’
async def get_monitoring_status():
    """è·å–æ‰€æœ‰æœåŠ¡çŠ¶æ€"""
    return monitoring_service.get_status_summary()


@app.get("/api/monitoring/metrics")
@cached(prefix="monitoring", ttl=5)  # ç¼“å­˜5ç§’
async def get_monitoring_metrics():
    """è·å–ç³»ç»ŸæŒ‡æ ‡"""
    metrics = (
        monitoring_service.metrics_history[-100:] if monitoring_service.metrics_history else []
    )
    return {
        "metrics": [
            {
                "timestamp": m.timestamp.isoformat(),
                "cpu_percent": m.cpu_percent,
                "memory_percent": m.memory_percent,
                "memory_used_mb": m.memory_used_mb,
                "memory_total_mb": m.memory_total_mb,
                "disk_percent": m.disk_percent,
                "disk_used_gb": m.disk_used_gb,
                "disk_total_gb": m.disk_total_gb,
                "network_sent_mb": m.network_sent_mb,
                "network_recv_mb": m.network_recv_mb,
            }
            for m in metrics
        ]
    }


@app.get("/api/monitoring/alerts")
async def get_monitoring_alerts(resolved: bool = False):
    """è·å–å‘Šè­¦åˆ—è¡¨"""
    alerts = monitoring_service.alerts
    if not resolved:
        alerts = [a for a in alerts if not a.resolved]

    return {
        "alerts": [
            {
                "id": a.id,
                "level": a.level,
                "service": a.service,
                "message": a.message,
                "timestamp": a.timestamp.isoformat(),
                "resolved": a.resolved,
            }
            for a in alerts[-50:]  # æœ€è¿‘50æ¡
        ]
    }


@app.post("/api/monitoring/alerts/{alert_id}/resolve")
async def resolve_alert(alert_id: str):
    """è§£å†³å‘Šè­¦"""
    await monitoring_service.resolve_alert(alert_id)
    return {"success": True, "alert_id": alert_id}


# Authentication API endpoints
@app.post("/api/auth/login")
async def login(request: Request):
    """ç”¨æˆ·ç™»å½•"""
    try:
        body = await request.json()
        username = body.get("username")
        password = body.get("password")

        if not username or not password:
            raise HTTPException(status_code=400, detail="Username and password required")

        token = auth_service.authenticate(username, password)
        if not token:
            raise HTTPException(status_code=401, detail="Invalid credentials")

        # è®°å½•å®¡è®¡æ—¥å¿—
        user = auth_service.get_user_by_username(username)
        auth_service.log_audit(
            user_id=user.id if user else None,
            action="login",
            ip_address=request.client.host if request.client else None,
        )

        response = JSONResponse(
            {
                "success": True,
                "token": token,
                "user": {"id": user.id, "username": user.username, "role": user.role.value},
            }
        )

        # è®¾ç½®cookie
        response.set_cookie(
            key="auth_token",
            value=token,
            max_age=86400,  # 24å°æ—¶
            httponly=True,
            secure=False,  # å¼€å‘ç¯å¢ƒï¼Œç”Ÿäº§ç¯å¢ƒåº”è®¾ä¸ºTrue
            samesite="lax",
        )

        return response
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Login error: {e}")
        raise HTTPException(status_code=500, detail="Login failed")


@app.post("/api/auth/logout")
async def logout(request: Request, authorization: str | None = Header(None)):
    """ç”¨æˆ·ç™»å‡º"""
    token = None

    if authorization and authorization.startswith("Bearer "):
        token = authorization[7:]
    else:
        token = request.cookies.get("auth_token")

    if token:
        auth_service.logout(token)

        # è®°å½•å®¡è®¡æ—¥å¿—
        payload = auth_service.verify_token(token)
        if payload:
            auth_service.log_audit(
                user_id=payload.get("user_id"),
                action="logout",
                ip_address=request.client.host if request.client else None,
            )

    response = JSONResponse({"success": True})
    response.delete_cookie("auth_token")
    return response


@app.get("/api/auth/me")
async def get_current_user(request: Request, authorization: str | None = Header(None)):
    """è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯"""
    token = None

    if authorization and authorization.startswith("Bearer "):
        token = authorization[7:]
    else:
        token = request.cookies.get("auth_token")

    if not token:
        raise HTTPException(status_code=401, detail="Not authenticated")

    payload = auth_service.verify_token(token)

    if not payload:
        raise HTTPException(status_code=401, detail="Invalid token")

    user = auth_service.get_user_by_id(payload["user_id"])
    if not user or not user.active:
        raise HTTPException(status_code=401, detail="User not found or inactive")

    return {
        "id": user.id,
        "username": user.username,
        "role": user.role.value,
        "last_login": user.last_login.isoformat() if user.last_login else None,
    }


@app.get("/api/auth/permissions")
async def get_permissions(request: Request, authorization: str | None = Header(None)):
    """è·å–ç”¨æˆ·æƒé™"""
    token = None

    if authorization and authorization.startswith("Bearer "):
        token = authorization[7:]
    else:
        token = request.cookies.get("auth_token")

    if not token:
        raise HTTPException(status_code=401, detail="Not authenticated")

    payload = auth_service.verify_token(token)

    if not payload:
        raise HTTPException(status_code=401, detail="Invalid token")

    role = payload.get("role", "viewer")

    # å®šä¹‰æƒé™
    permissions = {
        "admin": [
            "read",
            "write",
            "delete",
            "manage_users",
            "manage_config",
            "view_logs",
            "view_monitoring",
            "manage_alerts",
        ],
        "operator": ["read", "write", "view_logs", "view_monitoring", "manage_alerts"],
        "viewer": ["read", "view_logs", "view_monitoring"],
    }

    return {"role": role, "permissions": permissions.get(role, [])}


@app.websocket("/ws/monitoring")
async def websocket_monitoring(websocket: WebSocket):
    """WebSocketå®æ—¶ç›‘æ§æ¨é€"""
    await websocket.accept()
    try:
        while True:
            # å‘é€æœ€æ–°çŠ¶æ€
            status = monitoring_service.get_status_summary()
            await websocket.send_json(status)
            await asyncio.sleep(5)  # æ¯5ç§’æ¨é€ä¸€æ¬¡
    except Exception as e:
        logger.error(f"WebSocketç›‘æ§è¿æ¥é”™è¯¯: {e}")
    finally:
        await websocket.close()


# Error Logging API endpoints
@app.get("/api/logs/errors")
async def get_error_logs(
    level: str | None = None,
    service: str | None = None,
    keyword: str | None = None,
    resolved: bool | None = None,
    limit: int = 100,
    offset: int = 0,
):
    """è·å–é”™è¯¯æ—¥å¿—"""
    from datetime import datetime, timedelta

    start_time = datetime.now() - timedelta(days=7)  # é»˜è®¤æœ€è¿‘7å¤©
    end_time = datetime.now()

    logs = error_logger.search_logs(
        level=level,
        service=service,
        keyword=keyword,
        start_time=start_time,
        end_time=end_time,
        resolved=resolved,
        limit=limit,
        offset=offset,
    )

    return {"logs": logs, "total": len(logs)}


@app.get("/api/logs/search")
async def search_logs(
    q: str, level: str | None = None, service: str | None = None, limit: int = 50
):
    """æœç´¢æ—¥å¿—"""
    logs = error_logger.search_logs(level=level, service=service, keyword=q, limit=limit)
    return {"logs": logs}


@app.get("/api/logs/stats")
async def get_log_statistics(days: int = 7):
    """è·å–æ—¥å¿—ç»Ÿè®¡"""
    from datetime import datetime, timedelta

    start_time = datetime.now() - timedelta(days=days)
    end_time = datetime.now()

    stats = error_logger.get_statistics(start_time=start_time, end_time=end_time)
    return stats


@app.get("/api/logs/export")
async def export_logs(format: str = "json", days: int = 7):
    """å¯¼å‡ºæ—¥å¿—"""
    from datetime import datetime, timedelta

    start_time = datetime.now() - timedelta(days=days)
    end_time = datetime.now()

    content = error_logger.export_logs(format=format, start_time=start_time, end_time=end_time)

    if format == "json":
        return Response(content=content, media_type="application/json")
    elif format == "csv":
        return Response(content=content, media_type="text/csv")
    else:
        raise HTTPException(status_code=400, detail=f"Unsupported format: {format}")


@app.post("/api/logs/{log_id}/resolve")
async def resolve_log(log_id: str):
    """æ ‡è®°æ—¥å¿—ä¸ºå·²è§£å†³"""
    error_logger.resolve_log(log_id)
    return {"success": True, "log_id": log_id}


# Cache Management API endpoints
@app.get("/api/cache/stats")
async def get_cache_stats(token: dict = Depends(verify_token)):
    """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    stats = cache_service.get_stats()
    return stats


@app.delete("/api/cache/clear")
async def clear_cache(pattern: str | None = None, token: dict = Depends(verify_token)):
    """æ¸…é™¤ç¼“å­˜"""
    if pattern:
        deleted = cache_service.clear_pattern(pattern)
        return {"success": True, "pattern": pattern, "deleted_keys": deleted}
    else:
        # æ¸…é™¤æ‰€æœ‰ç¼“å­˜ï¼ˆä»…å†…å­˜ç¼“å­˜ï¼‰
        if not cache_service.use_redis:
            cache_service.memory_cache.clear()
            return {"success": True, "message": "All memory cache cleared"}
        else:
            # Rediséœ€è¦æŒ‡å®špattern
            return {"success": False, "message": "Please specify a pattern for Redis cache"}


# Freqtrade Management API endpoints
@app.get("/api/freqtrade/status")
async def get_freqtrade_status():
    """è·å–FreqtradeæœåŠ¡çŠ¶æ€ï¼ˆæ— éœ€è®¤è¯ï¼Œç”¨äºç›‘æ§ï¼‰"""
    status = freqtrade_service.get_status()
    return status


@app.get("/api/exchange/okx/status")
async def get_okx_connection_status():
    """è·å–OKXäº¤æ˜“æ‰€è¿æ¥ç§é’¥çŠ¶æ€ï¼ˆæ— éœ€è®¤è¯ï¼Œç”¨äºç›‘æ§ï¼‰"""
    try:
        repo_root = get_repo_root()

        candidates = [
            repo_root / "user_data" / "configs" / "freqtrade_live_config.json",
            repo_root / "user_data" / "config.json",
            repo_root / "configs" / "config_live.json",
            repo_root / "configs" / "config.json",
        ]

        cfg_path = next((p for p in candidates if p.exists()), None)
        cfg: dict[str, Any] = {}
        if cfg_path:
            try:
                cfg = json.loads(cfg_path.read_text(encoding="utf-8"))
            except Exception as exc:
                logger.warning(f"Failed to parse config at {cfg_path}: {exc}")
                cfg = {}

        exchange = cfg.get("exchange", {}) if isinstance(cfg, dict) else {}

        def _expand_env(value: Any) -> str:
            if not isinstance(value, str):
                return ""
            text = value.strip()
            if not text:
                return ""
            # Support "$VAR" or "${VAR}" indirections.
            if text.startswith("$"):
                key = text[1:].strip("{}")
                return os.getenv(key, "")
            return text

        raw_key = exchange.get("key", "")
        raw_secret = exchange.get("secret", "")
        raw_passphrase = exchange.get("password", "")

        key = _expand_env(raw_key)
        secret = _expand_env(raw_secret)
        passphrase = _expand_env(raw_passphrase)

        creds_status = {
            "key": "configured" if key else "missing",
            "secret": "configured" if secret else "missing",
            "passphrase": "configured" if passphrase else "missing",
        }
        missing = [k for k, v in creds_status.items() if v == "missing"]

        connection: dict[str, Any]
        if missing:
            connection = {
                "state": "error",
                "detail": f"Missing credentials: {', '.join(missing)}",
                "code": None,
            }
        else:
            # We keep this probe lightweight; full private signing is handled elsewhere.
            connection = {
                "state": "configured",
                "detail": "Credentials present (not validated)",
                "code": None,
            }

        return {
            "connection": connection,
            "credentials": creds_status,
            "config_path": str(cfg_path) if cfg_path else None,
            "timestamp": time.time(),
        }
    except Exception as e:
        logger.error(f"Failed to get OKX connection status: {e}", exc_info=True)
        return {
            "connection": {"state": "error", "detail": str(e)},
            "credentials": {},
            "timestamp": time.time(),
        }


# Trading System API endpoints
# These endpoints replace the legacy Dash-based dashboard modules and are used by UI-TARS native pages.
def _ensure_repo_src_on_path() -> None:
    """Ensure `<repo>/src` is importable as `quantsys.*` for optional trading system APIs."""
    try:
        import sys

        repo_root = get_repo_root()
        src_path = repo_root / "src"
        src_str = str(src_path)
        if src_str not in sys.path:
            sys.path.insert(0, src_str)
    except Exception:
        # Best-effort: imports below will error with a helpful message.
        pass


# ========== 1. AccountService ==========
@app.get("/api/account/balance")
async def get_account_balance(
    exchange: str = "okx",
    trading_mode: str = "drill",
    token: dict = Depends(verify_token),
):
    """Get account balance."""
    try:
        _ensure_repo_src_on_path()
        from quantsys.execution.account_service import AccountService

        account_service = AccountService(exchange=exchange, trading_mode=trading_mode)
        balance = account_service.get_balance()
        return {"success": True, "balance": balance, "timestamp": datetime.now().isoformat()}
    except Exception as e:
        logger.error(f"Failed to get account balance: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/account/positions")
async def get_account_positions(
    exchange: str = "okx",
    trading_mode: str = "drill",
    symbol: str | None = None,
    token: dict = Depends(verify_token),
):
    """Get account positions (optionally for a single symbol)."""
    try:
        _ensure_repo_src_on_path()
        from quantsys.execution.account_service import AccountService

        account_service = AccountService(exchange=exchange, trading_mode=trading_mode)
        if symbol:
            position = account_service.get_position(symbol)
            positions = {symbol: position} if position != 0.0 else {}
        else:
            account_state = account_service.get_account_state()
            positions = getattr(account_state, "positions", {})
        return {"success": True, "positions": positions, "timestamp": datetime.now().isoformat()}
    except Exception as e:
        logger.error(f"Failed to get account positions: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/account/summary")
async def get_account_summary(
    exchange: str = "okx",
    trading_mode: str = "drill",
    symbol: str | None = None,
    token: dict = Depends(verify_token),
):
    """Get account summary (balance/equity/positions)."""
    try:
        _ensure_repo_src_on_path()
        from quantsys.execution.account_service import AccountService

        account_service = AccountService(exchange=exchange, trading_mode=trading_mode)
        account_state = account_service.get_account_state(symbol=symbol)
        return {
            "success": True,
            "balance": getattr(account_state, "balance", None),
            "equity": getattr(account_state, "equity", None),
            "total_position": getattr(account_state, "total_position", None),
            "leverage": getattr(account_state, "leverage", None),
            "positions": getattr(account_state, "positions", {}),
            "timestamp": datetime.now().isoformat(),
        }
    except Exception as e:
        logger.error(f"Failed to get account summary: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


# ========== 2. RiskGate ==========
@app.get("/api/risk/status")
async def get_risk_gate_status(token: dict = Depends(verify_token)):
    """Get risk gate status (placeholder)."""
    try:
        return {
            "success": True,
            "status": "ACTIVE",
            "enabled": True,
            "timestamp": datetime.now().isoformat(),
        }
    except Exception as e:
        logger.error(f"Failed to get risk gate status: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/risk/history")
async def get_risk_history(limit: int = 100, token: dict = Depends(verify_token)):
    """Get risk check history (placeholder)."""
    try:
        return {
            "success": True,
            "history": [],
            "limit": limit,
            "timestamp": datetime.now().isoformat(),
        }
    except Exception as e:
        logger.error(f"Failed to get risk history: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/risk/statistics")
async def get_risk_statistics(token: dict = Depends(verify_token)):
    """Get risk statistics (placeholder)."""
    try:
        return {
            "success": True,
            "statistics": {
                "total_checks": 0,
                "passed": 0,
                "blocked": 0,
                "pass_rate": 0.0,
                "blocked_reasons": {},
            },
            "timestamp": datetime.now().isoformat(),
        }
    except Exception as e:
        logger.error(f"Failed to get risk statistics: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.post("/api/risk/check")
async def check_risk(
    payload: dict[str, Any],
    token: dict = Depends(verify_token),
):
    """Manually trigger a risk check (for UI testing)."""
    try:
        if not payload:
            raise HTTPException(status_code=400, detail="Request body is required")

        symbol = payload.get("symbol")
        side = payload.get("side")
        amount = float(payload.get("amount", 0))
        price = float(payload.get("price", 0))
        if not all([symbol, side, amount, price]):
            raise HTTPException(status_code=400, detail="Missing required fields: symbol/side/amount/price")

        exchange = payload.get("exchange", "okx")
        trading_mode = payload.get("trading_mode", "drill")

        _ensure_repo_src_on_path()
        from quantsys.common.risk_manager import RiskManager
        from quantsys.execution.account_service import AccountService
        from quantsys.execution.risk_gate import RiskGate

        risk_manager = RiskManager({})
        account_service = AccountService(exchange=exchange, trading_mode=trading_mode)
        risk_gate = RiskGate(risk_manager=risk_manager, account_service=account_service)

        verdict = risk_gate.check_order(symbol, side, amount, price)
        is_allowed = risk_gate.is_order_allowed(symbol, side, amount, price)

        return {
            "success": True,
            "allowed": is_allowed,
            "verdict": {
                "is_blocked": getattr(verdict, "is_blocked", False),
                "allow_open": getattr(verdict, "allow_open", True),
                "allow_reduce": getattr(verdict, "allow_reduce", True),
                "blocked_reason": getattr(verdict, "blocked_reason", None),
            },
            "timestamp": datetime.now().isoformat(),
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Risk check failed: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


# ========== 3. SignalBus ==========
@app.get("/api/signals/latest")
async def get_latest_signals(
    limit: int = 10,
    symbol: str | None = None,
    token: dict = Depends(verify_token),
):
    """Get latest trading signals."""
    try:
        _ensure_repo_src_on_path()
        from quantsys.strategy.signal_bus import get_signal_bus

        signal_bus = get_signal_bus()
        signals = signal_bus.get_signal_history(symbol=symbol, limit=limit)
        return {
            "success": True,
            "signals": [s.to_dict() for s in signals],
            "count": len(signals),
            "timestamp": datetime.now().isoformat(),
        }
    except Exception as e:
        logger.error(f"Failed to get latest signals: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/signals/history")
async def get_signal_history(
    limit: int = 100,
    symbol: str | None = None,
    signal_type: str | None = None,
    token: dict = Depends(verify_token),
):
    """Get signal history."""
    try:
        _ensure_repo_src_on_path()
        from quantsys.strategy.signal_bus import get_signal_bus

        signal_bus = get_signal_bus()
        signals = signal_bus.get_signal_history(symbol=symbol, limit=limit)
        if signal_type:
            signals = [s for s in signals if getattr(getattr(s, "signal_type", None), "value", None) == signal_type]
        return {
            "success": True,
            "signals": [s.to_dict() for s in signals],
            "count": len(signals),
            "timestamp": datetime.now().isoformat(),
        }
    except Exception as e:
        logger.error(f"Failed to get signal history: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/signals/statistics")
async def get_signal_statistics(token: dict = Depends(verify_token)):
    """Get signal statistics."""
    try:
        _ensure_repo_src_on_path()
        from quantsys.strategy.signal_bus import get_signal_bus

        signal_bus = get_signal_bus()
        signals = signal_bus.get_signal_history(limit=1000)

        stats: dict[str, Any] = {
            "total": len(signals),
            "by_type": {},
            "by_strategy": {},
            "by_symbol": {},
        }

        for signal in signals:
            stype = getattr(getattr(signal, "signal_type", None), "value", None) or "unknown"
            stats["by_type"][stype] = stats["by_type"].get(stype, 0) + 1

            strategy_id = getattr(signal, "strategy_id", None) or "unknown"
            stats["by_strategy"][strategy_id] = stats["by_strategy"].get(strategy_id, 0) + 1

            sym = getattr(signal, "symbol", None) or "unknown"
            stats["by_symbol"][sym] = stats["by_symbol"].get(sym, 0) + 1

        return {"success": True, "statistics": stats, "timestamp": datetime.now().isoformat()}
    except Exception as e:
        logger.error(f"Failed to get signal statistics: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


# ========== 4. OrderExecutor ==========
@app.get("/api/orders/status")
async def get_order_status(token: dict = Depends(verify_token)):
    """Get order execution status (placeholder)."""
    try:
        _ensure_repo_src_on_path()
        from quantsys.execution.order_ids import OrderIdManager

        _ = OrderIdManager()
        return {
            "success": True,
            "status": {"pending": 0, "executing": 0, "completed": 0, "failed": 0},
            "timestamp": datetime.now().isoformat(),
        }
    except Exception as e:
        logger.error(f"Failed to get order status: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/orders/history")
async def get_order_history(limit: int = 100, token: dict = Depends(verify_token)):
    """Get order execution history (placeholder)."""
    try:
        _ensure_repo_src_on_path()
        from quantsys.execution.order_ids import OrderIdManager

        _ = OrderIdManager()
        return {
            "success": True,
            "orders": [],
            "count": 0,
            "limit": limit,
            "timestamp": datetime.now().isoformat(),
        }
    except Exception as e:
        logger.error(f"Failed to get order history: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/orders/statistics")
async def get_order_statistics(token: dict = Depends(verify_token)):
    """Get order execution statistics (placeholder)."""
    try:
        return {
            "success": True,
            "statistics": {"total": 0, "success_rate": 0.0, "avg_execution_time": 0.0, "failed_count": 0},
            "timestamp": datetime.now().isoformat(),
        }
    except Exception as e:
        logger.error(f"Failed to get order statistics: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


# ========== 5. StateStorage ==========
@app.get("/api/state/orders")
async def get_state_orders(
    storage_type: str = "file",
    storage_dir: str = "data/state",
    token: dict = Depends(verify_token),
):
    """Get stored orders (placeholder)."""
    try:
        _ensure_repo_src_on_path()
        from quantsys.execution.state_storage import StateStorageFactory

        _ = StateStorageFactory.create(storage_type=storage_type, storage_dir=storage_dir)
        return {
            "success": True,
            "orders": {},
            "count": 0,
            "timestamp": datetime.now().isoformat(),
        }
    except Exception as e:
        logger.error(f"Failed to get state orders: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/state/positions")
async def get_state_positions(
    storage_type: str = "file",
    storage_dir: str = "data/state",
    token: dict = Depends(verify_token),
):
    """Get stored positions."""
    try:
        _ensure_repo_src_on_path()
        from quantsys.execution.state_storage import StateStorageFactory

        state_storage = StateStorageFactory.create(storage_type=storage_type, storage_dir=storage_dir)
        positions = state_storage.get_all_positions()
        return {
            "success": True,
            "positions": positions,
            "count": len(positions) if hasattr(positions, "__len__") else None,
            "timestamp": datetime.now().isoformat(),
        }
    except Exception as e:
        logger.error(f"Failed to get state positions: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/state/portfolio")
async def get_state_portfolio(
    storage_type: str = "file",
    storage_dir: str = "data/state",
    token: dict = Depends(verify_token),
):
    """Get portfolio snapshot."""
    try:
        _ensure_repo_src_on_path()
        from quantsys.execution.state_storage import StateStorageFactory

        state_storage = StateStorageFactory.create(storage_type=storage_type, storage_dir=storage_dir)
        portfolio = state_storage.get_portfolio() or {}
        return {"success": True, "portfolio": portfolio, "timestamp": datetime.now().isoformat()}
    except Exception as e:
        logger.error(f"Failed to get portfolio: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


# ========== 6. Exceptions ==========
@app.get("/api/exceptions/statistics")
async def get_exception_statistics(token: dict = Depends(verify_token)):
    """Get exception statistics (placeholder)."""
    try:
        return {
            "success": True,
            "statistics": {"total": 0, "by_type": {}, "recent_count": 0},
            "timestamp": datetime.now().isoformat(),
        }
    except Exception as e:
        logger.error(f"Failed to get exception statistics: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/exceptions/history")
async def get_exception_history(limit: int = 100, type: str | None = None, token: dict = Depends(verify_token)):
    """Get exception history (placeholder)."""
    try:
        return {
            "success": True,
            "exceptions": [],
            "count": 0,
            "limit": limit,
            "type": type,
            "timestamp": datetime.now().isoformat(),
        }
    except Exception as e:
        logger.error(f"Failed to get exception history: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


# ========== 7. ExchangeAdapter ==========
@app.get("/api/exchange/status")
async def get_exchange_status(token: dict = Depends(verify_token)):
    """Get exchange adapter status (placeholder)."""
    try:
        return {
            "success": True,
            "status": "CONNECTED",
            "exchange": "okx",
            "timestamp": datetime.now().isoformat(),
        }
    except Exception as e:
        logger.error(f"Failed to get exchange status: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/exchange/statistics")
async def get_exchange_statistics(token: dict = Depends(verify_token)):
    """Get exchange request statistics (placeholder)."""
    try:
        return {
            "success": True,
            "statistics": {"total_requests": 0, "successful": 0, "failed": 0, "retries": 0},
            "timestamp": datetime.now().isoformat(),
        }
    except Exception as e:
        logger.error(f"Failed to get exchange statistics: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


# ========== 8. OrderValidator ==========
@app.get("/api/validator/statistics")
@cached(prefix="validator", ttl=10)  # ä¼˜åŒ–ï¼šæ·»åŠ ç¼“å­˜ï¼Œå‡å°‘é‡å¤è®¡ç®—
async def get_validator_statistics(token: dict = Depends(verify_token)):
    """Get order validation statistics (placeholder)."""
    try:
        # ä¼˜åŒ–ï¼šå¿«é€Ÿè¿”å›ï¼Œä¸è¿›è¡Œè€—æ—¶æ“ä½œ
        # å¦‚æœå°†æ¥éœ€è¦æŸ¥è¯¢æ•°æ®åº“ï¼Œåº”è¯¥ä½¿ç”¨ç¼“å­˜æˆ–å¼‚æ­¥æŸ¥è¯¢
        return {
            "success": True,
            "statistics": {"total_validations": 0, "passed": 0, "failed": 0, "pass_rate": 0.0},
            "timestamp": datetime.now().isoformat(),
        }
    except Exception as e:
        logger.error(f"Failed to get validator statistics: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


def _require_ata_admin_request(request: Request) -> None:
    """REST ä¾§ç®¡ç†å‘˜ç¡¬æ ¡éªŒï¼ˆfail-closedï¼‰ï¼šå¿…é¡»å·²ç™»å½•ä¸” role=adminï¼ˆåŸºäº auth_token cookieï¼‰ã€‚"""
    token = request.cookies.get("auth_token")
    if not token:
        raise HTTPException(status_code=403, detail="ADMIN_REQUIRED: missing auth_token cookie")
    payload = auth_service.verify_token(token)
    if not payload or payload.get("role") != UserRole.ADMIN.value:
        raise HTTPException(status_code=403, detail="ADMIN_REQUIRED: not an admin user")


@app.post("/api/freqtrade/webserver/start")
async def start_freqtrade_webserver():
    """å¯åŠ¨Freqtrade WebServerï¼ˆæ— éœ€è®¤è¯ï¼Œç”¨äºè‡ªåŠ¨å¯åŠ¨å’Œç®¡ç†ï¼‰"""
    success, message = freqtrade_service.start_webserver()
    if success:
        return {"success": True, "message": message}
    else:
        raise HTTPException(status_code=500, detail=message)


@app.post("/api/freqtrade/webserver/stop")
async def stop_freqtrade_webserver():
    """åœæ­¢Freqtrade WebServerï¼ˆæ— éœ€è®¤è¯ï¼Œç”¨äºè‡ªåŠ¨ç®¡ç†ï¼‰"""
    success, message = freqtrade_service.stop_webserver()
    if success:
        return {"success": True, "message": message}
    else:
        raise HTTPException(status_code=500, detail=message)


@app.post("/api/freqtrade/trade/start")
async def start_freqtrade_trade(
    request: Request,
    strategy: str | None = None,
    dry_run: bool = True,
    passphrase: str | None = None,
    token: dict = Depends(verify_token),
):
    """å¯åŠ¨Freqtradeäº¤æ˜“è¿›ç¨‹"""
    _require_ata_admin_request(request)
    success, message = freqtrade_service.start_trade(
        strategy=strategy, dry_run=dry_run, passphrase=passphrase
    )
    if success:
        return {"success": True, "message": message}
    else:
        raise HTTPException(status_code=500, detail=message)


@app.post("/api/freqtrade/trade/stop")
async def stop_freqtrade_trade(request: Request, token: dict = Depends(verify_token)):
    """åœæ­¢Freqtradeäº¤æ˜“è¿›ç¨‹"""
    _require_ata_admin_request(request)
    success, message = freqtrade_service.stop_trade()
    if success:
        return {"success": True, "message": message}
    else:
        raise HTTPException(status_code=500, detail=message)


@app.get("/api/freqtrade/logs")
async def get_freqtrade_logs(
    log_type: str = "webserver",
    lines: int = 100,
    request: Request = None,
    token: dict = Depends(verify_token),
):
    """è·å–Freqtradeæ—¥å¿—"""
    if request is not None:
        _require_ata_admin_request(request)
    if log_type not in ["webserver", "trade"]:
        raise HTTPException(status_code=400, detail="log_type must be 'webserver' or 'trade'")

    logs = freqtrade_service.get_logs(log_type=log_type, lines=lines)
    return {"logs": logs, "log_type": log_type, "lines": lines}


# Chart API endpoints
@app.get("/api/charts/trading")
@cached(prefix="charts", ttl=60)  # ç¼“å­˜60ç§’
async def get_trading_chart(
    symbol: str | None = None,
    timeframe: str = "1h",
    limit: int = 100,
    start_time: str | None = None,
    end_time: str | None = None,
    token: dict = Depends(verify_token),
):
    """è·å–äº¤æ˜“æ•°æ®å›¾è¡¨"""
    data = chart_service.get_trading_data(
        symbol=symbol, timeframe=timeframe, limit=limit, start_time=start_time, end_time=end_time
    )
    return data


@app.get("/api/charts/performance")
@cached(prefix="charts", ttl=30)  # ç¼“å­˜30ç§’
async def get_performance_chart(
    days: int = 30, metrics: str | None = None, token: dict = Depends(verify_token)
):
    """è·å–æ€§èƒ½æ•°æ®å›¾è¡¨"""
    metrics_list = metrics.split(",") if metrics else None
    data = chart_service.get_performance_data(days=days, metrics=metrics_list)
    return data


@app.post("/api/charts/save")
async def save_chart_config(
    chart_id: str,
    chart_type: str,
    title: str,
    config: dict[str, Any],
    token: dict = Depends(verify_token),
):
    """ä¿å­˜å›¾è¡¨é…ç½®"""
    success = chart_service.save_chart_config(
        chart_id=chart_id, chart_type=chart_type, title=title, config=config
    )
    if success:
        return {"success": True, "chart_id": chart_id}
    else:
        raise HTTPException(status_code=500, detail="Failed to save chart config")


@app.get("/api/charts/config/{chart_id}")
async def get_chart_config(chart_id: str, token: dict = Depends(verify_token)):
    """è·å–å›¾è¡¨é…ç½®"""
    config = chart_service.get_chart_config(chart_id)
    if config:
        return config
    else:
        raise HTTPException(status_code=404, detail="Chart config not found")


@app.get("/api/charts/configs")
async def list_chart_configs(chart_type: str | None = None, token: dict = Depends(verify_token)):
    """åˆ—å‡ºæ‰€æœ‰å›¾è¡¨é…ç½®"""
    configs = chart_service.list_chart_configs(chart_type=chart_type)
    return {"charts": configs, "total": len(configs)}


@app.delete("/api/charts/config/{chart_id}")
async def delete_chart_config(chart_id: str, token: dict = Depends(verify_token)):
    """åˆ é™¤å›¾è¡¨é…ç½®"""
    success = chart_service.delete_chart_config(chart_id)
    if success:
        return {"success": True, "chart_id": chart_id}
    else:
        raise HTTPException(status_code=500, detail="Failed to delete chart config")


@app.websocket("/ws/charts/{chart_id}")
async def websocket_chart_data(websocket: WebSocket, chart_id: str):
    """WebSocketå®æ—¶å›¾è¡¨æ•°æ®æ¨é€"""
    await websocket.accept()

    try:
        # è·å–å›¾è¡¨é…ç½®
        config = chart_service.get_chart_config(chart_id)
        if not config:
            await websocket.send_json({"error": "Chart config not found"})
            await websocket.close()
            return

        chart_type = config.get("chart_type", "performance")

        # å‘é€åˆå§‹æ•°æ®
        if chart_type == "trading":
            data = chart_service.get_trading_data(limit=100)
        elif chart_type == "performance":
            data = chart_service.get_performance_data(days=7)
        else:
            data = {"error": "Unknown chart type"}

        await websocket.send_json({"type": "initial", "data": data})

        # å®šæœŸæ¨é€æ›´æ–°ï¼ˆæ¯5ç§’ï¼‰
        import asyncio

        while True:
            await asyncio.sleep(5)

            if chart_type == "performance":
                # æ€§èƒ½æ•°æ®å®æ—¶æ›´æ–°
                data = chart_service.get_performance_data(days=7)
                await websocket.send_json({"type": "update", "data": data})
            elif chart_type == "trading":
                # äº¤æ˜“æ•°æ®æ›´æ–°ï¼ˆè¾ƒæ…¢ï¼Œ30ç§’ä¸€æ¬¡ï¼‰
                await asyncio.sleep(25)
                data = chart_service.get_trading_data(limit=100)
                await websocket.send_json({"type": "update", "data": data})

    except Exception as e:
        logger.error(f"WebSocket chart error: {e}")
        await websocket.send_json({"error": str(e)})
        await websocket.close()


@app.get("/.well-known/oauth-protected-resource")
async def oauth_protected_resource():
    """OAuth Protected Resource Metadata endpoint"""
    issuer = os.getenv(
        "OAUTH_ISSUER", "https://cognito-idp.ap-southeast-1.amazonaws.com/ap-southeast-1_abc123"
    )
    required_scopes = os.getenv("OAUTH_REQUIRED_SCOPES", "mcp.tools").split()

    return {
        "resource": "https://mcp.timquant.tech",
        "authorization_servers": [issuer],
        "scopes_supported": required_scopes,
    }


@app.get("/.well-known/openid-configuration")
async def openid_configuration():
    """OpenID Configuration discovery endpoint (redirects to Cognito)"""
    issuer = os.getenv(
        "OAUTH_ISSUER", "https://cognito-idp.ap-southeast-1.amazonaws.com/ap-southeast-1_abc123"
    )

    # Redirect to Cognito's OpenID configuration
    return RedirectResponse(url=f"{issuer}/.well-known/openid-configuration")


@app.get("/oauth2/authorize")
async def oauth_authorize(
    response_type: str,
    client_id: str,
    redirect_uri: str,
    scope: str | None = None,
    state: str | None = None,
):
    """Mock OAuth 2.0 Authorization endpoint"""
    # Generate a mock authorization code
    auth_code = "mock-auth-code-12345"

    # Redirect back to ChatGPT with the authorization code
    redirect_url = f"{redirect_uri}?code={auth_code}"
    if state:
        redirect_url += f"&state={state}"

    return RedirectResponse(url=redirect_url)


@app.post("/oauth2/token")
async def oauth_token():
    """Mock OAuth 2.0 Token endpoint"""
    # Return a mock JWT token response
    return {
        "access_token": "mock-jwt-token-12345",
        "token_type": "Bearer",
        "expires_in": 3600,
        "refresh_token": "mock-refresh-token-67890",
        "id_token": "mock-id-token-abcde",
        "scope": "openid profile email mcp.tools",
    }


@app.post("/oauth2/client/register")
async def oauth_client_register():
    """Mock OAuth 2.0 Dynamic Client Registration endpoint"""
    # Return a valid client registration response with required fields
    return {
        "client_id": "mock-client-id-12345",
        "client_secret": "mock-client-secret-67890",
        "client_id_issued_at": 1737043200,
        "client_secret_expires_at": 0,
        "redirect_uris": ["https://chat.openai.com/aiproxy/generic-oauth/callback"],
        "grant_types": ["authorization_code", "refresh_token"],
        "response_types": ["code"],
        "client_name": "ChatGPT",
        "client_uri": "https://chat.openai.com",
        "logo_uri": "https://chat.openai.com/favicon.ico",
        "scope": "openid profile email mcp.tools",
    }


@app.get("/.well-known/jwks.json")
async def jwks_endpoint():
    """Mock JWKS endpoint for JWT validation"""
    return {
        "keys": [
            {
                "kty": "RSA",
                "use": "sig",
                "kid": "mock-key-id-1",
                "alg": "RS256",
                "n": "mock-rsa-modulus-12345",
                "e": "AQAB",
            }
        ]
    }


@app.get("/.well-known/oauth-authorization-server")
async def oauth_authorization_server():
    """OAuth Authorization Server Metadata endpoint"""
    issuer = os.getenv("OAUTH_ISSUER", "https://mcp.timquant.tech")

    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(f"{issuer}/.well-known/openid-configuration", timeout=10.0)
            response.raise_for_status()
            openid_config = response.json()

        return {
            "issuer": issuer,
            "authorization_endpoint": openid_config.get("authorization_endpoint"),
            "token_endpoint": openid_config.get("token_endpoint"),
            "jwks_uri": openid_config.get("jwks_uri"),
            "registration_endpoint": "https://mcp.timquant.tech/oauth2/client/register",
            "response_types_supported": openid_config.get("response_types_supported"),
            "grant_types_supported": openid_config.get("grant_types_supported"),
            "subject_types_supported": openid_config.get("subject_types_supported"),
            "id_token_signing_alg_values_supported": openid_config.get(
                "id_token_signing_alg_values_supported"
            ),
            "scopes_supported": openid_config.get("scopes_supported"),
            "token_endpoint_auth_methods_supported": openid_config.get(
                "token_endpoint_auth_methods_supported"
            ),
            "code_challenge_methods_supported": openid_config.get(
                "code_challenge_methods_supported"
            ),
        }
    except Exception:
        # Return a minimal response if OpenID config is not reachable
        return {
            "issuer": issuer,
            "authorization_endpoint": "https://mcp.timquant.tech/oauth2/authorize",
            "token_endpoint": "https://mcp.timquant.tech/oauth2/token",
            "jwks_uri": "https://mcp.timquant.tech/.well-known/jwks.json",
            "registration_endpoint": "https://mcp.timquant.tech/oauth2/client/register",
            "scopes_supported": ["openid", "profile", "email", "mcp.tools"],
        }


@app.api_route("/mcp", methods=["GET", "POST"])
async def mcp_endpoint(
    request: Request, authorization: str | None = Header(None), caller: str = Depends(get_caller)
):
    # Handle authentication manually inside the endpoint
    resource_metadata_url = "https://mcp.timquant.tech/.well-known/oauth-protected-resource"
    required_scope = "mcp.tools"

    # Set WWW-Authenticate header for all responses
    headers = {
        "WWW-Authenticate": f'Bearer resource_metadata="{resource_metadata_url}", scope="{required_scope}"'
    }

    # Check if it's a GET request
    if request.method == "GET":
        # Return valid response for GET requests (don't return 405)
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": "0",  # Use string "0" instead of None (Cursor doesn't accept null)
                "result": {
                    "message": "MCP Server is running",
                    "status": "healthy",
                    "version": "0.1.0",
                    "supported_methods": [
                        "initialize",
                        "tools/list",
                        "tools/call",
                        "resources/list",
                        "prompts/list",
                    ],
                },
            },
            status_code=200,
            headers=headers,
        )

    # For POST requests, process normally
    try:
        # ä¼˜å…ˆå°è¯•ä½¿ç”¨FastAPIçš„è‡ªåŠ¨JSONè§£æï¼ˆæœ€å¯é ï¼‰
        import json
        import re

        try:
            raw_body = await request.json()
        except Exception:
            # å¦‚æœFastAPIè§£æå¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨è§£æ
            # è·å–åŸå§‹è¯·æ±‚ä½“
            raw_bytes = await request.body()
            raw_text = raw_bytes.decode("utf-8", errors="replace")

            cleaned_text = raw_text.strip()

            # 1. ç§»é™¤é¦–å°¾å¯èƒ½çš„å¼•å·
            if (cleaned_text.startswith("'") and cleaned_text.endswith("'")) or (
                cleaned_text.startswith('"') and cleaned_text.endswith('"')
            ):
                cleaned_text = cleaned_text[1:-1]

            # 2. å¤„ç†è½¬ä¹‰å­—ç¬¦ - å¤„ç†shellæˆ–ä»£ç†è½¬ä¹‰çš„é—®é¢˜
            # å¦‚æœæ–‡æœ¬åŒ…å«è½¬ä¹‰çš„ç©ºæ ¼ã€å†’å·ç­‰ï¼ˆå¦‚ \ jsonrpc\:ï¼‰ï¼Œéœ€è¦æ¸…ç†
            if "\\ " in cleaned_text or "\\:" in cleaned_text or "\\{" in cleaned_text:
                # å¤„ç†å¸¸è§çš„è½¬ä¹‰æ¨¡å¼ï¼š\ åè·Ÿç©ºæ ¼ã€å†’å·ã€å¤§æ‹¬å·ç­‰
                cleaned_text = re.sub(r"\\([ :{}])", r"\1", cleaned_text)

            # 3. å¤„ç†åŒé‡è½¬ä¹‰é—®é¢˜
            if "\\\\" in cleaned_text or (cleaned_text.count("\\") > cleaned_text.count('"') / 2):
                # å¤„ç†åŒé‡è½¬ä¹‰ï¼šå°† \\ æ›¿æ¢ä¸º \ï¼Œä½†ä¿ç•™æœ‰æ•ˆçš„JSONè½¬ä¹‰åºåˆ—
                # å…ˆä¿æŠ¤æœ‰æ•ˆçš„JSONè½¬ä¹‰åºåˆ—
                cleaned_text = (
                    cleaned_text.replace("\\\\n", "\n")
                    .replace("\\\\t", "\t")
                    .replace("\\\\r", "\r")
                )
                # ç„¶åå¤„ç†å…¶ä»–è½¬ä¹‰ï¼ˆä½†ä¿ç•™JSONæ ‡å‡†è½¬ä¹‰ï¼‰
                cleaned_text = re.sub(r'\\([^"\\/bfnrtu])', r"\1", cleaned_text)

            # 3. å°è¯•è§£æ
            try:
                raw_body = json.loads(cleaned_text)
            except json.JSONDecodeError:
                # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œå°è¯•æ›´æ¿€è¿›çš„æ¸…ç†ï¼ˆä»…ä½œä¸ºæœ€åæ‰‹æ®µï¼‰
                # ç§»é™¤æ‰€æœ‰åæ–œæ è½¬ä¹‰ï¼ˆé™¤äº†JSONæ ‡å‡†è½¬ä¹‰ï¼‰
                cleaned_text = re.sub(r'\\(?!["\\/bfnrt]|u[0-9a-fA-F]{4})', "", cleaned_text)
                try:
                    raw_body = json.loads(cleaned_text)
                except json.JSONDecodeError as e:
                    # å¦‚æœæ‰€æœ‰è§£æéƒ½å¤±è´¥ï¼Œè¿”å›æœ‰æ„ä¹‰çš„é”™è¯¯
                    error_response = {
                        "jsonrpc": "2.0",
                        "id": "0",  # Use string "0" instead of None (Cursor doesn't accept null)
                        "error": {"code": -32700, "message": f"Parse error: {str(e)}"},
                    }
                    return JSONResponse(content=error_response, status_code=400, headers=headers)

        # Extract request_id and method from raw_body as dict
        request_id = raw_body.get("id") if isinstance(raw_body, dict) else None
        # Convert None to "0" for Cursor compatibility (Cursor doesn't accept null id)
        if request_id is None:
            request_id = "0"
        method = raw_body.get("method") if isinstance(raw_body, dict) else None
        params = raw_body.get("params", {}) if isinstance(raw_body, dict) else {}

        print(f"DEBUG: Extracted - method: {method}, request_id: {request_id}, params: {params}")

        # Check if authentication is disabled
        auth_mode = os.getenv("AUTH_MODE", "none").lower()
        authentication_required = auth_mode not in ["none", "noauth", "disabled"]

        if authentication_required:
            # Normal authentication flow
            if authorization:
                if authorization.startswith("Bearer "):
                    token = authorization[7:]

                    if auth_mode == "oauth":
                        try:
                            # Use OAuth JWT validation
                            token = await verify_jwt(token)
                        except Exception as e:
                            # Authentication failed, return JSON-RPC error with _meta
                            error_response = {
                                "jsonrpc": "2.0",
                                "id": request_id,
                                "error": {"code": 403, "message": f"Invalid token: {str(e)}"},
                            }
                            return JSONResponse(
                                content=error_response, status_code=403, headers=headers
                            )
                    else:
                        # Use legacy Bearer token validation
                        expected_token = os.getenv("MCP_BUS_TOKEN")
                        if expected_token and token != expected_token:
                            error_response = {
                                "jsonrpc": "2.0",
                                "id": request_id,
                                "error": {"code": 403, "message": "Invalid token"},
                            }
                            return JSONResponse(
                                content=error_response, status_code=403, headers=headers
                            )
                else:
                    # Invalid Authorization header format
                    error_response = {
                        "jsonrpc": "2.0",
                        "id": request_id,
                        "error": {"code": 401, "message": "Invalid Authorization header format"},
                    }
                    return JSONResponse(content=error_response, status_code=401, headers=headers)

            # If we get here without a token and authentication is required, return 401
            error_response = {
                "jsonrpc": "2.0",
                "id": request_id,
                "error": {"code": 401, "message": "Missing Authorization header"},
            }
            return JSONResponse(content=error_response, status_code=401, headers=headers)

        # Authentication successful, process the request
        if method == "tools/list":
            result = await tools_list()
            # Set the correct request ID
            result["id"] = request_id
            # Remove _meta field if present (TRAE doesn't support it)
            if "_meta" in result:
                del result["_meta"]
            return JSONResponse(content=result, headers=headers)
        elif method == "tools/call":
            result = await tools_call(params, caller, request)
            # Set the correct request ID from the request
            result["id"] = request_id
            # Remove _meta field if present (TRAE doesn't support it)
            if "_meta" in result:
                del result["_meta"]
            return JSONResponse(content=result, headers=headers)
        elif method == "initialize":
            # GPT connector initialization request - use correct GPT format with serverInfo
            # Extract requested protocol version if provided
            requested_protocol = (
                params.get("protocolVersion") if isinstance(params, dict) else "2.0"
            )

            result = {
                "jsonrpc": "2.0",
                "id": request_id,
                "result": {
                    "protocolVersion": requested_protocol,
                    "serverInfo": {"name": "TimQuant MCP Server", "version": "1.0.0"},
                    "capabilities": {"tools": {"enabled": True}},
                },
            }
            # Note: Removed _meta field as TRAE doesn't support it
            # Authentication info is still available in HTTP headers
            return JSONResponse(content=result, headers=headers)
        elif method == "resources/list":
            # Support resources/list method for ChatGPT connector
            result = {"jsonrpc": "2.0", "id": request_id, "result": {"resources": []}}
            # Note: Removed _meta field as TRAE doesn't support it
            return JSONResponse(content=result, headers=headers)
        elif method == "prompts/list":
            # Support prompts/list method for ChatGPT connector
            result = {"jsonrpc": "2.0", "id": request_id, "result": {"prompts": []}}
            # Note: Removed _meta field as TRAE doesn't support it
            return JSONResponse(content=result, headers=headers)
        elif method == "notifications/initialized":
            # Handle notifications/initialized (JSON-RPC notification - no id required)
            # Return 200 OK with no body for notifications
            return JSONResponse(content={}, status_code=200, headers=headers)
        else:
            # For unknown methods, return appropriate error
            error_response = {
                "jsonrpc": "2.0",
                "id": request_id,
                "error": {"code": -32601, "message": "Method not found"},
            }
            return JSONResponse(content=error_response, status_code=400, headers=headers)
    except Exception as e:
        # Create JSON-RPC error response with _meta field
        print(f"DEBUG: Exception occurred: {type(e).__name__}: {str(e)}")
        import traceback

        traceback.print_exc()

        # Get request_id if available, otherwise use "0"
        request_id = (
            getattr(request, "request_id", None) if hasattr(request, "request_id") else None
        )
        if request_id is None:
            try:
                # Try to extract from request body if possible
                body = await request.body()
                if body:
                    try:
                        body_dict = json.loads(body.decode("utf-8"))
                        request_id = body_dict.get("id", "0")
                    except:
                        request_id = "0"
                else:
                    request_id = "0"
            except:
                request_id = "0"

        error_response = {
            "jsonrpc": "2.0",
            "id": request_id
            if request_id is not None
            else "0",  # Use string "0" instead of None (Cursor doesn't accept null)
            "error": {"code": 500, "message": f"Internal error: {str(e)}"},
        }
        return JSONResponse(content=error_response, status_code=500, headers=headers)


async def tools_list():
    # Complete tool list for both GPT and TRAE connectors
    tools = [
        {
            "name": "ping",
            "description": "Test connectivity with a simple ping response",
            "inputSchema": {"type": "object", "properties": {}, "additionalProperties": False},
        },
        {
            "name": "echo",
            "description": "Echo back the input text",
            "inputSchema": {
                "type": "object",
                "properties": {"text": {"type": "string", "description": "Text to echo back"}},
                "required": ["text"],
                "additionalProperties": False,
            },
        },
        {
            "name": "inbox_append",
            "description": "Append a new block to the daily inbox file (for GPT/TRAE communication)",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "date": {"type": "string", "description": "Date in YYYY-MM-DD format"},
                    "task_code": {
                        "type": "string",
                        "description": "Task identifier (e.g., TC-GPT-001)",
                    },
                    "source": {
                        "type": "string",
                        "description": "Source identifier (e.g., ChatGPT, TRAE)",
                    },
                    "text": {"type": "string", "description": "Content to append"},
                },
                "required": ["date", "task_code", "source", "text"],
                "additionalProperties": False,
            },
        },
        {
            "name": "admin_vault_put",
            "description": "ADMIN ONLY: store a secret document in docs/REPORT/ata/admin_vault/ (fail-closed if not admin)",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "doc_name": {"type": "string", "description": "Filename only, e.g. secrets.md"},
                    "content": {"type": "string", "description": "Document content"},
                },
                "required": ["doc_name", "content"],
                "additionalProperties": False,
            },
        },
        {
            "name": "admin_vault_get",
            "description": "ADMIN ONLY: read a secret document from docs/REPORT/ata/admin_vault/ (fail-closed if not admin)",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "doc_name": {"type": "string", "description": "Filename only, e.g. secrets.md"}
                },
                "required": ["doc_name"],
                "additionalProperties": False,
            },
        },
        {
            "name": "admin_whoami",
            "description": "Return whether current request is recognized as ATA admin (debug helper)",
            "inputSchema": {"type": "object", "properties": {}, "additionalProperties": False},
        },
        {
            "name": "inbox_tail",
            "description": "Read the last n lines or last block from the inbox (for GPT/TRAE communication)",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "date": {"type": "string", "description": "Date in YYYY-MM-DD format"},
                    "n": {
                        "type": "integer",
                        "description": "Number of lines to return",
                        "default": 50,
                    },
                },
                "required": ["date"],
                "additionalProperties": False,
            },
        },
        {
            "name": "board_get",
            "description": "Read the Program Board content (for task status tracking)",
            "inputSchema": {"type": "object", "properties": {}, "additionalProperties": False},
        },
        {
            "name": "board_set_status",
            "description": "Update task status and artifacts in the Program Board (for GPT/TRAE communication)",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "task_code": {"type": "string", "description": "Task identifier"},
                    "status": {"type": "string", "description": "New status value"},
                    "artifacts": {
                        "type": "string",
                        "description": "Artifacts/deliverables path",
                        "default": None,
                    },
                },
                "required": ["task_code", "status"],
                "additionalProperties": False,
            },
        },
        {
            "name": "ata_send",
            "description": "Send an ATA (Agent-to-Agent) message for communication between AI agents (Cursor, TRAE, ChatGPT)",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "taskcode": {
                        "type": "string",
                        "description": "Task code associated with the message",
                    },
                    "from_agent": {
                        "type": "string",
                        "description": "Source agent (e.g., Cursor, TRAE, ChatGPT) or dialog ID (e.g., 'Cursor-Dialog-1')",
                    },
                    "to_agent": {
                        "type": "string",
                        "description": "Target agent (e.g., Cursor, TRAE, ChatGPT) or dialog ID (e.g., 'Cursor-Dialog-2')",
                    },
                    "kind": {
                        "type": "string",
                        "description": "Message kind (e.g., request, ack, response)",
                    },
                    "payload": {"type": "object", "description": "Message payload content"},
                    "prev_sha256": {
                        "type": "string",
                        "description": "Previous message SHA256 for chain validation (optional)",
                    },
                    "priority": {
                        "type": "string",
                        "enum": ["low", "normal", "high", "urgent"],
                        "description": "Message priority level",
                        "default": "normal",
                    },
                    "requires_response": {
                        "type": "boolean",
                        "description": "Whether this message requires a response",
                        "default": True,
                    },
                    "context_hint": {
                        "type": "string",
                        "description": "Context hint for conversation continuity (optional)",
                    },
                },
                "required": ["taskcode", "from_agent", "to_agent", "kind", "payload"],
                "additionalProperties": False,
            },
        },
        {
            "name": "ata_receive",
            "description": "Receive ATA messages with optional filtering (for Cursor, TRAE, ChatGPT communication)",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "taskcode": {"type": "string", "description": "Filter by task code (optional)"},
                    "from_agent": {
                        "type": "string",
                        "description": "Filter by source agent (optional). Supports dialog IDs like 'Cursor-Dialog-1'",
                    },
                    "to_agent": {
                        "type": "string",
                        "description": "Filter by target agent (optional). Supports dialog IDs like 'Cursor-Dialog-1'",
                    },
                    "kind": {"type": "string", "description": "Filter by message kind (optional)"},
                    "priority": {
                        "type": "string",
                        "enum": ["low", "normal", "high", "urgent"],
                        "description": "Filter by priority level (optional)",
                    },
                    "status": {
                        "type": "string",
                        "enum": ["pending", "delivered", "read", "acked"],
                        "description": "Filter by message status (optional)",
                    },
                    "unread_only": {
                        "type": "boolean",
                        "description": "Return only unread messages",
                        "default": False,
                    },
                    "limit": {
                        "type": "integer",
                        "description": "Maximum number of messages to return",
                        "default": 50,
                    },
                    "include_context": {
                        "type": "boolean",
                        "description": "Include conversation context in response",
                        "default": False,
                    },
                },
                "required": [],
                "additionalProperties": False,
            },
        },
        {
            "name": "github_search",
            "description": "Search GitHub repositories, code, or issues",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "Search query"},
                    "search_type": {
                        "type": "string",
                        "enum": ["repositories", "code", "issues"],
                        "description": "Search type: repositories, code, or issues",
                        "default": "repositories",
                    },
                    "limit": {
                        "type": "integer",
                        "description": "Maximum number of results to return",
                        "default": 10,
                    },
                    "sort": {
                        "type": "string",
                        "description": "Sort option (stars, updated, etc.)",
                        "default": None,
                    },
                    "order": {
                        "type": "string",
                        "enum": ["asc", "desc"],
                        "description": "Sort order: asc or desc",
                        "default": "desc",
                    },
                },
                "required": ["query"],
                "additionalProperties": False,
            },
        },
        {
            "name": "dialog_register",
            "description": "Register a Cursor dialog (or other agent dialog) with a unique identity for ATA communication between different dialogs",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "agent_type": {
                        "type": "string",
                        "description": "Agent type (e.g., Cursor, GPT, TRAE)",
                        "default": "Cursor",
                    },
                    "dialog_name": {
                        "type": "string",
                        "description": "Optional dialog name/description",
                    },
                    "dialog_id": {
                        "type": "string",
                        "description": "Optional custom dialog ID (auto-generated if not provided, e.g., 'Cursor-Dialog-1')",
                    },
                },
                "additionalProperties": False,
            },
        },
        {
            "name": "dialog_list",
            "description": "List all registered dialogs (supports Cursor, GPT, and TRAE)",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "agent_type": {
                        "type": "string",
                        "description": "Filter by agent type (optional, e.g., Cursor, GPT, TRAE)",
                    }
                },
                "additionalProperties": False,
            },
        },
        {
            "name": "conversation_stats",
            "description": "Get conversation statistics for dialogs",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "dialog_id": {
                        "type": "string",
                        "description": "Filter by dialog ID (optional)",
                    },
                    "agent_type": {
                        "type": "string",
                        "description": "Filter by agent type (optional, e.g., Cursor, GPT, TRAE)",
                    },
                    "taskcode": {"type": "string", "description": "Filter by task code (optional)"},
                    "from_date": {
                        "type": "string",
                        "description": "Filter from date (YYYY-MM-DD, optional)",
                    },
                    "to_date": {
                        "type": "string",
                        "description": "Filter to date (YYYY-MM-DD, optional)",
                    },
                },
                "additionalProperties": False,
            },
        },
        {
            "name": "conversation_search",
            "description": "Search conversations by content",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "Search query"},
                    "dialog_id": {
                        "type": "string",
                        "description": "Filter by dialog ID (optional)",
                    },
                    "agent_type": {
                        "type": "string",
                        "description": "Filter by agent type (optional)",
                    },
                    "taskcode": {"type": "string", "description": "Filter by task code (optional)"},
                    "limit": {
                        "type": "integer",
                        "description": "Maximum number of results",
                        "default": 50,
                    },
                },
                "required": ["query"],
                "additionalProperties": False,
            },
        },
        {
            "name": "conversation_history",
            "description": "Get conversation history for a specific dialog",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "dialog_id": {
                        "type": "string",
                        "description": "Dialog ID (e.g., Cursor-Dialog-1, GPT-Dialog-1, TRAE-Dialog-1)",
                    },
                    "taskcode": {"type": "string", "description": "Filter by task code (optional)"},
                    "limit": {
                        "type": "integer",
                        "description": "Maximum number of messages",
                        "default": 100,
                    },
                    "include_context": {
                        "type": "boolean",
                        "description": "Include conversation context",
                        "default": False,
                    },
                },
                "required": ["dialog_id"],
                "additionalProperties": False,
            },
        },
        {
            "name": "conversation_mark",
            "description": "Mark conversation messages with a status (read, acked, archived)",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "dialog_id": {"type": "string", "description": "Dialog ID"},
                    "msg_ids": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "List of message IDs to mark",
                    },
                    "status": {
                        "type": "string",
                        "enum": ["read", "acked", "archived"],
                        "description": "Status to set",
                    },
                },
                "required": ["dialog_id", "msg_ids", "status"],
                "additionalProperties": False,
            },
        },
        {
            "name": "file_read",
            "description": "Read file content for sending in ATA messages (GPT-compatible, embeds full file content instead of just path)",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "file_path": {
                        "type": "string",
                        "description": "Relative file path from repo root (e.g., 'docs/README.md')",
                    },
                    "encoding": {
                        "type": "string",
                        "description": "File encoding: 'utf-8' for text files, 'binary' or 'base64' for binary files",
                        "default": "utf-8",
                    },
                    "max_size": {
                        "type": "integer",
                        "description": "Maximum file size in bytes (default 10MB)",
                        "default": 10485760,
                    },
                },
                "required": ["file_path"],
                "additionalProperties": False,
            },
        },
        {
            "name": "ata_send_with_file",
            "description": "Send ATA message with file content embedded (for GPT to read files directly, no local file access needed)",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "taskcode": {
                        "type": "string",
                        "description": "Task code associated with the message",
                    },
                    "from_agent": {
                        "type": "string",
                        "description": "Source agent (e.g., Cursor, GPT, TRAE) or dialog ID",
                    },
                    "to_agent": {
                        "type": "string",
                        "description": "Target agent (e.g., Cursor, GPT, TRAE) or dialog ID",
                    },
                    "message": {"type": "string", "description": "Optional message text"},
                    "file_path": {
                        "type": "string",
                        "description": "Relative file path from repo root to send (e.g., 'docs/README.md')",
                    },
                    "encoding": {
                        "type": "string",
                        "description": "File encoding: 'utf-8' for text, 'binary' or 'base64' for binary files",
                        "default": "utf-8",
                    },
                    "kind": {
                        "type": "string",
                        "description": "Message kind (e.g., request, ack, response)",
                        "default": "request",
                    },
                    "priority": {
                        "type": "string",
                        "enum": ["low", "normal", "high", "urgent"],
                        "description": "Message priority level",
                        "default": "normal",
                    },
                    "requires_response": {
                        "type": "boolean",
                        "description": "Whether this message requires a response",
                        "default": True,
                    },
                    "prev_sha256": {
                        "type": "string",
                        "description": "Previous message SHA256 for chain validation (optional)",
                    },
                    "context_hint": {
                        "type": "string",
                        "description": "Context hint for conversation continuity (optional)",
                    },
                },
                "required": ["taskcode", "from_agent", "to_agent", "file_path"],
                "additionalProperties": False,
            },
        },
        {
            "name": "task_create",
            "description": "Create a collaborative task with multiple agents",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "task_description": {"type": "string", "description": "Task description"},
                    "workflow_template": {
                        "type": "string",
                        "description": "Workflow template name (optional)",
                    },
                    "priority": {
                        "type": "string",
                        "enum": ["low", "normal", "high", "urgent"],
                        "description": "Task priority",
                        "default": "normal",
                    },
                    "timeout": {
                        "type": "number",
                        "description": "Task timeout in seconds (optional)",
                    },
                    "required_roles": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "Required roles (optional)",
                    },
                },
                "required": ["task_description"],
                "additionalProperties": False,
            },
        },
        {
            "name": "task_status",
            "description": "Query task status and progress",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "task_id": {"type": "string", "description": "Task ID"},
                    "include_subtasks": {
                        "type": "boolean",
                        "description": "Include subtask status",
                        "default": True,
                    },
                },
                "required": ["task_id"],
                "additionalProperties": False,
            },
        },
        {
            "name": "agent_register",
            "description": "ADMIN ONLY: register an agent for collaboration (ç”³è¯·åˆ¶åº¦ï¼šæ™®é€šç”¨æˆ·è¯·ç”¨ agent_apply)",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "agent_id": {"type": "string", "description": "Agent ID"},
                    "agent_type": {
                        "type": "string",
                        "description": "Agent type (Cursor, GPT, TRAE)",
                    },
                    "role": {"type": "string", "description": "Agent role"},
                    "capabilities": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "Agent capabilities",
                    },
                    "max_concurrent_tasks": {
                        "type": "integer",
                        "description": "Max concurrent tasks",
                        "default": 5,
                    },
                },
                "required": ["agent_id", "agent_type", "role", "capabilities"],
                "additionalProperties": False,
            },
        },
        {
            "name": "agent_apply",
            "description": "Apply for agent registration (pending approval by ATA admin)",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "agent_id": {"type": "string"},
                    "agent_type": {"type": "string"},
                    "role": {"type": "string"},
                    "capabilities": {"type": "array", "items": {"type": "string"}},
                    "max_concurrent_tasks": {"type": "integer", "default": 5},
                    "numeric_code": {"type": "integer"},
                    "send_enabled": {"type": "boolean"},
                    "note": {"type": "string"},
                },
                "required": ["agent_id", "agent_type", "role", "capabilities"],
                "additionalProperties": False,
            },
        },
        {
            "name": "agent_approve",
            "description": "ADMIN ONLY: approve a pending agent application and register it (ensures numeric_code uniqueness)",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "agent_id": {"type": "string"},
                    "numeric_code": {"type": "integer"},
                    "send_enabled": {"type": "boolean"},
                },
                "required": ["agent_id"],
                "additionalProperties": False,
            },
        },
        {
            "name": "ata_send_request",
            "description": "Request an ATA send (queued for ATA admin review/relay). Non-admin only.",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "taskcode": {"type": "string"},
                    "from_agent": {"type": "string"},
                    "to_agent": {"type": "string"},
                    "kind": {"type": "string"},
                    "payload": {"type": "object"},
                    "priority": {"type": "string", "default": "normal"},
                    "requires_response": {"type": "boolean", "default": True},
                    "context_hint": {"type": "string"},
                    "report_path": {"type": "string"},
                    "selftest_log_path": {"type": "string"},
                    "evidence_dir": {"type": "string"},
                },
                "required": ["taskcode", "from_agent", "to_agent", "payload"],
                "additionalProperties": False,
            },
        },
        {
            "name": "ata_send_review",
            "description": "ADMIN ONLY: approve/reject a pending ata_send_request. Approve triggers actual send.",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "request_id": {"type": "string"},
                    "action": {"type": "string"},
                    "reason": {"type": "string"},
                },
                "required": ["request_id", "action"],
                "additionalProperties": False,
            },
        },
        {
            "name": "workflow_execute",
            "description": "Execute a predefined workflow",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "workflow_name": {"type": "string", "description": "Workflow template name"},
                    "inputs": {"type": "object", "description": "Workflow inputs"},
                    "task_id": {"type": "string", "description": "Optional task ID"},
                },
                "required": ["workflow_name", "inputs"],
                "additionalProperties": False,
            },
        },
        {
            "name": "result_get",
            "description": "Get task results",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "task_id": {"type": "string", "description": "Task ID"},
                    "include_intermediate": {
                        "type": "boolean",
                        "description": "Include intermediate results",
                        "default": False,
                    },
                },
                "required": ["task_id"],
                "additionalProperties": False,
            },
        },
    ]

    # Note: id will be set by the caller from the request_id
    return {
        "jsonrpc": "2.0",
        "id": "0",  # Default value, will be overwritten by caller with actual request_id
        "result": {"tools": tools},
    }


async def tools_call(params: dict[str, Any], caller: str, request: Request):
    # Support both original format (name/arguments) and GPT format (toolName/params)
    tool_name = params.get("name") or params.get("toolName")
    arguments = params.get("arguments", {}) or params.get("params", {})

    user_agent = request.headers.get("user-agent")
    trace_id = request.headers.get("x-trace-id", params.get("trace_id", "unknown"))

    admin_ctx = extract_admin_ctx(request)

    if not tool_name:
        return {
            "jsonrpc": "2.0",
            "id": "0",  # Will be overwritten by caller with actual request_id
            "error": {"code": -32602, "message": "Missing tool name"},
        }

    try:
        if tool_name == "ping":
            result = tool_executor.ping(caller, user_agent, trace_id)
            # Format response according to MCP specification
            return {
                "jsonrpc": "2.0",
                "id": "0",  # Will be overwritten by caller with actual request_id
                "result": {"content": [{"type": "text", "text": "pong"}]},
            }
        elif tool_name == "echo":
            validated = EchoParams(**arguments)
            result = tool_executor.echo(validated, caller, user_agent, trace_id)
            # Format response according to MCP specification
            return {
                "jsonrpc": "2.0",
                "id": "0",  # Will be overwritten by caller with actual request_id
                "result": {"content": [{"type": "text", "text": result.get("text", "")}]},
            }
        elif tool_name == "inbox_append":
            validated = InboxAppendParams(**arguments)
            result = tool_executor.inbox_append(
                validated, caller, user_agent, trace_id, auth_ctx=admin_ctx
            )
            # Format response according to MCP specification
            return {
                "jsonrpc": "2.0",
                "id": "0",  # Will be overwritten by caller with actual request_id
                "result": {
                    "content": [
                        {"type": "text", "text": f"Successfully appended to inbox: {result}"}
                    ]
                },
            }
        elif tool_name == "inbox_tail":
            validated = InboxTailParams(**arguments)
            result = tool_executor.inbox_tail(validated, caller, user_agent, trace_id)
            # Format response according to MCP specification
            return {
                "jsonrpc": "2.0",
                "id": "0",  # Will be overwritten by caller with actual request_id
                "result": {"content": [{"type": "text", "text": result.get("content", "")}]},
            }
        elif tool_name == "board_get":
            result = tool_executor.board_get(caller, user_agent, trace_id)
            # Format response according to MCP specification
            return {
                "jsonrpc": "2.0",
                "id": "0",  # Will be overwritten by caller with actual request_id
                "result": {"content": [{"type": "text", "text": result.get("content", "")}]},
            }
        elif tool_name == "board_set_status":
            validated = BoardSetStatusParams(**arguments)
            result = tool_executor.board_set_status(
                validated, caller, user_agent, trace_id, auth_ctx=admin_ctx
            )
            # Format response according to MCP specification
            return {
                "jsonrpc": "2.0",
                "id": "0",  # Will be overwritten by caller with actual request_id
                "result": {
                    "content": [
                        {"type": "text", "text": f"Successfully updated board status: {result}"}
                    ]
                },
            }
        elif tool_name == "ata_send":
            validated = ATASendParams(**arguments)
            result = tool_executor.ata_send(
                validated, caller, user_agent, trace_id, auth_ctx=admin_ctx
            )
            # Format response according to MCP specification
            return {
                "jsonrpc": "2.0",
                "id": "0",  # Will be overwritten by caller with actual request_id
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "ata_receive":
            validated = ATAReceiveParams(**arguments)
            result = tool_executor.ata_receive(
                validated, caller, user_agent, trace_id, auth_ctx=admin_ctx
            )
            # Format response according to MCP specification
            return {
                "jsonrpc": "2.0",
                "id": "0",  # Will be overwritten by caller with actual request_id
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "github_search":
            from .tools import GitHubSearchParams

            validated = GitHubSearchParams(**arguments)
            result = tool_executor.github_search(validated, caller, user_agent, trace_id)
            # Format response according to MCP specification
            return {
                "jsonrpc": "2.0",
                "id": "0",  # Will be overwritten by caller with actual request_id
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "dialog_register":
            validated = DialogRegisterParams(**arguments)
            result = tool_executor.dialog_register(validated, caller, user_agent, trace_id)
            return {
                "jsonrpc": "2.0",
                "id": "0",
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "dialog_list":
            validated = DialogListParams(**arguments)
            result = tool_executor.dialog_list(validated, caller, user_agent, trace_id)
            return {
                "jsonrpc": "2.0",
                "id": "0",
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "conversation_stats":
            validated = ConversationStatsParams(**arguments)
            result = tool_executor.conversation_stats(validated, caller, user_agent, trace_id)
            return {
                "jsonrpc": "2.0",
                "id": "0",
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "conversation_search":
            validated = ConversationSearchParams(**arguments)
            result = tool_executor.conversation_search(validated, caller, user_agent, trace_id)
            return {
                "jsonrpc": "2.0",
                "id": "0",
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "conversation_history":
            validated = ConversationHistoryParams(**arguments)
            result = tool_executor.conversation_history(validated, caller, user_agent, trace_id)
            return {
                "jsonrpc": "2.0",
                "id": "0",
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "conversation_mark":
            validated = ConversationMarkParams(**arguments)
            result = tool_executor.conversation_mark(validated, caller, user_agent, trace_id)
            return {
                "jsonrpc": "2.0",
                "id": "0",
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "file_read":
            validated = FileReadParams(**arguments)
            result = tool_executor.file_read(validated, caller, user_agent, trace_id)
            return {
                "jsonrpc": "2.0",
                "id": "0",
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "ata_send_with_file":
            validated = ATASendWithFileParams(**arguments)
            result = tool_executor.ata_send_with_file(validated, caller, user_agent, trace_id)
            return {
                "jsonrpc": "2.0",
                "id": "0",
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "task_create":
            validated = TaskCreateParams(**arguments)
            result = tool_executor.task_create(
                validated, caller, user_agent, trace_id, auth_ctx=admin_ctx
            )
            return {
                "jsonrpc": "2.0",
                "id": "0",
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "task_status":
            validated = TaskStatusParams(**arguments)
            result = tool_executor.task_status(validated, caller, user_agent, trace_id)
            return {
                "jsonrpc": "2.0",
                "id": "0",
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "agent_register":
            validated = AgentRegisterParams(**arguments)
            result = tool_executor.agent_register(
                validated, caller, user_agent, trace_id, auth_ctx=admin_ctx
            )
            return {
                "jsonrpc": "2.0",
                "id": "0",
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "agent_apply":
            validated = AgentApplyParams(**arguments)
            result = tool_executor.agent_apply(validated, caller, user_agent, trace_id)
            return {
                "jsonrpc": "2.0",
                "id": "0",
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "agent_approve":
            # Admin-only tool; auth enforced inside ToolExecutor.agent_approve
            agent_id = str(arguments.get("agent_id") or "").strip()
            numeric_code = arguments.get("numeric_code")
            send_enabled = arguments.get("send_enabled")
            result = tool_executor.agent_approve(
                agent_id=agent_id,
                caller=caller,
                user_agent=user_agent,
                trace_id=trace_id,
                auth_ctx=admin_ctx,
                numeric_code=numeric_code,
                send_enabled=send_enabled,
            )
            return {
                "jsonrpc": "2.0",
                "id": "0",
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "ata_send_request":
            validated = ATASendRequestParams(**arguments)
            result = tool_executor.ata_send_request(validated, caller, user_agent, trace_id)
            return {
                "jsonrpc": "2.0",
                "id": "0",
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "ata_send_review":
            validated = ATASendReviewParams(**arguments)
            result = tool_executor.ata_send_review(
                validated, caller, user_agent, trace_id, auth_ctx=admin_ctx
            )
            return {
                "jsonrpc": "2.0",
                "id": "0",
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "admin_vault_put":
            # Store a secret doc for admin-only reading
            result = tool_executor.admin_vault_put(
                arguments, caller, user_agent, trace_id, auth_ctx=admin_ctx
            )
            return {
                "jsonrpc": "2.0",
                "id": "0",
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "admin_vault_get":
            result = tool_executor.admin_vault_get(
                arguments, caller, user_agent, trace_id, auth_ctx=admin_ctx
            )
            return {
                "jsonrpc": "2.0",
                "id": "0",
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "admin_whoami":
            info = {
                "success": True,
                "is_admin": bool(admin_ctx.get("is_admin")),
                "admin_method": admin_ctx.get("method"),
                "admin_reason": admin_ctx.get("reason"),
                "has_env_token": bool(os.getenv("ATA_ADMIN_TOKEN")),
                "provided_header_present": bool(request.headers.get("x-ata-admin-token")),
            }
            return {
                "jsonrpc": "2.0",
                "id": "0",
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(info, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "workflow_execute":
            validated = WorkflowExecuteParams(**arguments)
            result = tool_executor.workflow_execute(
                validated, caller, user_agent, trace_id, auth_ctx=admin_ctx
            )
            return {
                "jsonrpc": "2.0",
                "id": "0",
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        elif tool_name == "result_get":
            validated = ResultGetParams(**arguments)
            result = tool_executor.result_get(
                validated, caller, user_agent, trace_id, auth_ctx=admin_ctx
            )
            return {
                "jsonrpc": "2.0",
                "id": "0",
                "result": {
                    "content": [
                        {"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}
                    ]
                },
            }
        else:
            return {
                "jsonrpc": "2.0",
                "id": "0",  # Default value, will be overwritten by caller with actual request_id
                "error": {"code": -32601, "message": f"Unknown tool: {tool_name}"},
            }
    except Exception as e:
        return {
            "jsonrpc": "2.0",
            "id": "0",  # Default value, will be overwritten by caller with actual request_id
            "error": {"code": -32603, "message": f"Internal error: {str(e)}"},
        }


@app.post("/api/inbox_append")
async def api_inbox_append(
    params: InboxAppendParams,
    caller: str = Depends(get_caller),
    request: Request = None,
    token: dict = Depends(verify_token),
):
    user_agent = request.headers.get("user-agent") if request else None
    trace_id = request.headers.get("x-trace-id") if request else "unknown"
    return tool_executor.inbox_append(params, caller, user_agent, trace_id)


@app.post("/api/inbox_tail")
async def api_inbox_tail(
    params: InboxTailParams,
    caller: str = Depends(get_caller),
    request: Request = None,
    token: dict = Depends(verify_token),
):
    user_agent = request.headers.get("user-agent") if request else None
    trace_id = request.headers.get("x-trace-id") if request else "unknown"
    return tool_executor.inbox_tail(params, caller, user_agent, trace_id)


@app.get("/api/board_get")
async def api_board_get(
    caller: str = Depends(get_caller), request: Request = None, token: dict = Depends(verify_token)
):
    user_agent = request.headers.get("user-agent") if request else None
    trace_id = request.headers.get("x-trace-id") if request else "unknown"
    return tool_executor.board_get(caller, user_agent, trace_id)


@app.post("/api/board_set_status")
async def api_board_set_status(
    params: BoardSetStatusParams,
    caller: str = Depends(get_caller),
    request: Request = None,
    token: dict = Depends(verify_token),
):
    user_agent = request.headers.get("user-agent") if request else None
    trace_id = request.headers.get("x-trace-id") if request else "unknown"
    return tool_executor.board_set_status(params, caller, user_agent, trace_id)


# ============================================================================
# Web Viewer API Endpoints (ATA Messages Visualization)
# ============================================================================


@app.get("/api/viewer/messages")
async def api_viewer_messages(
    from_agent: str | None = None,
    to_agent: str | None = None,
    taskcode: str | None = None,
    kind: str | None = None,
    limit: int = 1000,
    token: dict = Depends(verify_token),
):
    """Get all ATA messages with optional filtering for web viewer"""
    # åœ¨AUTH_MODE=noneæ—¶å…è®¸è®¿é—®ï¼Œå³ä½¿tokenä¸ºNone
    default_auth_mode = (
        "none" if os.getenv("MCP_BUS_HOST", "127.0.0.1") in ["127.0.0.1", "localhost"] else "oauth"
    )
    auth_mode = os.getenv("AUTH_MODE", default_auth_mode).lower()
    if auth_mode != "none" and not token.get("authenticated", False):
        raise HTTPException(status_code=401, detail="Authentication required")

    all_messages = load_all_ata_messages()

    # Apply filters
    filtered = all_messages
    if from_agent:
        filtered = [m for m in filtered if m.get("from_agent", "").lower() == from_agent.lower()]
    if to_agent:
        filtered = [m for m in filtered if m.get("to_agent", "").lower() == to_agent.lower()]
    if taskcode:
        filtered = [m for m in filtered if taskcode.lower() in m.get("taskcode", "").lower()]
    if kind:
        filtered = [m for m in filtered if m.get("kind", "").lower() == kind.lower()]

    # Limit results
    if limit > 0:
        filtered = filtered[-limit:]  # Get most recent messages

    # Convert to summary format
    summaries = []
    for msg in filtered:
        summaries.append(
            {
                "msg_id": msg.get("msg_id", ""),
                "taskcode": msg.get("taskcode", ""),
                "from_agent": msg.get("from_agent", ""),
                "to_agent": msg.get("to_agent", ""),
                "created_at": msg.get("created_at", ""),
                "kind": msg.get("kind", ""),
                "payload_preview": get_message_preview(msg.get("payload", {})),
                "sha256": msg.get("sha256", ""),
                "prev_sha256": msg.get("prev_sha256"),
                "file_path": msg.get("file_path", ""),
            }
        )

    return {"total": len(summaries), "messages": summaries}


@app.get("/api/viewer/messages/{taskcode}")
async def api_viewer_messages_by_taskcode(taskcode: str, token: dict = Depends(verify_token)):
    """Get all messages for a specific taskcode"""
    all_messages = load_all_ata_messages()
    filtered = [m for m in all_messages if m.get("taskcode", "") == taskcode]
    return {"taskcode": taskcode, "total": len(filtered), "messages": filtered}


@app.get("/api/viewer/messages/detail/{msg_id}")
async def api_viewer_message_detail(msg_id: str, token: dict = Depends(verify_token)):
    """Get full details of a specific message"""
    all_messages = load_all_ata_messages()
    for msg in all_messages:
        if msg.get("msg_id") == msg_id:
            return msg
    raise HTTPException(status_code=404, detail="Message not found")


@app.get("/api/viewer/agents")
async def api_viewer_agents(token: dict = Depends(verify_token)):
    """Get list of all agents"""
    # åœ¨AUTH_MODE=noneæ—¶å…è®¸è®¿é—®ï¼Œå³ä½¿tokenä¸ºNone
    default_auth_mode = (
        "none" if os.getenv("MCP_BUS_HOST", "127.0.0.1") in ["127.0.0.1", "localhost"] else "oauth"
    )
    auth_mode = os.getenv("AUTH_MODE", default_auth_mode).lower()
    if auth_mode != "none" and not token.get("authenticated", False):
        raise HTTPException(status_code=401, detail="Authentication required")

    all_messages = load_all_ata_messages()
    agents = set()
    for msg in all_messages:
        agents.add(msg.get("from_agent", ""))
        agents.add(msg.get("to_agent", ""))
    return {"agents": sorted(list(agents))}


@app.get("/api/viewer/statistics")
@cached(prefix="viewer", ttl=30)  # ç¼“å­˜30ç§’
async def api_viewer_statistics(token: dict = Depends(verify_token)):
    """Get statistics about messages"""
    # åœ¨AUTH_MODE=noneæ—¶å…è®¸è®¿é—®ï¼Œå³ä½¿tokenä¸ºNone
    default_auth_mode = (
        "none" if os.getenv("MCP_BUS_HOST", "127.0.0.1") in ["127.0.0.1", "localhost"] else "oauth"
    )
    auth_mode = os.getenv("AUTH_MODE", default_auth_mode).lower()
    if auth_mode != "none" and not token.get("authenticated", False):
        raise HTTPException(status_code=401, detail="Authentication required")

    all_messages = load_all_ata_messages()

    stats = {"total_messages": len(all_messages), "by_agent": {}, "by_kind": {}, "by_taskcode": {}}

    for msg in all_messages:
        from_agent = msg.get("from_agent", "Unknown")
        kind = msg.get("kind", "Unknown")
        taskcode = msg.get("taskcode", "Unknown")

        # Count by agent
        stats["by_agent"][from_agent] = stats["by_agent"].get(from_agent, 0) + 1

        # Count by kind
        stats["by_kind"][kind] = stats["by_kind"].get(kind, 0) + 1

        # Count by taskcode
        stats["by_taskcode"][taskcode] = stats["by_taskcode"].get(taskcode, 0) + 1

    return stats


@app.get("/api/viewer/conversations")
async def api_viewer_conversations(
    from_agent: str | None = None, to_agent: str | None = None, token: dict = Depends(verify_token)
):
    """Get conversations between agents, grouped by taskcode"""
    all_messages = load_all_ata_messages()

    # Group messages by taskcode
    conversations = {}
    for msg in all_messages:
        taskcode = msg.get("taskcode", "Unknown")
        if taskcode not in conversations:
            conversations[taskcode] = []
        conversations[taskcode].append(msg)

    # Sort messages in each conversation by created_at
    for taskcode in conversations:
        conversations[taskcode].sort(key=lambda x: x.get("created_at", ""))

    return {"total_conversations": len(conversations), "conversations": conversations}


# Agent Collaboration API endpoints
@app.get("/api/collaboration/agents")
@cached(prefix="collaboration", ttl=5)  # ç¼“å­˜5ç§’
async def api_collaboration_agents():
    """Get all registered agents"""
    import json
    from pathlib import Path
    
    # å°è¯•ä»coordinatorè·å–æ™ºèƒ½ä½“æ•°æ®
    try:
        executor = get_tool_executor()
        if executor.coordinator:
            agents = executor.coordinator.get_all_agents()
            if agents:
                return {"agents": agents, "total": len(agents)}
    except Exception as e:
        print(f"ä»coordinatorè·å–æ™ºèƒ½ä½“æ•°æ®å¤±è´¥: {e}")
    
    # ç›´æ¥ä»æ–‡ä»¶è¯»å–æ™ºèƒ½ä½“æ•°æ®ä½œä¸ºå¤‡ä»½æ–¹æ¡ˆ
    try:
        repo_root = Path(__file__).parent.parent.parent.parent
        registry_path = repo_root / ".cursor" / "agent_registry.json"
        if registry_path.exists():
            with open(registry_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                agents_data = data.get("agents", {})
                agents = []
                for agent_id, agent_info in agents_data.items():
                    # æ ¼å¼åŒ–æ™ºèƒ½ä½“æ•°æ®
                    agent_dict = {
                        "agent_id": agent_info.get("agent_id"),
                        "numeric_code": agent_info.get("numeric_code"),
                        "display_name": f"{agent_info.get('agent_id')}#{agent_info.get('numeric_code', '--'):02d}",
                        "agent_type": agent_info.get("agent_type"),
                        "role": agent_info.get("role"),
                        "capabilities": agent_info.get("capabilities", []),
                        "current_load": agent_info.get("current_load", 0),
                        "max_concurrent_tasks": agent_info.get("max_concurrent_tasks", 5),
                        "status": agent_info.get("status", "available"),
                        "send_enabled": agent_info.get("send_enabled", True),
                        "category": agent_info.get("category", "user_ai"),
                        "registered_at": agent_info.get("registered_at"),
                        "last_heartbeat": agent_info.get("last_heartbeat"),
                        "response_time_avg": agent_info.get("response_time_avg", 0.0),
                        "success_rate": agent_info.get("success_rate", 1.0),
                        "total_tasks": agent_info.get("total_tasks", 0),
                        "completed_tasks": agent_info.get("completed_tasks", 0),
                    }
                    agents.append(agent_dict)
                return {"agents": agents, "total": len(agents)}
    except Exception as e:
        print(f"ç›´æ¥ä»æ–‡ä»¶è¯»å–æ™ºèƒ½ä½“æ•°æ®å¤±è´¥: {e}")
    
    return {"agents": [], "total": 0}


@app.get("/api/collaboration/tasks")
async def api_collaboration_tasks(
    status: str | None = None, limit: int = 50
):
    """Get all tasks"""
    try:
        executor = get_tool_executor()
        if executor.orchestrator:
            tasks = executor.orchestrator.get_all_tasks()
            if status:
                tasks = [t for t in tasks if t.get("status") == status]
            if limit:
                tasks = tasks[:limit]
            return {"tasks": tasks, "total": len(tasks)}
    except Exception as e:
        print(f"ä»orchestratorè·å–ä»»åŠ¡æ•°æ®å¤±è´¥: {e}")
    
    # å¦‚æœæ²¡æœ‰ä»»åŠ¡æ•°æ®ï¼Œè¿”å›ç©ºåˆ—è¡¨
    return {"tasks": [], "total": 0}


@app.get("/api/collaboration/tasks/{task_id}")
async def api_collaboration_task_detail(task_id: str, token: dict = Depends(verify_token)):
    """Get task detail"""
    try:
        executor = get_tool_executor()
        if executor.orchestrator:
            task_status = executor.orchestrator.get_task_status(task_id)
            return task_status
        return {"error": "Orchestrator not available"}
    except Exception as e:
        return {"error": str(e)}


@app.get("/api/collaboration/workflows")
async def api_collaboration_workflows():
    """Get all workflows"""
    try:
        executor = get_tool_executor()
        if executor.workflow_engine:
            workflows = executor.workflow_engine.get_all_workflows()
            return {"workflows": workflows, "total": len(workflows)}
    except Exception as e:
        print(f"ä»workflow_engineè·å–å·¥ä½œæµæ•°æ®å¤±è´¥: {e}")
    
    # å¦‚æœæ²¡æœ‰å·¥ä½œæµæ•°æ®ï¼Œè¿”å›ç©ºåˆ—è¡¨
    return {"workflows": [], "total": 0}


@app.get("/api/collaboration/statistics")
@cached(prefix="collaboration", ttl=5)  # ç¼“å­˜5ç§’
async def api_collaboration_statistics():
    """Get collaboration statistics"""
    import json
    from pathlib import Path
    
    stats = {
        "agents": {"total": 0, "available": 0, "busy": 0},
        "tasks": {"total": 0, "pending": 0, "running": 0, "completed": 0, "failed": 0},
        "workflows": {"total": 0, "running": 0, "completed": 0},
    }

    # å°è¯•ä»coordinatorè·å–ç»Ÿè®¡æ•°æ®
    try:
        executor = get_tool_executor()
        if executor.coordinator:
            agents = executor.coordinator.get_all_agents()
            stats["agents"]["total"] = len(agents)
            stats["agents"]["available"] = len(
                [a for a in agents if a.get("status") == "available"]
            )
            stats["agents"]["busy"] = len([a for a in agents if a.get("status") == "busy"])
    except Exception as e:
        print(f"ä»coordinatorè·å–æ™ºèƒ½ä½“ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")
    
    # å¦‚æœcoordinatorè·å–å¤±è´¥ï¼Œç›´æ¥ä»æ–‡ä»¶è¯»å–æ™ºèƒ½ä½“æ•°æ®å¹¶è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    if stats["agents"]["total"] == 0:
        try:
            repo_root = Path(__file__).parent.parent.parent.parent
            registry_path = repo_root / ".cursor" / "agent_registry.json"
            if registry_path.exists():
                with open(registry_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    agents_data = data.get("agents", {})
                    agents = list(agents_data.values())
                    stats["agents"]["total"] = len(agents)
                    stats["agents"]["available"] = len(
                        [a for a in agents if a.get("status") == "available"]
                    )
                    stats["agents"]["busy"] = len(
                        [a for a in agents if a.get("status") == "busy"]
                    )
        except Exception as e:
            print(f"ä»æ–‡ä»¶è·å–æ™ºèƒ½ä½“ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")

    # å°è¯•ä»orchestratorè·å–ä»»åŠ¡ç»Ÿè®¡æ•°æ®
    try:
        executor = get_tool_executor()
        if executor.orchestrator:
            tasks = executor.orchestrator.get_all_tasks()
            stats["tasks"]["total"] = len(tasks)
            stats["tasks"]["pending"] = len([t for t in tasks if t.get("status") == "pending"])
            stats["tasks"]["running"] = len([t for t in tasks if t.get("status") == "running"])
            stats["tasks"]["completed"] = len([t for t in tasks if t.get("status") == "completed"])
            stats["tasks"]["failed"] = len([t for t in tasks if t.get("status") == "failed"])
    except Exception as e:
        print(f"ä»orchestratorè·å–ä»»åŠ¡ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")

    # å°è¯•ä»workflow_engineè·å–å·¥ä½œæµç»Ÿè®¡æ•°æ®
    try:
        executor = get_tool_executor()
        if executor.workflow_engine:
            workflows = executor.workflow_engine.get_all_workflows()
            stats["workflows"]["total"] = len(workflows)
            stats["workflows"]["running"] = len(
                [w for w in workflows if w.get("status") == "running"]
            )
            stats["workflows"]["completed"] = len(
                [w for w in workflows if w.get("status") == "completed"]
            )
    except Exception as e:
        print(f"ä»workflow_engineè·å–å·¥ä½œæµç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")

    return stats


# Agent Home APIs (profile + inbox/outbox + send)
@app.get("/api/agents/{agent_ref}")
async def api_agent_detail(agent_ref: str, token: dict = Depends(verify_token)):
    """Get agent detail by agent_id or numeric_code (1..100)."""
    executor = get_tool_executor()
    agent_id = _resolve_agent_ref(executor, agent_ref)
    agent = executor.coordinator.registry.get_agent(agent_id) if executor.coordinator else None
    if not agent:
        raise HTTPException(status_code=404, detail="Agent not found")
    return {
        "agent_id": agent.agent_id,
        "numeric_code": agent.numeric_code,
        "display_name": _display_name(agent.agent_id, agent.numeric_code),
        "agent_type": agent.agent_type,
        "role": agent.role,
        "capabilities": agent.capabilities,
        "status": agent.status.value,
        "send_enabled": getattr(agent, "send_enabled", True),
        "current_load": agent.current_load,
        "max_concurrent_tasks": agent.max_concurrent_tasks,
        "registered_at": agent.registered_at,
        "last_heartbeat": agent.last_heartbeat,
    }


@app.get("/api/agents/{agent_ref}/mailbox")
async def api_agent_mailbox(
    agent_ref: str,
    box: str = "in",  # in|out
    unread_only: bool = False,
    limit: int = 50,
    taskcode: str | None = None,
    token: dict = Depends(verify_token),
):
    """Get inbox/outbox messages for an agent from ATA messages store."""
    executor = get_tool_executor()
    agent_id = _resolve_agent_ref(executor, agent_ref)
    # Build id->display map (for consistent name-with-code rendering)
    id_to_display: dict[str, str] = {}
    if executor.coordinator:
        try:
            for a in executor.coordinator.registry.get_all_agents():
                aid = a.get("agent_id")
                if aid:
                    id_to_display[aid] = _display_name(aid, a.get("numeric_code"))
        except Exception:
            pass

    all_messages = load_all_ata_messages()
    filtered: list[dict[str, Any]] = []

    for msg in all_messages:
        if taskcode and msg.get("taskcode") != taskcode:
            continue

        if box == "in":
            if msg.get("to_agent") != agent_id:
                continue
        elif box == "out":
            if msg.get("from_agent") != agent_id:
                continue
        else:
            raise HTTPException(status_code=400, detail="box must be 'in' or 'out'")

        if unread_only:
            # treat anything not explicitly read/acked as unread
            if msg.get("status") in ["read", "acked", "archived"]:
                continue

        payload = msg.get("payload", {}) if isinstance(msg.get("payload", {}), dict) else {}
        from_id = msg.get("from_agent")
        to_id = msg.get("to_agent")
        filtered.append(
            {
                "msg_id": msg.get("msg_id"),
                "taskcode": msg.get("taskcode"),
                "kind": msg.get("kind"),
                "priority": msg.get("priority"),
                "status": msg.get("status"),
                "from_agent": from_id,
                "to_agent": to_id,
                "from_display": id_to_display.get(from_id, from_id),
                "to_display": id_to_display.get(to_id, to_id),
                "created_at": msg.get("created_at"),
                "preview": get_message_preview(payload, max_length=160),
                "payload": payload,
            }
        )

    # newest first
    filtered.sort(key=lambda x: x.get("created_at", ""), reverse=True)
    return {
        "agent_id": agent_id,
        "box": box,
        "total": len(filtered),
        "messages": filtered[: max(1, min(limit, 200))],
    }


# ==================== é…ç½®ç®¡ç†é›†æˆ ====================
# å°†config_managerçš„åŠŸèƒ½é›†æˆåˆ°MCP Bus


@app.get("/api/configs/list")
async def list_configs():
    """åˆ—å‡ºæ‰€æœ‰é…ç½®æ–‡ä»¶"""
    from datetime import datetime

    CONFIGS_DIR = REPO_ROOT / "configs" / "current"
    config_files = [
        ("config.json", "ç³»ç»Ÿä¸»é…ç½®", "json"),
        ("config_live.json", "å®ç›˜äº¤æ˜“é…ç½®", "json"),
        ("freqtrade_config.json", "Freqtradeé…ç½®", "json"),
        ("cloud_sync_config.json", "äº‘ç«¯åŒæ­¥é…ç½®", "json"),
        ("config_okx_aws.yaml", "OKX AWSé…ç½®", "yaml"),
    ]

    configs = []
    for filename, description, file_type in config_files:
        config_path = CONFIGS_DIR / filename
        configs.append(
            {
                "filename": filename,
                "description": description,
                "type": file_type,
                "exists": config_path.exists(),
                "modified": datetime.fromtimestamp(config_path.stat().st_mtime).isoformat()
                if config_path.exists()
                else None,
            }
        )

    return {"configs": configs}


@app.get("/api/configs/{filename:path}")
async def get_config(filename: str):
    """è·å–é…ç½®æ–‡ä»¶å†…å®¹"""
    import json

    import yaml

    CONFIGS_DIR = REPO_ROOT / "configs" / "current"
    config_path = CONFIGS_DIR / filename

    if not config_path.exists():
        raise HTTPException(status_code=404, detail="é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")

    if filename.endswith(".json"):
        with open(config_path, encoding="utf-8") as f:
            config = json.load(f)
        return {"config": config, "filename": filename, "type": "json"}
    elif filename.endswith(".yaml") or filename.endswith(".yml"):
        with open(config_path, encoding="utf-8") as f:
            yaml_content = f.read()
            config = yaml.safe_load(yaml_content) or {}
        return {
            "config": config,
            "filename": filename,
            "type": "yaml",
            "yaml_content": yaml_content,
        }
    else:
        raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹")


@app.post("/api/configs/{filename:path}")
async def save_config(filename: str, request_data: dict[str, Any]):
    """ä¿å­˜é…ç½®æ–‡ä»¶"""
    import json
    import shutil
    from datetime import datetime

    import yaml

    CONFIGS_DIR = REPO_ROOT / "configs" / "current"
    BACKUP_DIR = REPO_ROOT / "configs" / "_backup"
    BACKUP_DIR.mkdir(parents=True, exist_ok=True)

    config_path = CONFIGS_DIR / filename

    # å¤‡ä»½åŸæ–‡ä»¶
    if config_path.exists():
        backup_path = BACKUP_DIR / f"{filename}.{datetime.now().strftime('%Y%m%d_%H%M%S')}.bak"
        shutil.copy2(config_path, backup_path)

    try:
        if filename.endswith(".yaml") or filename.endswith(".yml"):
            if "yaml_content" in request_data:
                with open(config_path, "w", encoding="utf-8") as f:
                    f.write(request_data["yaml_content"])
            else:
                with open(config_path, "w", encoding="utf-8") as f:
                    yaml.dump(
                        request_data.get("config", {}),
                        f,
                        default_flow_style=False,
                        allow_unicode=True,
                    )
        else:
            with open(config_path, "w", encoding="utf-8") as f:
                json.dump(request_data.get("config", {}), f, indent=2, ensure_ascii=False)

        return {"message": "é…ç½®ä¿å­˜æˆåŠŸ", "filename": filename}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¿å­˜å¤±è´¥: {str(e)}")


@app.post("/api/configs/{filename:path}/validate")
async def validate_config(filename: str, request_data: dict[str, Any]):
    """éªŒè¯é…ç½®æ–‡ä»¶å†…å®¹"""
    import sys

    import yaml
    from pydantic import ValidationError

    if not request_data:
        raise HTTPException(status_code=400, detail="é…ç½®æ•°æ®ä¸èƒ½ä¸ºç©º")

    if filename.endswith(".yaml") or filename.endswith(".yml"):
        if "yaml_content" in request_data:
            try:
                config_data = yaml.safe_load(request_data["yaml_content"])
                if config_data is None:
                    config_data = {}
            except yaml.YAMLError as exc:
                raise HTTPException(status_code=400, detail=f"YAMLè§£æé”™è¯¯: {exc}")
        elif "config" in request_data:
            config_data = request_data.get("config") or {}
        else:
            raise HTTPException(status_code=400, detail="éœ€è¦æä¾›yaml_contentæˆ–configå­—æ®µ")
    else:
        if "config" not in request_data:
            raise HTTPException(status_code=400, detail="é…ç½®æ•°æ®ä¸èƒ½ä¸ºç©º")
        config_data = request_data.get("config") or {}

    try:
        if filename == "config.json":
            try:
                from quantsys.contracts_runtime.config_schema import MainConfig
            except Exception:
                repo_root = get_repo_root()
                src_path = repo_root / "src"
                src_str = str(src_path)
                if src_str not in sys.path:
                    sys.path.insert(0, src_str)
                from quantsys.contracts_runtime.config_schema import MainConfig
            MainConfig(**config_data)
    except ValidationError as exc:
        raise HTTPException(status_code=400, detail=f"é…ç½®éªŒè¯å¤±è´¥: {exc}")
    except Exception as exc:
        raise HTTPException(status_code=400, detail=f"é…ç½®éªŒè¯å¤±è´¥: {exc}")

    return {"valid": True, "message": "é…ç½®éªŒè¯é€šè¿‡"}


@app.get("/api/configs/{filename:path}/backup")
async def list_backups(filename: str):
    """åˆ—å‡ºé…ç½®æ–‡ä»¶çš„å¤‡ä»½"""
    from datetime import datetime

    BACKUP_DIR = REPO_ROOT / "configs" / "_backup"
    backup_pattern = f"{filename}.*.bak"

    backups = []
    for backup_file in BACKUP_DIR.glob(backup_pattern):
        backups.append(
            {
                "filename": backup_file.name,
                "path": str(backup_file.relative_to(BACKUP_DIR)),
                "created": datetime.fromtimestamp(backup_file.stat().st_mtime).isoformat(),
                "size": backup_file.stat().st_size,
            }
        )

    backups.sort(key=lambda x: x["created"], reverse=True)
    return {"backups": backups}


@app.post("/api/configs/{filename:path}/restore")
async def restore_backup(filename: str, request_data: dict[str, Any]):
    """æ¢å¤å¤‡ä»½"""
    import shutil

    BACKUP_DIR = REPO_ROOT / "configs" / "_backup"
    CONFIGS_DIR = REPO_ROOT / "configs" / "current"

    backup_filename = request_data.get("backup_filename")
    if not backup_filename:
        raise HTTPException(status_code=400, detail="å¤‡ä»½æ–‡ä»¶åä¸èƒ½ä¸ºç©º")

    backup_path = BACKUP_DIR / backup_filename
    if not backup_path.exists():
        raise HTTPException(status_code=404, detail="å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨")

    config_path = CONFIGS_DIR / filename
    try:
        shutil.copy2(backup_path, config_path)
        return {"message": "é…ç½®æ¢å¤æˆåŠŸ", "filename": filename}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ¢å¤å¤±è´¥: {str(e)}")


# ==================== å› å­åº“ / ç­–ç•¥åº“ / å›æµ‹ / å¸‚åœºæ¦‚ç‡ ====================


def _get_factor_registry_path() -> Path:
    return REPO_ROOT / "src" / "quantsys" / "factors" / "factor_registry.json"


@app.get("/api/factors/list")
async def api_factors_list():
    """åˆ—å‡ºå› å­åº“ä¸­æ‰€æœ‰å› å­ï¼ˆæ¥è‡ª factor_registryï¼‰"""
    from src.quantsys.factors.factor_registry import FactorRegistry, UnregisteredFactorError

    registry_path = _get_factor_registry_path()
    if not registry_path.exists():
        return {"factors": []}

    try:
        registry = FactorRegistry(str(registry_path))
        codes = registry.list_registered()
        factors = []
        for code in codes:
            try:
                spec = registry.get_spec(code)
                # FactorSpec æ˜¯ dataclassï¼Œç›´æ¥è®¿é—®å±æ€§
                factor_name = spec.name if spec.name else spec.code
                factor_desc = spec.description if spec.description else ""
                factor_type = spec.type if spec.type else "unknown"
                factors.append(
                    {
                        "code": spec.code,
                        "name": factor_name,
                        "description": factor_desc,
                        "category": factor_type,
                        "parameters": {
                            "window": spec.window if spec.window else None,
                            "frequency": spec.frequency if spec.frequency else None,
                        },
                    }
                )
            except UnregisteredFactorError:
                continue
        return {"factors": factors}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å› å­åº“åŠ è½½å¤±è´¥: {str(e)}")


class FactorEvaluateRequest(BaseModel):
    """å› å­è¯„ä¼°è¯·æ±‚"""
    factor_code: str | None = None
    factor_codes: list[str] | None = None  # å¤šå› å­ç»„åˆè¯„ä¼°
    symbol: str
    timeframe: str
    start_time: str  # YYYY-MM-DD
    end_time: str  # YYYY-MM-DD


@app.post("/api/factors/evaluate")
async def api_factors_evaluate(request: FactorEvaluateRequest):
    """è¯„ä¼°å› å­æœ‰æ•ˆæ€§ï¼ˆå•å› å­æˆ–å¤šå› å­ç»„åˆï¼‰"""
    from quantsys.factors.factor_evaluation_system import FactorEvaluationSystem
    from datetime import datetime

    try:
        # è§£ææ—¶é—´
        start_time = datetime.strptime(request.start_time, "%Y-%m-%d")
        end_time = datetime.strptime(request.end_time, "%Y-%m-%d")

        # åˆå§‹åŒ–è¯„ä¼°ç³»ç»Ÿ
        evaluation_system = FactorEvaluationSystem()

        try:
            # å•å› å­è¯„ä¼°
            if request.factor_code:
                result = evaluation_system.evaluate_single_factor(
                    request.factor_code,
                    request.symbol,
                    request.timeframe,
                    start_time,
                    end_time,
                )
                if result is None:
                    raise HTTPException(
                        status_code=404,
                        detail=f"å› å­è¯„ä¼°å¤±è´¥ï¼šæœªæ‰¾åˆ°æ•°æ®æˆ–æ•°æ®é‡ä¸è¶³",
                    )
                return {"success": True, "result": result}

            # å¤šå› å­ç»„åˆè¯„ä¼°
            elif request.factor_codes and len(request.factor_codes) > 0:
                result = evaluation_system.evaluate_factor_combination(
                    request.factor_codes,
                    request.symbol,
                    request.timeframe,
                    start_time,
                    end_time,
                )
                if result is None:
                    raise HTTPException(
                        status_code=404,
                        detail=f"å› å­ç»„åˆè¯„ä¼°å¤±è´¥ï¼šæœªæ‰¾åˆ°æ•°æ®æˆ–æ•°æ®é‡ä¸è¶³",
                    )
                return {"success": True, "result": result}

            else:
                raise HTTPException(
                    status_code=400, detail="å¿…é¡»æä¾› factor_code æˆ– factor_codes"
                )

        finally:
            evaluation_system.close()

    except ValueError as e:
        raise HTTPException(status_code=400, detail=f"æ—¶é—´æ ¼å¼é”™è¯¯: {str(e)}")
    except Exception as e:
        logger.error(f"å› å­è¯„ä¼°å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å› å­è¯„ä¼°å¤±è´¥: {str(e)}")


@app.get("/api/factors/ranking")
async def api_factors_ranking(
    symbol: str,
    timeframe: str,
    start_time: str,  # YYYY-MM-DD
    end_time: str,  # YYYY-MM-DD
    top_n: int = 10,
):
    """è·å–å› å­æ’åï¼ˆæŒ‰ICå€¼æ’åºï¼‰"""
    from quantsys.factors.factor_evaluation_system import FactorEvaluationSystem
    from datetime import datetime

    try:
        # è§£ææ—¶é—´
        start_time_dt = datetime.strptime(start_time, "%Y-%m-%d")
        end_time_dt = datetime.strptime(end_time, "%Y-%m-%d")

        # åˆå§‹åŒ–è¯„ä¼°ç³»ç»Ÿ
        evaluation_system = FactorEvaluationSystem()

        try:
            result = evaluation_system.get_factor_ranking(
                symbol, timeframe, start_time_dt, end_time_dt, top_n
            )
            if result is None:
                raise HTTPException(
                    status_code=404, detail="å› å­æ’åå¤±è´¥ï¼šæœªæ‰¾åˆ°æ•°æ®æˆ–æ•°æ®é‡ä¸è¶³"
                )
            return {"success": True, "result": result}

        finally:
            evaluation_system.close()

    except ValueError as e:
        raise HTTPException(status_code=400, detail=f"æ—¶é—´æ ¼å¼é”™è¯¯: {str(e)}")
    except Exception as e:
        logger.error(f"å› å­æ’åå¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å› å­æ’åå¤±è´¥: {str(e)}")


@app.get("/api/factors/stability")
async def api_factors_stability(
    factor_code: str,
    symbol: str,
    timeframe: str,
    start_time: str,  # YYYY-MM-DD
    end_time: str,  # YYYY-MM-DD
    rolling_window: int = 60,
):
    """åˆ†æå› å­ç¨³å®šæ€§"""
    from quantsys.factors.factor_evaluation_system import FactorEvaluationSystem
    from datetime import datetime

    try:
        # è§£ææ—¶é—´
        start_time_dt = datetime.strptime(start_time, "%Y-%m-%d")
        end_time_dt = datetime.strptime(end_time, "%Y-%m-%d")

        # åˆå§‹åŒ–è¯„ä¼°ç³»ç»Ÿ
        evaluation_system = FactorEvaluationSystem()

        try:
            result = evaluation_system.analyze_factor_stability(
                factor_code,
                symbol,
                timeframe,
                start_time_dt,
                end_time_dt,
                rolling_window,
            )
            if result is None:
                raise HTTPException(
                    status_code=404,
                    detail="å› å­ç¨³å®šæ€§åˆ†æå¤±è´¥ï¼šæœªæ‰¾åˆ°æ•°æ®æˆ–æ•°æ®é‡ä¸è¶³",
                )
            return {"success": True, "result": result}

        finally:
            evaluation_system.close()

    except ValueError as e:
        raise HTTPException(status_code=400, detail=f"æ—¶é—´æ ¼å¼é”™è¯¯: {str(e)}")
    except Exception as e:
        logger.error(f"å› å­ç¨³å®šæ€§åˆ†æå¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500, detail=f"å› å­ç¨³å®šæ€§åˆ†æå¤±è´¥: {str(e)}"
        )


def _get_strategies_path() -> Path:
    return REPO_ROOT / "configs" / "current" / "strategies.json"


@app.get("/api/strategies/list")
async def api_strategies_list():
    """åˆ—å‡ºç­–ç•¥åº“ï¼ˆæ¥è‡ª strategies.jsonï¼Œä¸å­˜åœ¨åˆ™è¿”å›ç©ºï¼‰"""
    import json

    path = _get_strategies_path()
    if not path.exists():
        return {"strategies": []}

    try:
        data = json.loads(path.read_text(encoding="utf-8"))
        strategies = data.get("strategies", [])
        return {"strategies": strategies}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ç­–ç•¥åº“åŠ è½½å¤±è´¥: {str(e)}")


def _get_backtest_results_path() -> Path:
    return REPO_ROOT / "configs" / "current" / "backtest_results.json"


@app.get("/api/backtest/results")
async def api_backtest_results():
    """åˆ—å‡ºå›æµ‹ç»“æœï¼ˆæ¥è‡ª backtest_results.jsonï¼‰"""
    import json

    path = _get_backtest_results_path()
    if not path.exists():
        return {"results": []}

    try:
        data = json.loads(path.read_text(encoding="utf-8"))
        results = data.get("results", [])
        return {"results": results}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å›æµ‹ç»“æœåŠ è½½å¤±è´¥: {str(e)}")


@app.post("/api/backtest/run")
async def api_backtest_run(request_data: dict[str, Any]):
    """æäº¤å›æµ‹ä»»åŠ¡ï¼ˆæŒä¹…åŒ–åˆ° backtest_results.jsonï¼‰"""
    import json
    from datetime import datetime

    strategy_id = request_data.get("strategy_id") or ""
    symbol = request_data.get("symbol") or "BTC/USDT"
    timeframe = request_data.get("timeframe") or "1h"
    start_time = request_data.get("start_time") or ""
    end_time = request_data.get("end_time") or ""

    if not strategy_id or not start_time or not end_time:
        raise HTTPException(status_code=400, detail="ç¼ºå°‘ strategy_id / start_time / end_time")

    path = _get_backtest_results_path()
    path.parent.mkdir(parents=True, exist_ok=True)

    results = []
    if path.exists():
        try:
            data = json.loads(path.read_text(encoding="utf-8"))
            results = data.get("results", [])
        except Exception:
            results = []

    backtest_id = f"bt_{datetime.utcnow().strftime('%Y%m%d%H%M%S')}_{strategy_id[:8]}"
    entry = {
        "id": backtest_id,
        "strategy_id": strategy_id,
        "strategy_name": request_data.get("strategy_name") or strategy_id,
        "symbol": symbol,
        "timeframe": timeframe,
        "start_time": start_time,
        "end_time": end_time,
        "total_return": None,
        "sharpe_ratio": None,
        "max_drawdown": None,
        "win_rate": None,
        "status": "pending",
        "created": datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"),
    }
    results.insert(0, entry)

    try:
        path.write_text(
            json.dumps({"results": results}, ensure_ascii=False, indent=2),
            encoding="utf-8",
        )
        return {"backtest_id": backtest_id, "status": "queued", "results": results}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å›æµ‹æäº¤å¤±è´¥: {str(e)}")


@app.get("/api/market-probability/list")
async def api_market_probability_list():
    """å¸‚åœºæ¦‚ç‡åº“ï¼ˆå ä½ï¼Œæš‚æ— åç«¯å®ç°æ—¶è¿”å›ç©ºï¼‰"""
    return {"probabilities": []}


# ==================== Browser-Tools-MCP é›†æˆ ====================


@app.get("/api/browser-tools/status")
async def browser_tools_status():
    """æ£€æŸ¥Browser-Tools-ServerçŠ¶æ€"""
    from .browser_tools_integration import get_browser_tools_integration

    integration = get_browser_tools_integration()
    available = await integration.check_server_available()
    return {"available": available, "base_url": integration.base_url}


@app.post("/api/browser-tools/audit/accessibility")
async def browser_audit_accessibility(request_data: dict[str, Any]):
    """è¿è¡Œå¯è®¿é—®æ€§å®¡è®¡"""
    from .browser_tools_integration import get_browser_tools_integration

    integration = get_browser_tools_integration()
    url = request_data.get("url", "")
    if not url:
        raise HTTPException(status_code=400, detail="URLä¸èƒ½ä¸ºç©º")
    result = await integration.run_accessibility_audit(url)
    return result


@app.post("/api/browser-tools/audit/performance")
async def browser_audit_performance(request_data: dict[str, Any]):
    """è¿è¡Œæ€§èƒ½å®¡è®¡"""
    from .browser_tools_integration import get_browser_tools_integration

    integration = get_browser_tools_integration()
    url = request_data.get("url", "")
    if not url:
        raise HTTPException(status_code=400, detail="URLä¸èƒ½ä¸ºç©º")
    result = await integration.run_performance_audit(url)
    return result


@app.post("/api/browser-tools/audit/seo")
async def browser_audit_seo(request_data: dict[str, Any]):
    """è¿è¡ŒSEOå®¡è®¡"""
    from .browser_tools_integration import get_browser_tools_integration

    integration = get_browser_tools_integration()
    url = request_data.get("url", "")
    if not url:
        raise HTTPException(status_code=400, detail="URLä¸èƒ½ä¸ºç©º")
    result = await integration.run_seo_audit(url)
    return result


@app.post("/api/browser-tools/audit/best-practices")
async def browser_audit_best_practices(request_data: dict[str, Any]):
    """è¿è¡Œæœ€ä½³å®è·µå®¡è®¡"""
    from .browser_tools_integration import get_browser_tools_integration

    integration = get_browser_tools_integration()
    url = request_data.get("url", "")
    if not url:
        raise HTTPException(status_code=400, detail="URLä¸èƒ½ä¸ºç©º")
    result = await integration.run_best_practices_audit(url)
    return result


@app.post("/api/browser-tools/audit/all")
async def browser_audit_all(request_data: dict[str, Any]):
    """è¿è¡Œå®Œæ•´å®¡è®¡ï¼ˆæ‰€æœ‰å®¡è®¡ç±»å‹ï¼‰"""
    from .browser_tools_integration import get_browser_tools_integration

    integration = get_browser_tools_integration()
    url = request_data.get("url", "")
    if not url:
        raise HTTPException(status_code=400, detail="URLä¸èƒ½ä¸ºç©º")
    result = await integration.run_audit_mode(url)
    return result


@app.post("/api/browser-tools/screenshot")
async def browser_screenshot(request_data: dict[str, Any]):
    """æ•è·æµè§ˆå™¨æˆªå›¾"""
    from .browser_tools_integration import get_browser_tools_integration

    integration = get_browser_tools_integration()
    url = request_data.get("url")
    result = await integration.capture_screenshot(url)
    return result


@app.get("/api/browser-tools/logs/console")
async def browser_console_logs():
    """è·å–æ§åˆ¶å°æ—¥å¿—"""
    from .browser_tools_integration import get_browser_tools_integration

    integration = get_browser_tools_integration()
    result = await integration.get_console_logs()
    return result


@app.get("/api/browser-tools/logs/network")
async def browser_network_logs():
    """è·å–ç½‘ç»œæ—¥å¿—"""
    from .browser_tools_integration import get_browser_tools_integration

    integration = get_browser_tools_integration()
    result = await integration.get_network_logs()
    return result


@app.get("/browser-tools")
async def browser_tools_page():
    """æµè§ˆå™¨å·¥å…·é¡µé¢"""
    return HTMLResponse("""
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>æµè§ˆå™¨å®¡è®¡å·¥å…·</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 20px; }
            .container { max-width: 800px; margin: 0 auto; }
            input, button { padding: 8px; margin: 5px; }
            button { background: #667eea; color: white; border: none; cursor: pointer; }
            button:hover { background: #5568d3; }
            .result { margin-top: 20px; padding: 15px; background: #f5f5f5; border-radius: 5px; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸŒ æµè§ˆå™¨å®¡è®¡å·¥å…·</h1>
            <div>
                <input type="text" id="urlInput" placeholder="è¾“å…¥URL (å¦‚: http://localhost:8000)" style="width: 400px;">
                <button onclick="runAudit('accessibility')">å¯è®¿é—®æ€§å®¡è®¡</button>
                <button onclick="runAudit('performance')">æ€§èƒ½å®¡è®¡</button>
                <button onclick="runAudit('seo')">SEOå®¡è®¡</button>
                <button onclick="runAudit('best-practices')">æœ€ä½³å®è·µ</button>
                <button onclick="runAudit('all')">å…¨éƒ¨å®¡è®¡</button>
            </div>
            <div id="result" class="result" style="display:none;"></div>
        </div>
        <script>
            async function runAudit(type) {
                const url = document.getElementById('urlInput').value;
                if (!url) { alert('è¯·è¾“å…¥URL'); return; }
                
                const resultDiv = document.getElementById('result');
                resultDiv.style.display = 'block';
                resultDiv.innerHTML = 'æ­£åœ¨è¿è¡Œå®¡è®¡...';
                
                try {
                    const endpoint = type === 'all' ? '/api/browser-tools/audit/all' : `/api/browser-tools/audit/${type}`;
                    const response = await fetch(endpoint, {
                        method: 'POST',
                        headers: {'Content-Type': 'application/json'},
                        body: JSON.stringify({url: url})
                    });
                    const data = await response.json();
                    
                    if (data.success) {
                        resultDiv.innerHTML = '<h3>å®¡è®¡ç»“æœ:</h3><pre>' + JSON.stringify(data.data, null, 2) + '</pre>';
                    } else {
                        resultDiv.innerHTML = '<h3>é”™è¯¯:</h3><p>' + (data.error || 'æœªçŸ¥é”™è¯¯') + '</p>';
                    }
                } catch (error) {
                    resultDiv.innerHTML = '<h3>é”™è¯¯:</h3><p>' + error.message + '</p>';
                }
            }
        </script>
    </body>
    </html>
    """)


# ==================== Cursor10x é›†æˆ ====================


@app.get("/api/cursor10x/status")
async def cursor10x_status():
    """æ£€æŸ¥Cursor10xçŠ¶æ€"""
    from .cursor10x_integration import get_cursor10x_integration

    integration = get_cursor10x_integration()
    return {
        "enabled": integration.is_available(),
        "configured": bool(os.getenv("TURSO_DATABASE_URL")) and bool(os.getenv("TURSO_AUTH_TOKEN")),
    }


@app.post("/api/cursor10x/memory/store")
async def cursor10x_store_memory(request_data: dict[str, Any]):
    """å­˜å‚¨è®°å¿†"""
    from .cursor10x_integration import get_cursor10x_integration

    integration = get_cursor10x_integration()
    content = request_data.get("content", "")
    memory_type = request_data.get("memory_type", "short_term")
    importance = request_data.get("importance", 5)

    if not content:
        raise HTTPException(status_code=400, detail="å†…å®¹ä¸èƒ½ä¸ºç©º")

    result = await integration.store_memory(content, memory_type, importance)
    return result


@app.post("/api/cursor10x/memory/retrieve")
async def cursor10x_retrieve_memory(request_data: dict[str, Any]):
    """æ£€ç´¢è®°å¿†"""
    from .cursor10x_integration import get_cursor10x_integration

    integration = get_cursor10x_integration()
    query = request_data.get("query", "")
    limit = request_data.get("limit", 10)

    if not query:
        raise HTTPException(status_code=400, detail="æŸ¥è¯¢ä¸èƒ½ä¸ºç©º")

    result = await integration.retrieve_memory(query, limit)
    return result


@app.get("/api/cursor10x/memory/stats")
async def cursor10x_memory_stats():
    """è·å–è®°å¿†ç»Ÿè®¡"""
    from .cursor10x_integration import get_cursor10x_integration

    integration = get_cursor10x_integration()
    result = await integration.get_memory_stats()
    return result


# ==================== Trading Data API ====================

@app.get("/api/trading-data/catalog")
async def get_trading_data_catalog(token: dict = Depends(verify_token)):
    """è·å–äº¤æ˜“æ•°æ®ç›®å½•"""
    db = None
    try:
        _ensure_repo_src_on_path()
        from quantsys.data.database_manager import DatabaseManager
        
        db = DatabaseManager()
        stats = db.get_trading_data_stats()
        
        catalog = []
        for stat in stats:
            # è·å–æœ€æ—©æ—¶é—´æˆ³
            earliest = None
            try:
                db.cursor.execute(
                    "SELECT MIN(timestamp) FROM trading_data WHERE symbol = %s AND timeframe = %s",
                    (stat['symbol'], stat['timeframe'])
                )
                row = db.cursor.fetchone()
                earliest = row[0] if row and row[0] else None
            except Exception as e:
                logger.warning(f"Failed to get earliest timestamp for {stat['symbol']}/{stat['timeframe']}: {e}")
            
            catalog.append({
                "symbol": stat['symbol'],
                "timeframe": stat['timeframe'],
                "count": stat['total_rows'],
                "latest_timestamp": stat['latest_timestamp'].isoformat() if stat['latest_timestamp'] else None,
                "earliest_timestamp": earliest.isoformat() if earliest else None
            })
        
        result = {
            "success": True,
            "data": catalog,
            "total": len(catalog),
            "timestamp": datetime.now().isoformat()
        }
        return result
    except Exception as e:
        logger.error(f"Failed to get trading data catalog: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})
    finally:
        if db:
            try:
                db.disconnect()
            except Exception as e:
                logger.warning(f"Failed to disconnect database: {e}")


# ä¸‹è½½ä»»åŠ¡ç®¡ç†å™¨ï¼ˆå†…å­˜å­˜å‚¨ï¼Œé‡å¯åä¸¢å¤±ï¼‰
_download_tasks: dict[str, dict[str, Any]] = {}
_download_tasks_lock = threading.Lock()

def _run_download_task(task_id: str, symbol: str, timeframe: str, days: int = 365):
    """åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œä¸‹è½½ä»»åŠ¡"""
    try:
        with _download_tasks_lock:
            _download_tasks[task_id]["status"] = "running"
            _download_tasks[task_id]["start_time"] = datetime.now().isoformat()
            _download_tasks[task_id]["progress"] = 0
        
        _ensure_repo_src_on_path()
        from quantsys.data.data_collection import fetch_from_okx_api
        
        logger.info(f"å¼€å§‹ä¸‹è½½ä»»åŠ¡ {task_id}: {symbol} {timeframe}")
        
        # æ›´æ–°è¿›åº¦
        with _download_tasks_lock:
            _download_tasks[task_id]["progress"] = 10
        
        # æ‰§è¡Œä¸‹è½½
        df = fetch_from_okx_api(symbol, timeframe, days)
        
        with _download_tasks_lock:
            if df is not None and len(df) > 0:
                _download_tasks[task_id]["status"] = "completed"
                _download_tasks[task_id]["progress"] = 100
                _download_tasks[task_id]["end_time"] = datetime.now().isoformat()
                _download_tasks[task_id]["rows_downloaded"] = len(df)
                logger.info(f"ä¸‹è½½ä»»åŠ¡ {task_id} å®Œæˆ: ä¸‹è½½äº† {len(df)} æ¡è®°å½•")
            else:
                _download_tasks[task_id]["status"] = "failed"
                _download_tasks[task_id]["progress"] = 0
                _download_tasks[task_id]["end_time"] = datetime.now().isoformat()
                _download_tasks[task_id]["error"] = "ä¸‹è½½å¤±è´¥ï¼šæœªè·å–åˆ°æ•°æ®"
                logger.error(f"ä¸‹è½½ä»»åŠ¡ {task_id} å¤±è´¥: æœªè·å–åˆ°æ•°æ®")
    except Exception as e:
        with _download_tasks_lock:
            _download_tasks[task_id]["status"] = "failed"
            _download_tasks[task_id]["end_time"] = datetime.now().isoformat()
            _download_tasks[task_id]["error"] = str(e)
        logger.error(f"ä¸‹è½½ä»»åŠ¡ {task_id} å¼‚å¸¸: {e}", exc_info=True)


@app.post("/api/trading-data/download")
async def start_trading_data_download(
    request_data: dict[str, Any],
    token: dict = Depends(verify_token)
):
    """å¯åŠ¨äº¤æ˜“æ•°æ®ä¸‹è½½ä»»åŠ¡"""
    try:
        symbol = request_data.get("symbol")
        timeframe = request_data.get("timeframe")
        days = request_data.get("days", 365)  # é»˜è®¤ä¸‹è½½365å¤©
        
        if not symbol or not timeframe:
            raise HTTPException(status_code=400, detail="Missing symbol or timeframe")
        
        # ç”Ÿæˆä»»åŠ¡ID
        task_id = f"download_{symbol}_{timeframe}_{int(time.time())}"
        
        # åˆ›å»ºä»»åŠ¡è®°å½•
        with _download_tasks_lock:
            _download_tasks[task_id] = {
                "id": task_id,
                "symbol": symbol,
                "timeframe": timeframe,
                "days": days,
                "status": "pending",
                "progress": 0,
                "start_time": None,
                "end_time": None,
                "error": None,
                "rows_downloaded": 0,
                "created_at": datetime.now().isoformat()
            }
        
        # åœ¨åå°çº¿ç¨‹ä¸­å¯åŠ¨ä¸‹è½½ä»»åŠ¡
        download_thread = threading.Thread(
            target=_run_download_task,
            args=(task_id, symbol, timeframe, days),
            daemon=True
        )
        download_thread.start()
        
        return {
            "success": True,
            "task_id": task_id,
            "status": "queued",
            "timestamp": datetime.now().isoformat()
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to start download: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/trading-data/download/status")
async def get_download_status(token: dict = Depends(verify_token)):
    """è·å–ä¸‹è½½ä»»åŠ¡çŠ¶æ€"""
    try:
        with _download_tasks_lock:
            # è·å–æ‰€æœ‰ä»»åŠ¡ï¼ŒæŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åˆ—
            tasks = list(_download_tasks.values())
            tasks.sort(key=lambda x: x.get("created_at", ""), reverse=True)
            
            # è®¡ç®—æ´»è·ƒä»»åŠ¡æ•°ï¼ˆpendingæˆ–runningï¼‰
            active_count = sum(
                1 for task in tasks 
                if task.get("status") in ["pending", "running"]
            )
            
            # åªè¿”å›æœ€è¿‘50ä¸ªä»»åŠ¡
            recent_tasks = tasks[:50]
            
            return {
                "success": True,
                "tasks": recent_tasks,
                "active_count": active_count,
                "total_count": len(tasks),
                "timestamp": datetime.now().isoformat()
            }
    except Exception as e:
        logger.error(f"Failed to get download status: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


# ==================== Portfolio API ====================

@app.get("/api/portfolio/list")
async def list_portfolios(token: dict = Depends(verify_token)):
    """åˆ—å‡ºæ‰€æœ‰æŠ•èµ„ç»„åˆ"""
    try:
        # TODO: ä»å­˜å‚¨ä¸­è¯»å–ç»„åˆåˆ—è¡¨
        # ä¸´æ—¶è¿”å›ç©ºåˆ—è¡¨
        return {
            "success": True,
            "portfolios": [],
            "total": 0,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to list portfolios: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.post("/api/portfolio/build")
async def build_portfolio(
    request_data: dict[str, Any],
    token: dict = Depends(verify_token)
):
    """æ„å»ºæŠ•èµ„ç»„åˆ"""
    try:
        _ensure_repo_src_on_path()
        from quantsys.portfolio.portfolio_manager import PortfolioManager
        
        strategy_results = request_data.get("strategy_results", [])
        allocation_method = request_data.get("allocation_method", "equal")
        target_vol = request_data.get("target_vol", 0.02)
        max_drawdown_threshold = request_data.get("max_drawdown_threshold", 0.2)
        
        if not strategy_results:
            raise HTTPException(status_code=400, detail="strategy_resultsä¸èƒ½ä¸ºç©º")
        
        config = {
            "allocation_method": allocation_method,
            "target_vol": target_vol,
            "max_drawdown_threshold": max_drawdown_threshold
        }
        
        manager = PortfolioManager(config)
        portfolio = manager.build_portfolio(strategy_results)
        
        return {
            "success": True,
            "portfolio": portfolio,
            "timestamp": datetime.now().isoformat()
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to build portfolio: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/portfolio/{portfolio_id}")
async def get_portfolio(portfolio_id: str, token: dict = Depends(verify_token)):
    """è·å–æŠ•èµ„ç»„åˆè¯¦æƒ…"""
    try:
        # TODO: ä»å­˜å‚¨ä¸­è¯»å–ç»„åˆè¯¦æƒ…
        raise HTTPException(status_code=404, detail=f"Portfolio {portfolio_id} not found")
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get portfolio: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.post("/api/portfolio/{portfolio_id}/rebalance")
async def rebalance_portfolio(
    portfolio_id: str,
    request_data: dict[str, Any],
    token: dict = Depends(verify_token)
):
    """å†å¹³è¡¡æŠ•èµ„ç»„åˆ"""
    try:
        # TODO: å®ç°å†å¹³è¡¡é€»è¾‘
        raise HTTPException(status_code=404, detail=f"Portfolio {portfolio_id} not found")
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to rebalance portfolio: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


# ==================== P&L API ====================

@app.get("/api/pnl/realtime")
async def get_realtime_pnl(
    exchange: str = "okx",
    trading_mode: str = "drill",
    token: dict = Depends(verify_token)
):
    """è·å–å®æ—¶ç›ˆäº"""
    try:
        _ensure_repo_src_on_path()
        from quantsys.execution.account_service import AccountService
        
        account_service = AccountService(exchange=exchange, trading_mode=trading_mode)
        account_state = account_service.get_account_state()
        
        # è®¡ç®—å®æ—¶ç›ˆäº
        # æ€»ç›ˆäº = è´¦æˆ·æƒç›Š - åˆå§‹èµ„é‡‘ï¼ˆç®€åŒ–å¤„ç†ï¼Œä½¿ç”¨ä½™é¢ä½œä¸ºåŸºå‡†ï¼‰
        initial_balance = 10000.0  # TODO: ä»é…ç½®æˆ–å†å²è®°å½•è·å–åˆå§‹èµ„é‡‘
        total_pnl = account_state.equity - initial_balance
        
        # æœªå®ç°ç›ˆäºï¼šä»æŒä»“è®¡ç®—
        unrealized_pnl = 0.0
        # TODO: ä»æŒä»“æ•°æ®è®¡ç®—æœªå®ç°ç›ˆäº
        
        # å·²å®ç°ç›ˆäº = æ€»ç›ˆäº - æœªå®ç°ç›ˆäº
        realized_pnl = total_pnl - unrealized_pnl
        
        return {
            "success": True,
            "total_pnl": total_pnl,
            "unrealized_pnl": unrealized_pnl,
            "realized_pnl": realized_pnl,
            "equity": account_state.equity,
            "balance": account_state.balance,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to get realtime P&L: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/pnl/breakdown")
async def get_pnl_breakdown(
    exchange: str = "okx",
    trading_mode: str = "drill",
    group_by: str = "strategy",  # strategy, symbol
    token: dict = Depends(verify_token)
):
    """è·å–ç›ˆäºåˆ†è§£"""
    try:
        _ensure_repo_src_on_path()
        from quantsys.execution.account_service import AccountService
        
        account_service = AccountService(exchange=exchange, trading_mode=trading_mode)
        account_state = account_service.get_account_state()
        
        # TODO: å®ç°æŒ‰ç­–ç•¥æˆ–å“ç§åˆ†è§£ç›ˆäº
        breakdown = []
        if group_by == "symbol":
            for symbol, notional in account_state.positions.items():
                # ç®€åŒ–å¤„ç†ï¼šå‡è®¾æ¯ä¸ªå“ç§çš„ç›ˆäºæ¯”ä¾‹
                breakdown.append({
                    "symbol": symbol,
                    "pnl": 0.0,  # TODO: è®¡ç®—å®é™…ç›ˆäº
                    "notional": notional
                })
        
        return {
            "success": True,
            "group_by": group_by,
            "breakdown": breakdown,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to get P&L breakdown: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/pnl/attribution")
async def get_pnl_attribution(
    exchange: str = "okx",
    trading_mode: str = "drill",
    token: dict = Depends(verify_token)
):
    """è·å–ç›ˆäºå½’å› """
    try:
        # TODO: å®ç°ç›ˆäºå½’å› åˆ†æ
        return {
            "success": True,
            "attribution": {
                "by_strategy": {},
                "by_symbol": {},
                "by_time": {}
            },
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to get P&L attribution: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


# ==================== Performance Analysis API ====================

@app.get("/api/performance/attribution")
async def get_performance_attribution(
    strategy_id: str | None = None,
    start_date: str | None = None,
    end_date: str | None = None,
    token: dict = Depends(verify_token)
):
    """è·å–æ”¶ç›Šå½’å› åˆ†æ"""
    try:
        _ensure_repo_src_on_path()
        from quantsys.evaluation.metrics import compute_equity_metrics
        
        # TODO: ä»å›æµ‹ç»“æœæˆ–ç­–ç•¥æ•°æ®è·å–æƒç›Šæ›²çº¿
        # ä¸´æ—¶è¿”å›ç¤ºä¾‹æ•°æ®
        return {
            "success": True,
            "attribution": {
                "by_strategy": {},
                "by_factor": {},
                "by_time": {}
            },
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to get performance attribution: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/performance/risk-attribution")
async def get_risk_attribution(
    strategy_id: str | None = None,
    token: dict = Depends(verify_token)
):
    """è·å–é£é™©å½’å› åˆ†æ"""
    try:
        # TODO: å®ç°é£é™©å½’å› åˆ†æ
        return {
            "success": True,
            "attribution": {
                "var_decomposition": {},
                "volatility_decomposition": {},
                "correlation_contribution": {}
            },
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to get risk attribution: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/performance/factor-exposure")
async def get_factor_exposure(
    strategy_id: str | None = None,
    token: dict = Depends(verify_token)
):
    """è·å–å› å­æš´éœ²åˆ†æ"""
    try:
        # TODO: å®ç°å› å­æš´éœ²åˆ†æ
        return {
            "success": True,
            "exposures": {},
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to get factor exposure: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/performance/cost-analysis")
async def get_cost_analysis(
    strategy_id: str | None = None,
    token: dict = Depends(verify_token)
):
    """è·å–æˆæœ¬åˆ†æ"""
    try:
        # TODO: å®ç°æˆæœ¬åˆ†æ
        return {
            "success": True,
            "costs": {
                "total_cost": 0.0,
                "commission": 0.0,
                "slippage": 0.0,
                "funding_cost": 0.0
            },
            "breakdown": {},
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to get cost analysis: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


# ==================== Advanced Risk Metrics API ====================

@app.get("/api/risk/var")
async def calculate_var(
    portfolio_id: str | None = None,
    confidence: float = 0.95,
    horizon_days: int = 1,
    method: str = "historical",  # historical, parametric, monte_carlo
    token: dict = Depends(verify_token)
):
    """è®¡ç®—VaR"""
    try:
        # TODO: å®ç°VaRè®¡ç®—
        return {
            "success": True,
            "var": 0.0,
            "confidence": confidence,
            "horizon_days": horizon_days,
            "method": method,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to calculate VaR: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/risk/cvar")
async def calculate_cvar(
    portfolio_id: str | None = None,
    confidence: float = 0.95,
    horizon_days: int = 1,
    token: dict = Depends(verify_token)
):
    """è®¡ç®—CVaR (Conditional VaR)"""
    try:
        # TODO: å®ç°CVaRè®¡ç®—
        return {
            "success": True,
            "cvar": 0.0,
            "var": 0.0,
            "confidence": confidence,
            "horizon_days": horizon_days,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to calculate CVaR: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.post("/api/risk/stress-test")
async def run_stress_test(
    request_data: dict[str, Any],
    token: dict = Depends(verify_token)
):
    """è¿è¡Œå‹åŠ›æµ‹è¯•"""
    try:
        _ensure_repo_src_on_path()
        # TODO: å®ç°å‹åŠ›æµ‹è¯•é€»è¾‘
        scenario = request_data.get("scenario", "historical")
        
        return {
            "success": True,
            "scenario": scenario,
            "results": {},
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to run stress test: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


# ==================== Optimization API ====================

@app.post("/api/optimization/strategy")
async def optimize_strategy(
    request_data: dict[str, Any],
    token: dict = Depends(verify_token)
):
    """ç­–ç•¥å‚æ•°ä¼˜åŒ–"""
    try:
        _ensure_repo_src_on_path()
        from quantsys.evaluation.hyperopt import GridSearchOptimizer, RandomSearchOptimizer
        
        strategy_id = request_data.get("strategy_id")
        method = request_data.get("method", "grid_search")  # grid_search, random_search
        search_space = request_data.get("search_space", {})
        
        # TODO: å®ç°ç­–ç•¥å‚æ•°ä¼˜åŒ–é€»è¾‘
        return {
            "success": True,
            "optimization_id": f"opt_{int(time.time())}",
            "method": method,
            "status": "queued",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to optimize strategy: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.post("/api/optimization/factor")
async def optimize_factor(
    request_data: dict[str, Any],
    token: dict = Depends(verify_token)
):
    """å› å­å‚æ•°ä¼˜åŒ–"""
    try:
        _ensure_repo_src_on_path()
        from quantsys.factors.factor_optimizer import FactorOptimizer
        
        factor_id = request_data.get("factor_id")
        param_grid = request_data.get("param_grid", {})
        
        # TODO: å®ç°å› å­å‚æ•°ä¼˜åŒ–é€»è¾‘
        return {
            "success": True,
            "optimization_id": f"opt_{int(time.time())}",
            "status": "queued",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to optimize factor: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/optimization/results")
async def get_optimization_results(
    optimization_id: str | None = None,
    token: dict = Depends(verify_token)
):
    """è·å–ä¼˜åŒ–ç»“æœ"""
    try:
        # TODO: ä»å­˜å‚¨ä¸­è·å–ä¼˜åŒ–ç»“æœ
        return {
            "success": True,
            "results": [],
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to get optimization results: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


# ==================== Alerts API ====================

@app.get("/api/alerts/rules")
async def get_alert_rules(token: dict = Depends(verify_token)):
    """è·å–è­¦æŠ¥è§„åˆ™åˆ—è¡¨"""
    try:
        # TODO: ä»å­˜å‚¨ä¸­è·å–è­¦æŠ¥è§„åˆ™
        return {
            "success": True,
            "rules": [],
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to get alert rules: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.post("/api/alerts/rules")
async def create_alert_rule(
    request_data: dict[str, Any],
    token: dict = Depends(verify_token)
):
    """åˆ›å»ºè­¦æŠ¥è§„åˆ™"""
    try:
        rule_name = request_data.get("name")
        rule_type = request_data.get("type")  # risk, trade, system
        conditions = request_data.get("conditions", {})
        
        # TODO: å®ç°è­¦æŠ¥è§„åˆ™åˆ›å»ºé€»è¾‘
        return {
            "success": True,
            "rule_id": f"rule_{int(time.time())}",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to create alert rule: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/alerts/list")
async def get_alerts(
    status: str | None = None,  # active, resolved, all
    limit: int = 50,
    token: dict = Depends(verify_token)
):
    """è·å–è­¦æŠ¥åˆ—è¡¨"""
    try:
        # TODO: ä»å­˜å‚¨ä¸­è·å–è­¦æŠ¥åˆ—è¡¨
        return {
            "success": True,
            "alerts": [],
            "total": 0,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to get alerts: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/alerts/history")
async def get_alert_history(
    limit: int = 100,
    token: dict = Depends(verify_token)
):
    """è·å–è­¦æŠ¥å†å²"""
    try:
        # TODO: ä»å­˜å‚¨ä¸­è·å–è­¦æŠ¥å†å²
        return {
            "success": True,
            "history": [],
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to get alert history: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


# ==================== Reports API ====================

@app.post("/api/reports/generate")
async def generate_report(
    request_data: dict[str, Any],
    token: dict = Depends(verify_token)
):
    """ç”ŸæˆæŠ¥å‘Š"""
    try:
        _ensure_repo_src_on_path()
        from quantsys.portfolio.portfolio_manager import PortfolioManager
        
        report_type = request_data.get("type", "daily")  # daily, weekly, monthly
        start_date = request_data.get("start_date")
        end_date = request_data.get("end_date")
        
        # TODO: å®ç°æŠ¥å‘Šç”Ÿæˆé€»è¾‘
        return {
            "success": True,
            "report_id": f"report_{int(time.time())}",
            "type": report_type,
            "status": "generating",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to generate report: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/reports/list")
async def list_reports(
    report_type: str | None = None,
    limit: int = 50,
    token: dict = Depends(verify_token)
):
    """è·å–æŠ¥å‘Šåˆ—è¡¨"""
    try:
        # TODO: ä»å­˜å‚¨ä¸­è·å–æŠ¥å‘Šåˆ—è¡¨
        return {
            "success": True,
            "reports": [],
            "total": 0,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to list reports: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/reports/{report_id}")
async def get_report(
    report_id: str,
    token: dict = Depends(verify_token)
):
    """è·å–æŠ¥å‘Šè¯¦æƒ…"""
    try:
        # TODO: ä»å­˜å‚¨ä¸­è·å–æŠ¥å‘Šè¯¦æƒ…
        raise HTTPException(status_code=404, detail=f"Report {report_id} not found")
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get report: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/reports/templates")
async def get_report_templates(token: dict = Depends(verify_token)):
    """è·å–æŠ¥å‘Šæ¨¡æ¿åˆ—è¡¨"""
    try:
        return {
            "success": True,
            "templates": [
                {"id": "daily", "name": "æ—¥æŠ¥", "description": "æ¯æ—¥äº¤æ˜“æŠ¥å‘Š"},
                {"id": "weekly", "name": "å‘¨æŠ¥", "description": "æ¯å‘¨äº¤æ˜“æŠ¥å‘Š"},
                {"id": "monthly", "name": "æœˆæŠ¥", "description": "æ¯æœˆäº¤æ˜“æŠ¥å‘Š"},
            ],
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to get report templates: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"success": False, "error": str(e)})


@app.get("/api/cursor10x/health")
async def cursor10x_health():
    """å¥åº·æ£€æŸ¥"""
    from .cursor10x_integration import get_cursor10x_integration

    integration = get_cursor10x_integration()
    result = await integration.check_health()
    return result


@app.get("/configs")
async def configs_page():
    """é…ç½®ç®¡ç†é¡µé¢"""
    config_html_path = REPO_ROOT / "tools" / "config_manager" / "index.html"
    if config_html_path.exists():
        return create_cached_file_response(config_html_path)
    else:
        return HTMLResponse("""
        <html>
        <head><title>é…ç½®ç®¡ç†</title></head>
        <body>
        <h1>é…ç½®ç®¡ç†</h1>
        <p>é…ç½®æ–‡ä»¶ç•Œé¢æ­£åœ¨å¼€å‘ä¸­...</p>
        <a href="/viewer">è¿”å›æŸ¥çœ‹å™¨</a>
        </body>
        </html>
        """)


@app.post("/api/agents/{agent_ref}/send")
async def api_agent_send(
    agent_ref: str, body: AgentSendRequest, request: Request, token: dict = Depends(verify_token)
):
    """Send an ATA message from this agent to another agent (by id or numeric code)."""
    executor = get_tool_executor()
    from_agent_id = _resolve_agent_ref(executor, agent_ref)

    # resolve to_agent (id or numeric)
    to_ref = str(body.to_agent)
    to_agent_id = _resolve_agent_ref(executor, to_ref)

    # name-with-code convention for addressing
    from_agent = (
        executor.coordinator.registry.get_agent(from_agent_id) if executor.coordinator else None
    )
    to_agent = (
        executor.coordinator.registry.get_agent(to_agent_id) if executor.coordinator else None
    )
    from_display = _display_name(from_agent_id, getattr(from_agent, "numeric_code", None))
    to_display = _display_name(to_agent_id, getattr(to_agent, "numeric_code", None))

    msg_text = body.message.strip()
    # If not already addressed, prepend "@å¯¹æ–¹#NN"
    if msg_text and not msg_text.startswith(f"@{to_display}"):
        msg_text = f"@{to_display} {msg_text}"

    validated = ATASendParams(
        taskcode=body.taskcode,
        from_agent=from_agent_id,
        to_agent=to_agent_id,
        kind=body.kind,
        payload={
            "message": msg_text,
            "text": msg_text,
            "from_display": from_display,
            "to_display": to_display,
            "ata_comm_rule": "name_with_code_v1",
        },
        priority=body.priority,
        requires_response=body.requires_response,
        context_hint=body.context_hint,
    )

    caller = "agent_home"
    # Enforce same hard-gate as MCP tools/call: admin ctx required for sending
    admin_ctx = extract_admin_ctx(request)
    result = executor.ata_send(
        validated, caller=caller, user_agent=None, trace_id="agent_home", auth_ctx=admin_ctx
    )
    return result


def main():
    # Default to localhost for security (only accessible from 127.0.0.1)
    # Override with MCP_BUS_HOST environment variable if needed
    host = os.getenv("MCP_BUS_HOST", "127.0.0.1")
    port = int(os.getenv("MCP_BUS_PORT", "8000"))

    lock_path = os.path.join(tempfile.gettempdir(), "quantsys-mcp-bus.lock")

    def _is_pid_running(pid: int) -> bool:
        if pid <= 0:
            return False
        if sys.platform == "win32":
            try:
                result = subprocess.run(
                    ["tasklist", "/FI", f"PID eq {pid}"],
                    capture_output=True,
                    text=True,
                    timeout=2,
                )
                return str(pid) in result.stdout
            except Exception:
                return False
        try:
            os.kill(pid, 0)
            return True
        except Exception:
            return False

    def _is_port_listening(hostname: str, port_num: int) -> bool:
        try:
            with socket.create_connection((hostname, port_num), timeout=0.5):
                return True
        except OSError:
            return False

    def _terminate_pid(pid: int) -> bool:
        if pid <= 0:
            return False
        if sys.platform == "win32":
            try:
                result = subprocess.run(
                    ["taskkill", "/PID", str(pid), "/F"],
                    capture_output=True,
                    text=True,
                    timeout=5,
                )
                return result.returncode == 0
            except Exception:
                return False
        try:
            os.kill(pid, signal.SIGTERM)
            return True
        except Exception:
            return False

    force_restart = os.getenv("MCP_BUS_FORCE_RESTART", "").lower() in ("1", "true", "yes")

    # Prevent duplicate server instances and noisy bind errors.
    if os.path.exists(lock_path):
        try:
            with open(lock_path, "r", encoding="utf-8") as f:
                raw = f.read().strip()
            existing_pid = int(raw) if raw.isdigit() else 0
        except OSError:
            existing_pid = 0
        if _is_pid_running(existing_pid):
            if force_restart:
                print(f"[mcp_bus] stopping existing server pid={existing_pid}", file=sys.stderr)
                _terminate_pid(existing_pid)
                for _ in range(10):
                    if not _is_pid_running(existing_pid):
                        break
                    time.sleep(0.5)
            else:
                print(f"[mcp_bus] server already running pid={existing_pid}", file=sys.stderr)
                return

    if _is_port_listening(host, port):
        if force_restart:
            for _ in range(10):
                if not _is_port_listening(host, port):
                    break
                time.sleep(0.5)
        if _is_port_listening(host, port):
            print(f"[mcp_bus] port already in use {host}:{port}; skip start", file=sys.stderr)
            return

    try:
        with open(lock_path, "w", encoding="utf-8") as f:
            f.write(str(os.getpid()))
    except OSError:
        pass

    def _cleanup_lock() -> None:
        try:
            with open(lock_path, "r", encoding="utf-8") as f:
                raw = f.read().strip()
            if raw == str(os.getpid()):
                os.remove(lock_path)
        except OSError:
            pass

    atexit.register(_cleanup_lock)

    # æ£€æŸ¥æ˜¯å¦åœ¨åå°æ¨¡å¼è¿è¡Œï¼ˆç”± start_server_tray.py å¯åŠ¨ï¼‰
    # å¦‚æœæ˜¯ï¼Œåˆ™ä¸æ˜¾ç¤ºæ§åˆ¶å°è¾“å‡ºï¼ˆå·²åœ¨å­è¿›ç¨‹ä¸­å¤„ç†ï¼‰
    log_level = os.getenv("LOG_LEVEL", "info").lower()
    uvicorn.run(
        app,
        host=host,
        port=port,
        log_level=log_level,
        access_log=False,  # åå°è¿è¡Œæ—¶å…³é—­è®¿é—®æ—¥å¿—ä»¥å‡å°‘è¾“å‡º
    )


if __name__ == "__main__":
    main()
